+++
title = "fastgpt最强AI知识库喂饭教程"
date = 2024-04-27
lastmod = 2024-04-27T15:26:58+08:00
tags = ["AI"]
categories = ["工作"]
draft = false
author = "nigo"
+++

手把手教你安装 fastgpt

包含：embedding 和 reranker 模型

{{< figure src="/ox-hugo/2024-04-26_18-32-31_screenshot.png" >}}


## 原理 {#原理}

![](/ox-hugo/2024-04-26_17-40-54_screenshot.png)
图片来源：<https://www.oschina.net/p/fastgpt>


## 个人安装时常见问题 {#个人安装时常见问题}

-   mongodb 启动不了，登录不了 fastgpt
-   embedding (m3e) 模型不会安装，或者 mac 安装 m3e 只能使用CPU.
-   reranker  重排模型不会安装，或者 mac 使用不了。

建议阅读[fastgpt官方教程文档](https://doc.fastgpt.run/docs/development/docker/)


## 安装 Docker 和 docker-compose {#安装-docker-和-docker-compose}

我们建议将源代码和其他数据绑定到 Linux 容器中时，将其存储在 Linux 文件系统中，而不是 Windows 文件系统中。

可以选择直接使用 WSL 2 后端在 Windows 中安装 Docker Desktop。

也可以直接在 WSL 2 中安装命令行版本的 Docker。


## 创建目录并下载 docker-compose.yml {#创建目录并下载-docker-compose-dot-yml}

创建 `fastgpt` 文件夹，下载 `docker-compose.yml` 和 `config.json` 文件：

{{< highlight bash >}}
mkdir fastgpt
cd fastgpt
curl -O https://raw.githubusercontent.com/labring/FastGPT/main/files/deploy/fastgpt/docker-compose.yml
curl -O https://raw.githubusercontent.com/labring/FastGPT/main/projects/app/data/config.json
{{< /highlight >}}


## 修改配置文件 {#修改配置文件}


### docker-compose.yml {#docker-compose-dot-yml}


#### mongo {#mongo}

{{< highlight bash >}}
image: mongo:5.0.18
{{< /highlight >}}


#### fastgpt {#fastgpt}

修改 `OPENAI_BASE_URL`

{{< highlight bash >}}
- OPENAI_BASE_URL=http://host.docker.internal:3001/v1
{{< /highlight >}}

修改 `CHAT_API_KEY`


#### one api {#one-api}

如果使用latest版本报错403， xxx 向量模型没有权限 403，就修改下版本为早一点的版本。v0.6.4


### config.json {#config-dot-json}

添加 llmModels


## 安装并启动 docker {#安装并启动-docker}

docker-compose up -d

fastgpt:
初始账号：~root~
初始密码：~1234~


## one-api {#one-api}

初始账号：~root~
初始密码：~123456~
创建自定义渠道

( 创建令牌，并更新渠道密钥, 本地的话非必需 ）
ollama:
<http://host.docker.internal:11434>

如果使用latest版本报错403， xxx 向量模型没有权限 403，就修改下版本为早一点的版本。v0.6.4


## 配置 Embedding 向量模型 {#配置-embedding-向量模型}

在 `config.json` 文件中添加 vectorModels
效果好的有：

-   znbang/bge:large-zh-v1.5-f16
-   milkey/m3e:large-f16
-   nomic-embed-text

<!--listend-->

{{< highlight json >}}
{
  "model": "znbang/bge:large-zh-v1.5-f16",
  "name": "bge:large_zh",
  "avatar": "/imgs/model/openai.svg",
  "charsPointsPrice": 0,
  "defaultToken": 512,
  "maxToken": 3000,
  "weight": 100,
  "dbConfig": {},
  "queryConfig": {}
}
{{< /highlight >}}


## 配置 reRankModels 重排模型 {#配置-rerankmodels-重排模型}

由于 ollama 暂未支持 reranker 模型，所以我们使用官方文档中的

[教程文档](https://doc.fastgpt.run/docs/development/custom-models/bge-rerank/)

安装并启动 `bge-reranker-base` 模型服务：


### mac 注意事项 {#mac-注意事项}

Mac需要修改 `app.py` 中的代码：

{{< highlight python >}}
class ReRanker(metaclass=Singleton):
    def __init__(self, model_path):
        self.reranker = FlagReranker(model_path, use_fp16=False, device="mps")
{{< /highlight >}}

使用 `pip install -r requirements.txt` 安装完依赖后，通过 `python app.py` 启动服务。

步骤：

1.  注意修改requirements.txt中FlagEmbedding==1.2.8

的版本为最新版本，即FlagEmbedding==1.2.9。该版本
支持Mac使用GPU加速。（仅Mac才需要修改）

1.  app.py 中修改FlagReranker(model_path, use_fp16=False)

为FlagReranker(model_path, use_fp16=False, device="mps")
才能支持Mac使用GPU加速（仅Mac才需要修改）。

1.  运行pip install -r requirements.txt安装相关依赖。

2.  通过export ACCESS_TOKEN=mytoken设置环境变量

（访问重排模型的令牌）。


### 配置 {#配置}

在 `config.json` 文件中添加 reRankModels

{{< highlight json >}}
{
  "model": "bge-reranker-base",
  "name": "bge-reranker-base",
  "charsPointsPrice": 0,
  "requestUrl": "http://host.docker.internal:6006/v1/rerank",
  "requestAuth": "mytoken"
}
{{< /highlight >}}


## 完整配置文件 {#完整配置文件}

视频中配置文件及 reranker 重排模型下载：

链接: <https://pan.baidu.com/s/1nRlPp_vxGgR4yKnbnJsmfw?pwd=nigo> 提取码: nigo
