+++
title = "会计师事务所利用AI大模型的思考"
date = 2023-09-15
lastmod = 2023-09-15T23:23:11+08:00
tags = ["ai"]
categories = ["工作"]
draft = false
author = "nigo"
+++

前面我们介绍了讯飞星火知识库文档问答，这两天我用Langchain-chatchat + Chatglm2-6B 部署了本地的知识库问答。

{{< figure src="/ox-hugo/2023-09-15_21-37-17_LangChain.gif" >}}

可以直接和大模型对话，也可以基于上传的文件组成的知识库对话，也可以对搜索引擎对话。

可以看到在本地响应速度是非常快的。

{{< figure src="/ox-hugo/2023-09-15_21-43-23_screenshot.png" >}}

另外我们可以将专业领域的文档上传组成知识库，而且这里不会有上传的页数、字数的限制，也可以直接将图片的PDF OCR 识别成文本。

下面我们分成两部分来说下本地部署大模型的一些想法：

1.  直接对话。
2.  本地知识库问答。


## 直接对话 {#直接对话}

直接在本地使用大模型最大的好处就是省钱，不用担心信息泄漏，响应速度也非常快。

这里使用的是清华大学开源大模型 chatglm2-6B 是 60 亿的参数，正常如果要跑起来的话，需要 10 多G的显存。

而我是 3080 显卡只有10 G显存，直接跑会爆显存。经过尝试可以跑量化版本 chatglm2-6b-int4 ，大概6G 以内的显存也可以跑起来。

但是要知道，跑的模型越小，效果就越差。所以在自己消费级电脑上跑起来，效果并不好。

{{< figure src="/ox-hugo/2023-09-15_22-15-01_chatglm2.gif" >}}

但是本地跑最大的好处就是免费和灵活。我们可以在任何程序中调用这个接口，辅助我们工作。

比如，上图就是我在我平时码字的编辑器 emacs 中调用接口（接口是 openai 格式），可以随时问问题，并返回给我结果，这是十分灵活的。

而有接口，想像空间就很大了，比如上传文档、合同等文件，都可以让他去批量整理出想要的信息。

其实之前介绍过提取合同关键信息也是这个道理，只是利用这个大模型会更加强大。

而作为会计师事务所，其实可以利用这些开源大模型私有化部署，嵌入到管理系统、作业系统中。

很多开源大模型都是世界上的大厂花巨资训练出来的，不比国内大厂闭源的模型差。

嵌入到作业系统中可以可以作什么呢？


### 风险评估 {#风险评估}

在风险评估过程中，将系统收集的财务数据、司法案件、工商信息、网络舆情等信息，交给大模型去分析，形成风险提示。

当然，特定场景下可以针对性训练成一个 Lora 小模型，加一起就可以有很好的效果。


### 执行阶段 {#执行阶段}

在执行过程中，就在作业系统中有个悬浮的小圆圈，我随时可以调用出来，帮我设计针对性审计程序，帮我提示被处罚的案例，帮我处理数据。

现在其实 AI 发展很快，它不只是很回答你的问题，而是直接可以办公自动化。比如，之前我想批量合并 excel 什么的，他会给我写一段代码，我还需要粘贴到Excel VBA或者 python等运行环境去执行。

而最近的开源open interpreter可以直接办公自动化，你给他说什么直接就完成电脑上的操作。

所以，将来在审计执行过程中，那些基础的数据收集，数据处理工作，它有很大的发挥空间。


## 本地知识库问答 {#本地知识库问答}

说实话，我搭建的这个效果还不理想，也不知道是这个模型太小的原因还是什么。

通过看资料，我了解到实现本地知识库的问答的原理是：


### 文档知识向量化 {#文档知识向量化}

我们所有的文件，它都会先将文件转换成文本，对文本分段后通过 Embedding 模型转换成向量数据并存储。

这个向量我理解就是我们高中学习过的向量，无非是几维的问题。

{{< figure src="/ox-hugo/2023-09-15_22-42-32_screenshot.png" >}}


### 提问查找最相似数据 {#提问查找最相似数据}

当我们向其提问时，它也会把这个问题转换成一个向量，然后再去求与这个向量夹角最小的向量。

通过这样的方式，其实就能从我们知识库中找到最相似的数据内容。

到这里我们其实都还没有运用到类似 gpt 这样的大模型，只是检索我们知识库的相似数据。


### 大模型整理问答 {#大模型整理问答}

最后，找到的相似的文本内容和我们提的问题一起提交给大模型，它会整理出条理清晰的问答内容返回给我们。

就完成了本地知识库问答的过程。

虽然我测试下来的效果还不完美，但对我有也有很大的帮助，相信在 AI 目前日新月异的发展过程中，很快就能非常成熟应用。

这些搞 AI 的大公司有个短板，就是没有行业数据，它没法搞出针对性非常强的适用特定行业的大模型。

就比如审计，大部分信息和数据都是保密的，公开无法查询。

而会计师事务所正好相反，最大的优势就是数据。

像公开披露的会计准则、审计准则、处罚案例、 IPO 反馈问询等就不说了，前几天有朋友留言说像一般复核底稿过程中常见的问题 AI 能不能进行复核。

我想，这一定是可以的，只是时间早晚的问题。

而这里最关键的就是将通用大模型的能力加上行业数据的训练微调，形成行业专用的大模型或者特定运用场景下的大模型。

这样它能解放人工的力量就会非常大。

也许你觉得好像还很远，其实不远了，将来要么就是专业知识的专家，要么就是写 prompt 的专家。

前两天，我看一个同事的底稿，统计电商行业每个产品的销售次数、销售金额，

我看到商品名称还是英文的，我说全部翻译成中文哈，别人才看得懂。

同事说这100 、200 个商品名称全部翻译可能需要比较久的时间。

我说这不就是 10 秒钟的事吗？

直接复制 excel 表格的一列，粘贴到 chatgpt ，告诉它让他翻译成中文，并返回成表格的形式，就完了。

同事这才想起可以运用工具。

之前我查几十个国家的增值税税率也是这么查的。

所以，想到用 AI 和会写 prompt 很重要。

其实很多大所现在也在积极研究 AI 在我们审计中的应用，同时在信息化建设中融入进来。

希望，会计师事务所能利用好我们的数据优势，解放行业所有人的效率。


## 参考文章 {#参考文章}

搭建过程使用的文档和模型：

1.  Lanchain-chatchat 官方文档：<https://github.com/chatchat-space/Langchain-Chatchat>
2.  Chatglm2-6B 官方文档：<https://github.com/THUDM/ChatGLM2-6B>
3.  ChatGLM2-6B-int4 国内下载镜像：<https://cloud.tsinghua.edu.cn/d/674208019e314311ab5c/?p=%2F&mode=list>

由于我的显卡比较小，如果你有大显存的可以选择参数更大的模型。
