[{"categories":["工作"],"content":"我们将数据分析过程可以简单划分为： 数据清洗。 数据分析。 数据可视化。 其实这三部分都非常重要，缺一不可，任何一个环节没有做好，都可能导致我们数据分析工作的延误或失败。 根据我做过一些数据核查项目的经验，我对上述三个步骤的感性认识进行介绍。 ","date":"2023-08-13","objectID":"/posts/20230813154519-metabase%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%8F%8A%E5%8F%AF%E8%A7%86%E5%8C%96_%E5%85%88%E5%AF%BC%E7%AF%87/:0:0","tags":["metabase"],"title":"metabase数据分析及可视化-先导篇","uri":"/posts/20230813154519-metabase%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%8F%8A%E5%8F%AF%E8%A7%86%E5%8C%96_%E5%85%88%E5%AF%BC%E7%AF%87/"},{"categories":["工作"],"content":"数据清洗 如果你是在企业做数据分析，这些数据可能已经在数据库的，并不需要数据清洗的这个步骤，可以直接上手分析。 但像我们作为中介机构对企业进行数据核查，那么第一件事就是数据清洗。 在我看来，一般当出现这两种情况的时候会花费较多时间： ","date":"2023-08-13","objectID":"/posts/20230813154519-metabase%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%8F%8A%E5%8F%AF%E8%A7%86%E5%8C%96_%E5%85%88%E5%AF%BC%E7%AF%87/:1:0","tags":["metabase"],"title":"metabase数据分析及可视化-先导篇","uri":"/posts/20230813154519-metabase%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%8F%8A%E5%8F%AF%E8%A7%86%E5%8C%96_%E5%85%88%E5%AF%BC%E7%AF%87/"},{"categories":["工作"],"content":"多文件手工数据 如果给到我们的数据是手工维护的，再加上按月、渠道等又分成多个文件。 那么将是比较麻烦的事。 当然，如果是格式一样，我们可以通过一些Excel VBA插件或者 python 能够批量处理。 但是，手工维护的往往不可能那么规范，因此前期清洗、合并数据将会费不少工夫。 ","date":"2023-08-13","objectID":"/posts/20230813154519-metabase%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%8F%8A%E5%8F%AF%E8%A7%86%E5%8C%96_%E5%85%88%E5%AF%BC%E7%AF%87/:1:1","tags":["metabase"],"title":"metabase数据分析及可视化-先导篇","uri":"/posts/20230813154519-metabase%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%8F%8A%E5%8F%AF%E8%A7%86%E5%8C%96_%E5%85%88%E5%AF%BC%E7%AF%87/"},{"categories":["工作"],"content":"大数据量文件 其实当数据量较少的时候（比如：几百兆），无论是 Excel 还是 CSV 文件大家用软件都还能打开。 所以，要去除其中特殊符号，不规范的字符等都还可以操作。 但只要数据量一大，大家可能就会碰到打不开，看不见，导不进的困境。 死死地卡在前期的数据清洗工作中。 其实这种情况下是有技巧和方法的，我们可以借助终端工具快速完成合并文件、替换文本、删除特殊字体、掐头去尾等操作的。 这些技巧，一般教程讲得比较少，主要靠自己学习总结。 ","date":"2023-08-13","objectID":"/posts/20230813154519-metabase%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%8F%8A%E5%8F%AF%E8%A7%86%E5%8C%96_%E5%85%88%E5%AF%BC%E7%AF%87/:1:2","tags":["metabase"],"title":"metabase数据分析及可视化-先导篇","uri":"/posts/20230813154519-metabase%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%8F%8A%E5%8F%AF%E8%A7%86%E5%8C%96_%E5%85%88%E5%AF%BC%E7%AF%87/"},{"categories":["工作"],"content":"数据分析 数据清洗完成后，我们利用 SQL 或者 Python 对数据进行查询分析，之前我们介绍过的 mysql 、duckdb 、clickhouse 、python 基本都是在完成这个目标。 其实，这部分工作相对来说，简单易学一些，对于常用的分析维度、分析指标、分析方法，写几次 SQL 就会了。 难度不大。 ","date":"2023-08-13","objectID":"/posts/20230813154519-metabase%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%8F%8A%E5%8F%AF%E8%A7%86%E5%8C%96_%E5%85%88%E5%AF%BC%E7%AF%87/:2:0","tags":["metabase"],"title":"metabase数据分析及可视化-先导篇","uri":"/posts/20230813154519-metabase%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%8F%8A%E5%8F%AF%E8%A7%86%E5%8C%96_%E5%85%88%E5%AF%BC%E7%AF%87/"},{"categories":["工作"],"content":"数据可视化 数据分析我们往往形成的是报表，有时候并不能直观发现问题及异常点，因此我们需要对数据进行可视化，当然这也是汇报展示时需要用到的。 这类工具有非常多 Excel, Power BI. 商业软件，ACL,Tableau 等。 Python 绘图库，Plotly,Seabon等。 开源 BI 工具，Superset,MetaBase,ReDash 等。 我花了很长时间，使用 Python 的 Plotly 库作为我的可视化工具，因为它能贯穿我的整个工作流，并且也具有快速和出图美观的特点。 但这肯定不是适合所有人的，毕竟它需要比较大的学习成本和时间成本。 那么我还是推荐大家使用开源的 BI 工具。之前我使用过基于 Python 的 Superset ，当时试用过下，最终还是没有继续使用下去。 前两天和所里创新研发部沟通的时候，了解到 MetaBase 这个工具，我试用了下，无论从易用性、美观度、功能都很不错。 因此，我准备自己学习使用下，同时写个系列教程文章进行介绍。 ","date":"2023-08-13","objectID":"/posts/20230813154519-metabase%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%8F%8A%E5%8F%AF%E8%A7%86%E5%8C%96_%E5%85%88%E5%AF%BC%E7%AF%87/:3:0","tags":["metabase"],"title":"metabase数据分析及可视化-先导篇","uri":"/posts/20230813154519-metabase%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%8F%8A%E5%8F%AF%E8%A7%86%E5%8C%96_%E5%85%88%E5%AF%BC%E7%AF%87/"},{"categories":["工作"],"content":"MetaBase MetaBase 是一款开源免费的 BI 系统。它面向的是非技术人员，因此使用起来比较易用，通过拖拖拽拽就可以形成比较美观的图表。 同时对于技术人员，也可以直接写 SQL ，将 SQL 查询结果出图表。 通过它我们可以连接多种常用的数据库类型，这样我们直接可以和我们第二步数据分析的环节打通，直接在这上面写 SQL 出图。 同时它还有比较强大的透视和下钻功能： ","date":"2023-08-13","objectID":"/posts/20230813154519-metabase%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%8F%8A%E5%8F%AF%E8%A7%86%E5%8C%96_%E5%85%88%E5%AF%BC%E7%AF%87/:4:0","tags":["metabase"],"title":"metabase数据分析及可视化-先导篇","uri":"/posts/20230813154519-metabase%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%8F%8A%E5%8F%AF%E8%A7%86%E5%8C%96_%E5%85%88%E5%AF%BC%E7%AF%87/"},{"categories":["工作"],"content":"透视 当我们只要连接了某个数据，就可以直接对其中的数据表进行透视。 他会自动将一些基本的分析维度的可视化结果展示给我们： 当然，在“更多透视方法”中也给我们提供了更多的字段，当我们关心某个字段时，可以点击进去。 比如我对created_at创建时间更感兴趣，我直接点击，就直接显示出时间序列的分析结果： 按年分析： 按月、按季度、按星期、按小时分析： 这些工作，我们还没有写一句 SQL ，全是它自动完成的。对于我们快速了解数据整体非常有帮助。 ","date":"2023-08-13","objectID":"/posts/20230813154519-metabase%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%8F%8A%E5%8F%AF%E8%A7%86%E5%8C%96_%E5%85%88%E5%AF%BC%E7%AF%87/:4:1","tags":["metabase"],"title":"metabase数据分析及可视化-先导篇","uri":"/posts/20230813154519-metabase%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%8F%8A%E5%8F%AF%E8%A7%86%E5%8C%96_%E5%85%88%E5%AF%BC%E7%AF%87/"},{"categories":["工作"],"content":"下钻 除此之外，我们还可以对我们关心的数据直接进行下钻和横向对比。 例如，下图中我看到美国的数值很大，我想看下是什么原因导致的，或者是其具体情况，我可以直接点击“透视” 我们可以直接看到地区是美国的详细情况。 甚至我们还可以点击“与其他国家对比”，直接看美国和所有国家的对比情况。 这一点其实非常有用的，因为我们经常在分析的过程的会看到异常波动的点，我们需要对其按各个维度对分析主要是什么原因导致的。 它的这个透视、下钻、横向对比功能，将大大减轻我们的工作。 ","date":"2023-08-13","objectID":"/posts/20230813154519-metabase%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%8F%8A%E5%8F%AF%E8%A7%86%E5%8C%96_%E5%85%88%E5%AF%BC%E7%AF%87/:4:2","tags":["metabase"],"title":"metabase数据分析及可视化-先导篇","uri":"/posts/20230813154519-metabase%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%8F%8A%E5%8F%AF%E8%A7%86%E5%8C%96_%E5%85%88%E5%AF%BC%E7%AF%87/"},{"categories":["工作"],"content":"结语 我们可以看到 MetaBase 是非常强大和方便的，但是有一个问题是我们需要对表的字段设置成正确的数据类型。 比如，一般我们在 Mysql 导入数据时可能为了图方便，直接全部字段设置成varchar(255)的文本类型。 但在 MetaBase 中进行可视化时，这种文本类型无法直接作为数值进行计算出图。 同样的，日期时间也需要正确设置成 DATETIME 、DATE 等数据类型，才可以进行时间序列分析。 这其实对我们数据核查来说提出了比较高的要求，因为我们面临大量的数据导入工作。 这将给我们增加大量建表工作。 因此，在我们正式安装学习之前，下一篇我会先介绍如何一键快速建表和导数。 这个过程会比使用图形化工具的导入向导更快。 那我们就先安利到这吧，下篇见。 ","date":"2023-08-13","objectID":"/posts/20230813154519-metabase%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%8F%8A%E5%8F%AF%E8%A7%86%E5%8C%96_%E5%85%88%E5%AF%BC%E7%AF%87/:5:0","tags":["metabase"],"title":"metabase数据分析及可视化-先导篇","uri":"/posts/20230813154519-metabase%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%8F%8A%E5%8F%AF%E8%A7%86%E5%8C%96_%E5%85%88%E5%AF%BC%E7%AF%87/"},{"categories":["工作"],"content":"在见微数据的 IPO 问询反馈栏目搜索一下关键词“ BOM ”，可以看到出现了 147 个相关问询。 这里随便列举前几条： 1.结合材料领用、成本结转与 BOM 清单的对比情况，说明成本结转的完整性. 2.结合 BOM 清单、产品销量以及实际领用数量，说明投入产出的配比关系、成本结转完整性以及是否存在将不相关支出计入存货的情形. 3.结合主要产品的 BOM 表单物料构成，说明主要物料采购、耗用、结存与产成品销售的匹配关系. 可以看出根据 BOM 计算出原材料的理论耗用量与实际耗用量，是 IPO 问询中的常见问题。 那么BOM (物料清单)是什么？ 它是产品结构表，通俗点理解就是配方。 假如我们要做一盘青椒肉丝，那么它的 BOM 就是理论上需要几两肉、几两青椒、多少调味料，就是生产过程的配方。 当然，这中间还涉及到生产工艺，分成几道工序，哪个时候洗菜、哪个时候切菜、哪个时候烹饪等等。 在制造型企业中，ERP 系统会专门维护 BOM ，生产领料时一般会根据系统 BOM 计算需要多少原材料并按单领料。 那么作为审计，我们会自己动手算产成品所需要理论原材料耗用量，或者说单耗吗？ 当工艺简单，只有一两道工序的时候，我们可能能做到，当工序多了后，可能只能让企业提供，我们分析复核了。 其实只要我们拿到 BOM 就可以计算出单个产成品所需要消耗的原材料数量。 下表是一个典型的 ERP 系统中的 BOM 表： 父物料 子物料 数量 单位 A B 1 EA A C 2 EA B D 0.6 KG 这里假设我们生产一个产成品 A 需要两道工序：冲压和焊接。 冲压是将钢材加工成一定的形状。 焊接是将冲压件焊接在一起。 那么产成品 A 在焊接工序需要耗用 B 、 C 两个物料。而 B 又是通过 C 在冲压工序中制得的。 我们可以看到这里有个问题是这个 BOM 表是一张二维表，而我们产成品是多层级的。如果直接看表中产成品 A 耗用的物料是 B 和 C , 但我们真正需要看的是 A 耗用的末级物料 C 和 D. 那么我们主要解决的问题是如何根据这个 bom 二维表计算出产成品消耗的末级物料数量。 之前我写过一篇文章用 python 构建两个类：节点类和树类，完成了这个操作。 当时生成产成品只包含：未在“子物料”列出现过的父物料，自动识别为产成品。 但我发现有些企业存在一些中间产品对外销售的情况，代码生产不能包含这些中间产品。 所以，我修订了下，可以和之前一样只生成产成品的末级物料消耗量，也可以生产指定物料（包含中间产品）的末级物料消耗量。 #!/usr/bin/python3 # -*- coding:UTF-8 -*- # Author: nigo import pandas as pd class Node: def __init__(self, name, amount=1): self.name = name # 节点名称 self.amount = amount # 数值 self.father = None # 父节点 self.children = [] # 子节点 def add_child(self, obj): self.children.append(obj) # 添加子节点 def add_father(self, obj): self.father = obj # 添加父节点 def terminal(self,name=True): \"\"\"末级节点\"\"\" terminal_list = [] # 创建末级节点列表 for node in self.children: # 遍历子节节点 if node.children: # 若子节点有子节点 terminal_list += node.terminal(name) # 递归函数 else: if name: terminal_list.append([name,node.name,node.amount]) # 添加到末级节点列表 else: terminal_list.append([node.name,node.amount]) # 添加到末级节点列表 return terminal_list class Tree: def __init__(self, df,tops=[]): self.trees = [] self.init(df,tops) # 初始化 def init(self, df,tops): father_list = df.iloc[:, 0] # df第一列为父节点名称 child_list = df.iloc[:, 1] # df第二列为子节点名称 if not tops: # 父节点中未出现在子节点的为顶级节点 tops = [i for i in father_list if i not in list(child_list)] # 指定了父节点就用指定的。 tops = list(set(tops)) relation = {} # 层级对应关系 for index, row in df.iterrows(): # 循环dataframe每一行 father = row[0] # 父节点名称 child = row[1] # 子节点名称 amount = row[2] # 子节点值 if father in relation.keys(): children = relation[father] children.append({'name':child,'amount':amount}) relation[father] = children else: relation[father] = [{'name':child,'amount':amount}] self.relation = relation for top in tops: if top in self.relation.keys(): self.trees.append(self.make_tree(top,1)) def make_tree(self, top, amount): \"\"\"根据顶级节点建立树状关系\"\"\" father_node = Node(top,amount) # 创建父节点 for child in self.relation[top]: # 遍历父节点对应的所有下一层级 if child['name'] in self.relation.keys(): # 如果child有下一层级 child_node = self.make_tree(child['name'],child['amount']*amount) # 调用递归函数 child_node.add_father(father_node) # 给子节点添加父节点 father_node.add_child(child_node) # 给父节点添加子节点 else: # 如果child没有下一层级 child_node = Node(child['name'],child['amount']*amount) # 创建子节点 child_node.add_father(father_node) # 给子节点添加父节点 father_node.add_child(child_node) # 给父节点添加子节点 return father_node if __name__ == \"__main__\": df = pd.read_excel('BOM表的路径.xlsx',converters={'父组件':str,'组件':str}) # 指定生成哪些物料就用下面这两行 ，自动生成最终产成品就注释这两行 df_product = pd.read_excel('指定物料号的文件（可以是生产订单）.xlsx',converters={ '物料号':str}) tops = df_product['物料号'].to_list() # 指定生成哪些物料就用上面这两行 ，自动生成最终产成品就注释这两行 code2name = {} # 物料编码与物料名称的映射 for index,row in df.iterrows(): code2name[row['父组件']] = row['父物料描述'] code2name[row['组件']] = row['物料描述'] df = df.loc[:,['父组件','组件','净数量']] # 截取三列 # 实例化Tree类 tree = Tree(df,tops) # 指定生成哪些物料就用 Tree(df,tops) ，自动生成最终产成品就用 Tree(df) df_result = pd.DataFrame() for top in tree.trees: # 循环每一个根节点 # 求每个根节点的末级节点 df_tmp = pd.DataFrame(top.terminal(top.name),columns=['父组件','组件','数量']) # 合并dataframe df_result = pd.concat([df_result,df_tmp]) # 根据物料代码添加物料名称 df_result['父组件名称'] = '' df_result['组件名称'] = '' df_result = df_result.reset_index(drop=True) for index,row in df_result.iterrows(): if row['父组件'] in code2na","date":"2023-08-03","objectID":"/posts/20230803221527-%E4%B8%BB%E8%A6%81%E5%8E%9F%E6%9D%90%E6%96%99%E4%B8%8E%E6%A0%87%E5%87%86bom%E8%AE%A1%E7%AE%97%E7%90%86%E8%AE%BA%E8%80%97%E7%94%A8%E9%87%8F%E7%9A%84%E5%8C%B9%E9%85%8D%E6%80%A7/:0:0","tags":["python"],"title":"主要原材料与标准BOM计算理论耗用量的匹配性","uri":"/posts/20230803221527-%E4%B8%BB%E8%A6%81%E5%8E%9F%E6%9D%90%E6%96%99%E4%B8%8E%E6%A0%87%E5%87%86bom%E8%AE%A1%E7%AE%97%E7%90%86%E8%AE%BA%E8%80%97%E7%94%A8%E9%87%8F%E7%9A%84%E5%8C%B9%E9%85%8D%E6%80%A7/"},{"categories":["工作"],"content":"上周同事在做一个项目，涉及到采购发票台账与税务系统发票的核对。 其中采购发票台账是财务手工维护的，长这样： 其中发票号是09254970-4977 ，代表着09254970 到 09254977 连续的编号，是一个范围。 而税务系统的发票号是分开的，长这样： 最终同事想生成这样的核对明细： ","date":"2023-07-30","objectID":"/posts/20230730232202-%E6%89%8B%E5%B7%A5%E5%8F%91%E7%A5%A8%E5%8F%B7%E6%8B%86%E5%88%86/:0:0","tags":["python"],"title":"手工发票号拆分","uri":"/posts/20230730232202-%E6%89%8B%E5%B7%A5%E5%8F%91%E7%A5%A8%E5%8F%B7%E6%8B%86%E5%88%86/"},{"categories":["工作"],"content":"需求 她需要实现 3 个目标： 将采购发票明细表里的发票号进行拆分，并对品名及规格型号进行合并列示。 也就是将范围的发票号拆分成多行，同时之前相同发票号范围的多个规格型号合并在一起。 将税务系统发票明细里的的品名及规格型号按发票号合并列示 也就是之前品名和规格是两列，要合在一列。 将拆分合并后的采购发票明细与税务系统发票明细，根据发票号，对品名规格型号进行匹配核对。 例如：09254970-4977 ，所有的规格型号和税务系统所有规格型号作对比，只要元素相同，不论顺序，就将这个范围的发票号“是否一致”标注成“是”。 ","date":"2023-07-30","objectID":"/posts/20230730232202-%E6%89%8B%E5%B7%A5%E5%8F%91%E7%A5%A8%E5%8F%B7%E6%8B%86%E5%88%86/:1:0","tags":["python"],"title":"手工发票号拆分","uri":"/posts/20230730232202-%E6%89%8B%E5%B7%A5%E5%8F%91%E7%A5%A8%E5%8F%B7%E6%8B%86%E5%88%86/"},{"categories":["工作"],"content":"拆分逻辑编写 当然，由于采购发票明细是手工维护的，有些不规范，录入的数据存在00737934-7937、1277263-7266这种多个范围的，也存在这种21256660-6664、6666-6681第二范围只用尾数 6666 开头，连前面前缀2125都省去的情况。 所以拆分的时候，我首先需要判断是否存在顿号、，有的号先将其拆分成多个范围组，再处理每一个范围组。 def split_number(input_str): if re.findall('、', input_str): subs_str = input_str.split('、') mother_str = subs_str[0] if re.findall('-', input_str): mother_number = mother_str.split('-')[0] else: mother_number = mother_str output = [] for sub_str in subs_str: output = output + split_number_by_flag(sub_str, mother_number) return output else: return split_number_by_flag(input_str) 上面的函数当我输入input_str发票号时，将判断是否有顿号，存在的话，拆分开，并获取第一个范围的数字前缀作为mother_number母号码。 这样就可以使用split_number_by_flay(input_str,mother_number='')函数分别处理单个范围组： def split_number_by_flag(input_str,mother_number=''): if re.findall('-',input_str): start, end = input_str.split('-') if len(start) \u003c len(mother_number): end = start[ :len(start)-len(end)] + end start = mother_number[ :len(mother_number)-len(start)] + start end = mother_number[ :len(mother_number)-len(end)] + end else: end = start[:len(start)-len(end)] + end length = len(start) start = int(start) end = int(end) output = [str(i).zfill(length) for i in range(int(start), int(end) + 1)] return output else: if mother_number: output = [mother_number[ :len(mother_number)-len(input_str) ] + input_str] else: output = [input_str] return output 这样我就可以完成连续发票号的拆分。 至于规格型号的对比，我只需要将发票号范围的所有规格型号存成元组，和税务系统的数据作对比，就可以判断是否一致。 ","date":"2023-07-30","objectID":"/posts/20230730232202-%E6%89%8B%E5%B7%A5%E5%8F%91%E7%A5%A8%E5%8F%B7%E6%8B%86%E5%88%86/:2:0","tags":["python"],"title":"手工发票号拆分","uri":"/posts/20230730232202-%E6%89%8B%E5%B7%A5%E5%8F%91%E7%A5%A8%E5%8F%B7%E6%8B%86%E5%88%86/"},{"categories":["工作"],"content":"完整代码 以下是完整代码，可以批量处理同事对2019-2023.6月的所有发票的拆分、核对工作。 #!/usr/bin/python3 # -*- coding:UTF-8 -*- # Author: nigo import pandas as pd from tqdm import tqdm import re def split_number_by_flag(input_str,mother_number=''): if re.findall('-',input_str): start, end = input_str.split('-') if len(start) \u003c len(mother_number): end = start[ :len(start)-len(end)] + end start = mother_number[ :len(mother_number)-len(start)] + start end = mother_number[ :len(mother_number)-len(end)] + end else: end = start[:len(start)-len(end)] + end length = len(start) start = int(start) end = int(end) output = [str(i).zfill(length) for i in range(int(start), int(end) + 1)] return output else: if mother_number: output = [mother_number[ :len(mother_number)-len(input_str) ] + input_str] else: output = [input_str] return output def split_number(input_str): if re.findall('、', input_str): subs_str = input_str.split('、') mother_str = subs_str[0] if re.findall('-', input_str): mother_number = mother_str.split('-')[0] else: mother_number = mother_str output = [] for sub_str in subs_str: output = output + split_number_by_flag(sub_str, mother_number) return output else: return split_number_by_flag(input_str) if __name__ == \"__main__\": print('读取数据') df_detail = pd.read_excel('采购发票明细表2019-2023.6-7.18版.xlsx',converters={'修正后发票号':str}) df_tax = pd.read_excel('税务系统发票明细2019-2023.6-7.18版.xlsx',converters={'发票号（合并）':str}) # 填充空值 df_detail.fillna('',inplace=True) df_tax.fillna('',inplace=True) # 合并规格型号 df_detail['品名材质规格'] = df_detail.apply(lambda row: str(row['修正后品名']) + str(row['材质']) + str(row['规格']),axis=1) df_tax['品名材质规格'] = df_tax.apply(lambda row: str(row['修正后品名']) + str(row['修正后规格型号']),axis=1) # 获取所有发票号码 invoice_numbers = df_detail['修正后发票号'].unique() # 税务发票号与品名规格型号对应关系 number2category = {} df_merge = pd.DataFrame() print('建立税务明细关系') for index,row in df_tax.iterrows(): invoice_number = row['发票号（合并）'] if invoice_number in number2category.keys(): tmp = number2category[invoice_number] if row['品名材质规格'] not in tmp: tmp.append(row['品名材质规格']) tmp.sort() number2category[invoice_number] = tmp else: number2category[invoice_number] = [row['品名材质规格']] print('循环采购明细') # 数据处理，循环采购发票明细 for invoice_number in tqdm(invoice_numbers): try: split_numbers = split_number(invoice_number) except: split_numbers = [] print(invoice_number) df_number = pd.DataFrame() tax_categories = [] tax_names = [] sub_df = df_detail[df_detail['修正后发票号']==invoice_number] sub_df = sub_df.reset_index(drop=True) categories = sub_df['品名材质规格'].unique() categories.sort() category = '、'.join(categories) if split_numbers: df_number['年度'] = [sub_df.loc[0,'年度']] * len(split_numbers) df_number['原始发票号'] = invoice_number df_number['拆分后发票号'] = split_numbers else: df_number['年度'] = [sub_df.loc[0,'年度']] * 1 df_number['原始发票号'] = invoice_number df_number['拆分后发票号'] = '不能拆分' df_number['品名材质规格'] = category for no in split_numbers: if no in number2category.keys(): tax_row_name = number2category[no] tax_row_name.sort() tax_categories = tax_categories + tax_row_name tax_name = '、'.join(tax_row_name) tax_names.append(tax_name) else: tax_names.append('未找到编号') if tax_names: df_number['与税务系统匹配'] = tax_names else: df_number['与税务系统匹配'] = '未找到编号' if set(tax_categories) == set(categories): df_number['是否一致'] = '是' else: df_number['是否一致'] = '否' df_merge = pd.concat([df_merge,df_number]) df_merge.to_excel('结果.xlsx',index=False) print('over') ","date":"2023-07-30","objectID":"/posts/20230730232202-%E6%89%8B%E5%B7%A5%E5%8F%91%E7%A5%A8%E5%8F%B7%E6%8B%86%E5%88%86/:3:0","tags":["python"],"title":"手工发票号拆分","uri":"/posts/20230730232202-%E6%89%8B%E5%B7%A5%E5%8F%91%E7%A5%A8%E5%8F%B7%E6%8B%86%E5%88%86/"},{"categories":["生活"],"content":"花了三周空余时间阅读完原版《Atomic Habits》，顺便用 Anki 记了 500 多个生词。 读这本原子习惯的原因，主要是因为在工作琐碎的时候，很难掌控自己的时间，年初定下的一些目标一直停滞不前。 这归根结底是主观上放松了，也是没有养成一个好的习惯。 Goals are about the results you want to achieve. Systems are about the processes that lead to those results. 目标是你想实现的结果，系统是你实现结果的过程。 这里的系统就是我们的习惯系统。 人是非常容易松懈的，每天工作完，往床上或者沙发上一躺，告诉自己就看半个小时的手机。 半个小时到了，对自己说我就把这条刷完就干活。 刷完还意犹未尽，心想再看几分钟也耽误不了什么事。 就这样，你会发现不知不学两三个小时过去了，自己屁事没干。 说好的考证、看书，早已抛之千里之外。 更糟糕的情况是，我们制定计划时没有容错机制，当发现很难完成目标时，就直接索性躺平了。 这就是我目前的现状。 这也是我没有养成好的习惯。 要知道习惯是个很可怕的东西，它其实代表着一个人的执行力和毅力。 当你养成一个习惯时，你会延续着这个轨迹做事，不需要花费额外的精力；但如果你想改变它，就不是一朝一夕能做到的。 Habits are mental shortcuts learned from experience. 没错，习惯就是我们日常行为的快捷方式。 书中介绍了习惯养成的 4 个步骤： Cue 提示 Crave 渴求 Response 反应 Reword 奖赏 针对这 4 点，作者介绍了养成好习惯的 4 个原则： ","date":"2023-07-29","objectID":"/posts/20230723225858-atomic_habits/:0:0","tags":["读书笔记"],"title":"Atomic Habits","uri":"/posts/20230723225858-atomic_habits/"},{"categories":["生活"],"content":"The 1st Law: Make It Obvious 我们在生活中有很多触发我们习惯的钩子(trigger)，我理解就是环境或者引发我们行为的提示(Cue)。 当周围有人抽烟，我就忍不住想来一根。 当躺在床上，就忍不住刷手机。 这就是环境的作用，它能触发我们已有的习惯。 而我们要做的就是让这个好的触发器显而易见。 这个可以根据自己的实际情况打造自己习惯的触发器。 ","date":"2023-07-29","objectID":"/posts/20230723225858-atomic_habits/:1:0","tags":["读书笔记"],"title":"Atomic Habits","uri":"/posts/20230723225858-atomic_habits/"},{"categories":["生活"],"content":"The 2nd Law: Make It Attractive 为什么刷剧、游戏能让人着迷，就是因为它能及时给予娱乐、反馈、奖励。 往往我们选择的长远目标，很难短时反馈。 理论上讲，考下 CPA 的成就感肯定比玩一把游戏赢了要高，更让吸引人。 但是这个周期太长了，我们不仅要让这个目标看上去吸引人，还要在短时间上给予自己心理上的奖励。 ","date":"2023-07-29","objectID":"/posts/20230723225858-atomic_habits/:2:0","tags":["读书笔记"],"title":"Atomic Habits","uri":"/posts/20230723225858-atomic_habits/"},{"categories":["生活"],"content":"The 3rd Law: Make It Easy 让这件事变得简单。 我们刚想形成一个新习惯时，常常虎头蛇尾，开始一时兴起，和打了鸡血一样，坚持不了两三天，就感觉难以维系，最终不了了之。 书中给出了一个两分种原则，就是说对于新习惯，要让它只需要做两分钟就可以完成。 例如，想要健身，那么给自己每天的任务就是到健身房去，什么都不用干，就完成目标。 当你这样坚持一周后，可能就会去尝试锻炼锻炼，循序渐进地就可以养成习惯。 仔细想想，很多时候，我们想达到比较远的目标时，往往需要做的很困难，而这种困难会吓到自己。 让它变得简单，就是让自己不费力的慢慢形成新的习惯。 如果想养成阅读的习惯，就每天让自己阅读一页书，甚至就是阅读一段也可以。 在不做出大的改变的时候，是容易形成新的习惯。当这个习惯形成后，又以此为基点，进一步形成新的习惯。 在一个一个新习惯的改变下，再加上时间的作用，将会发生巨大的改变。 ","date":"2023-07-29","objectID":"/posts/20230723225858-atomic_habits/:3:0","tags":["读书笔记"],"title":"Atomic Habits","uri":"/posts/20230723225858-atomic_habits/"},{"categories":["生活"],"content":"The 4th Law: Make It Satisfying Boredom is perhaps the greatest villain on the quest for self-improvement 无聊也许是追求自我提升的最大敌人。 让这件事变得有趣，也许是持续提升的催化剂。如果说习惯是一段漫长的旅途，那么在旅途中给予自己奖励，在每次到达小目标时，提升自己的满足感，将会使这个过程更容易和美妙。 就像以前考 CPA 时，我把未来可能赚到的钱除以 10 本书的页数，每看一页书，就告诉自己今天又挣了多少钱，这样的满足感，让自己能坚持下来。 ","date":"2023-07-29","objectID":"/posts/20230723225858-atomic_habits/:4:0","tags":["读书笔记"],"title":"Atomic Habits","uri":"/posts/20230723225858-atomic_habits/"},{"categories":["生活"],"content":"Forest 这本书我感觉还是写得很好的，虽然国外的书经常是一篇文章的内容写成一本书。 但读着读着时不时还是会有启发或者共鸣之处。 利用本书讲的养成习惯的四条法则，我也打算提升下自己，让自己养成一些好的习惯。 但需要注意的是，当一件事形成习惯的时候，我们所做的事情是不需要思考的，我们自己会下意识完成。 这有好处，其实也有坏处。 需要我们经常去审视自己和反思，就像书中说的： Establish a system for reflection and review. 需要我们建立反思系统。 最后再推荐大家一个APP : Forest. 它的名字就像一句名言： 种一棵树最好的时间是十年前，其次是现在。 当年在考 CPA 和学习英语的时候经常使用这个APP ，每专注 25 分钟就能种下棵树，这是 2017 年的纪录： 这是 2018 年的纪录： 这是 2019 年的纪录： 2018 年总共花了 44 小时 55 分钟，通过了 CPA 综合阶段： 2019 年之后就再未用过，现在打算再用起来，先有记录，才有反思，才能养成习惯。 不过，前几天我再登录账号时，发现之前我用的是国际服务器，同步速度很慢，所以重新注册了国内服务器的账号。 可惜的是，以前的树都没法迁移过来了。 如果你也想用，注册的时候可以填上我的邀请码：5MR65NYSC 这样，我们都可以获得 500 金币（金币可以换不同的树的样式）。 我的 Forest 账号（可以加好友，看到对方种的树）： tujiabing81@163.com 来一起种树吧！ ","date":"2023-07-29","objectID":"/posts/20230723225858-atomic_habits/:5:0","tags":["读书笔记"],"title":"Atomic Habits","uri":"/posts/20230723225858-atomic_habits/"},{"categories":["生活"],"content":"我经常会计划着自己什么时候退休。 为什么？ 因为总有些自己不喜欢干的事，总有些自己想干但没有时间干的事。 我这里指的退休，是不用上班，能够有足够的被动收入支撑自己的开支。 当然，不用上班，不是说就不干事了，也不是说就不挣钱了。 而是，我可以选择不做自己不想做的事，选择去做自己想做的事， 做与不做都能保证自己活着。 其实，我对物质的欲望很低，一台电脑、一日三餐、偶尔吃点肉、喝点酒，足矣。 所以，对于我自己来说，存够 200 万，按5%的收益率，差不多可以支撑我去做自己想做的事。 人这辈子，其实挺可悲的，大部分人都只是被动地活着。 寒窗苦读 20 载，毕业了996 ，结婚生子，30 年房贷，人至暮年，行将就木。 短短一句话，浓缩大部分人的一生。 这其中每一个阶段，有来自父母、爱人、子女、乃至社会对你的要求，你按这些要求活着。 从来你就是为别人而活，未曾为自己活过一天。 当然，体面的活着已是不易，能满足这些要求，已算是所谓的“成功”人士。 但，出生时拿着的这张几十年的单程票，当到达终点时，回望这一路，是否会感到无趣？ 我想我是会的。 我想多做些，我想多玩玩这个世界。 所以，要达到这个目标，我觉得需要： 掌握一门技能，攒钱，活在当下 有一门技能，就有一口饭吃。 其实大家不用把自己的工作想得多高大上，无论是西装革履的金融人，年薪百万的码农，风吹日晒的外卖小哥，都是新一代的农民工。 糊口而已，没有本质区别，都在通过卖自己的劳动时间挣钱。 而掌握一门技能，可以保证自己能随时换一口饭吃。 攒钱，避免掉入消费主义的陷井，让退休的时间早一点。 活在当下，感受每一个阶段的美，累了就休息，想躺平就躺平一会儿，感觉好了继续攒钱，若有余力，可以多尝试自己的兴趣和自己擅长的方面。 当被动收入可以支撑自己生活了，就去做自己想做的事吧。 你如果要问我想做的事是什么？ 我哪里知道， 我想做的就是都去尝试下呗，当了几十年的社畜，自己所知道的相比这个世界，总是渺小的吧。 总有些事，自己想去尝试吧；总有些地方，自己想去看看吧；总有些人，自己想去多陪陪吧。 我的退休时间点，就是存款 200 万，把两个孩子送进大学， 40 多岁，差不多了。 继续打工攒钱。 ","date":"2023-07-23","objectID":"/posts/20230722225245-%E5%95%A5%E6%97%B6%E5%80%99%E9%80%80%E4%BC%91/:0:0","tags":["感悟"],"title":"啥时候退休？","uri":"/posts/20230722225245-%E5%95%A5%E6%97%B6%E5%80%99%E9%80%80%E4%BC%91/"},{"categories":["工作"],"content":"在互联网行业中很多产品是采取的订阅制收费的模式，例如：订阅付费专栏，音乐视频会员，游戏会员，广告推广等等。 这类型的商品都有一个特点，就是用户在一个时点充值，在一段期间受益，收入需要按照这段期间进行分摊。 之前写过一篇用 Python 计算广告收入的文章，今天我们换一种方法用 SQL 来计算分摊的收入。 ","date":"2023-07-13","objectID":"/posts/20230712221905-%E8%AE%A2%E9%98%85%E5%88%B6%E6%94%B6%E5%85%A5%E5%88%86%E6%91%8A%E6%B5%8B%E7%AE%97/:0:0","tags":["duckdb"],"title":"订阅制收入分摊测算","uri":"/posts/20230712221905-%E8%AE%A2%E9%98%85%E5%88%B6%E6%94%B6%E5%85%A5%E5%88%86%E6%91%8A%E6%B5%8B%E7%AE%97/"},{"categories":["工作"],"content":"项目背景 下面摘取主要字段，作为示例数据： 字段 示例数据 释义 startTime 2023-01-03 22:25:36 订单开始时间 creatTime 2023-01-02 22:25:29 订单创建时间 totalFee 1690 总费用 payType 1 支付渠道 accelDays 90 订阅天数 freeDays 1 免费赠送天数 additionPrices 400 加价购买费用 additionDays 20 加价购买天数 ( 注：金额单位为“分”） 上面数据对应的场景是，我在 2023 年 1 月 2 日花了12.9元，购买了一张季卡，可以有 90 天的订阅天数。 我在购买这个商品时，享受了 1 天的免费订阅天数，同时商品有个加价购的活动，加价 4 元可以增加 20 天的订阅天数。 因此，我总共花了12.9+4=16.9元，获取了1+90+20 = 111天的订阅天数。 公司的业务系统在每个订单充值时自动计算未来各月消耗，计算的方法为： 先消耗免费时长，不分摊金额，因此上表中有个 startTime 订单开始时间是从 1 月 3 号开始。 然后，从 startTime 开始计算未来所有月份的消耗，分摊金额为TotalFee - additionPrices，即加价购的不参与这段期间的分摊。 最后，再将加价购的金额分摊给加价购买天数。 系统每个月会生成消耗报表，对于这个订单来说，系统生成的消耗报表为： 月份 消耗 结余 2023-01 401 1289 2023-02 401 888 2023-03 444 444 2023-04 444 0 总共订单数据量大概7000多万 。 这里我们首先需要验证下报表的准确性，即从订单数据出发按照系统计算逻辑计算后，与每月报表做比较。 其次，我们还需要按照会计准则的要求将总费用按照总天数平均分摊，看与报表的差异金额，是否达到重要性水平。 ","date":"2023-07-13","objectID":"/posts/20230712221905-%E8%AE%A2%E9%98%85%E5%88%B6%E6%94%B6%E5%85%A5%E5%88%86%E6%91%8A%E6%B5%8B%E7%AE%97/:1:0","tags":["duckdb"],"title":"订阅制收入分摊测算","uri":"/posts/20230712221905-%E8%AE%A2%E9%98%85%E5%88%B6%E6%94%B6%E5%85%A5%E5%88%86%E6%91%8A%E6%B5%8B%E7%AE%97/"},{"categories":["工作"],"content":"系统报表逻辑验证 这里我们先不考虑加价购买的情况，只考虑正常购买的消耗问题。 这也是数学中化归思想，先将复杂问题化归成简单问题，待简单问题解决后，再进行深入探讨。 假设我们计算 2023 年 1 月的应当消耗的金额。 如图所示，开始日为2023-01-01,结束日为2023-01-31. startTime=2023-01-03 22:25:36 endTime=2023-01-03 22:25:36 + 90 day 需要摊销的金额为 TotalFee - additionPrices = 1290 我们知道需要摊销的金额，这里的关键就是计算消耗期间，而这个期间的计算可以总结为下面公式： min(endTime, 结束日) - max(startTime, 开始日) 看到这个公式第一眼你可能不理解，没关系，你可以带入一些值去思考。 例如min(endTime,结束日) 就是报表期间结束日和订阅时间结束的较小值，这里报表期间结束日是2023-01-31 ，而订阅结束的日期肯定是大于 1 月的，所以取值为2023-01-31。 同样max(startTime,开始日) 就是报表期间开始日和订阅时间开始的较大值，这里报表期间开始日是2023-01-01, 而订阅时间开始日是2023-01-03所以取值是2023-01-03。 那么，min(endTime,结束日) - max(startTime, 开始日) 就是31-2 = 29天。 ( 注：系统规定充值当天不足一天，不计入摊销，所以实际这里是 28 天，可以考虑通过计算小时数/24, 再向下取整得到正确的值） 当然，你还可以想象一订阅期间在报表期间不同位置的情况，也可以验证这个公式的正确性。 接下来，我们就可以使用 DuckDB 中写 SQL 语句了（注：数据量较大，考虑使用 DuckDB 计算） with a as ( select startTime,payType,totalFee,creatTime,accelDays,additionDays,additionPrices, GREATEST(startTime,DATE '2023-01-01 00:00:00') beginTime, LEAST(startTime + interval 1 day * accelDays,DATE '2023-02-01 00:00:00') endTime from your_table ) select payType,sum(cast(totalFee-additionPrices as float)/accelDays * calcDays)/100 AS money from ( select *,date_diff('hour',beginTime, case when date_trunc('day', endTime) = endTime then endTime else date_trunc('day', endTime + INTERVAL '1 day') end )/24 calcDays from a where endTime\u003e=beginTime ) t group by payType order by payType 这里对上述 SQL 几处关键地方进行解释： GREATEST(startTime,DATE '2023-01-01 00:00:00') beginTime ，这里就是前面公式max(startTime,开始日) ，其中GREATEST函数是取两个数的较大值，将计算结果重命名为 beginTime LEAST(startTime + interval 1 day * accelDays,DATE '2023-02-01 00:00:00') endTime ，就里就是前面公式min(endTime,结束日) ，其中LEAST函数是取两个数的较小值，将计算结果重命名为 endTime cast(totalFee-additionPrices as float) 将待分摊的费用，转为float数据类型，如果不转换的话，在 DuckDB 导入数据时自动将数据识别为整形Int, 这样后面在进行除法时会丢失精度，造成计算结果的不准确。 date_diff('hour',beginTime, case when date_trunc('day', endTime) = endTime then endTime else date_trunc('day', endTime + INTERVAL '1 day') end )/24 calcDays 这里一长串实际就是求beginTime与 endTime 的间隔天数，但这个结束时间使用了case when语句进行判断，将 endTime 没有小时、分钟的时候使用endTime，如果有分钟的话就需要加 1 天，计算出两个时间的间隔小时数后除以24 ，由于小时数是整形，所以除法的时候就是自动向下取整。 这里是比较巧妙、简洁的作法，主要是考虑到了订阅开始日和结束日分别在报表期间的情况，能够正确计算当期天数。 如果你看懂了上面正常购买金额的摊销，那么加价购买的摊销与之是相同算法, 无非是开始日从startTime变成了startTime+accelDays,结束日从startTime+accelDays变成了startTime + accelDays +additionDays，然后把待分摊的金额变成了 additionPrices: with a as ( select startTime,payType,totalFee,creatTime,accelDays,additionDays,additionPrices, GREATEST(startTime+ interval 1 day * accelDays,DATE '2023-01-01 00:00:00') beginTime, LEAST(startTime + interval 1 day * (accelDays+additionDays),DATE '2023-02-01 00:00:00') endTime from yourtable ) select payType,sum(cast(additionPrices as float)/additionDays * calcDays)/100 AS money from ( select *,date_diff('hour',beginTime, case when date_trunc('day', endTime) = endTime then endTime else date_trunc('day', endTime + INTERVAL '1 day') end )/24 calcDays from a where endTime\u003e=beginTime ) t group by payType order by payType 上面我们是计算的 2023 年 1 月消耗金额，我们实际上可以计算任意期间的消耗金额，只需要将对应日期进行改变。 我们甚至可以不分月，直接求一整年的金额。 ","date":"2023-07-13","objectID":"/posts/20230712221905-%E8%AE%A2%E9%98%85%E5%88%B6%E6%94%B6%E5%85%A5%E5%88%86%E6%91%8A%E6%B5%8B%E7%AE%97/:2:0","tags":["duckdb"],"title":"订阅制收入分摊测算","uri":"/posts/20230712221905-%E8%AE%A2%E9%98%85%E5%88%B6%E6%94%B6%E5%85%A5%E5%88%86%E6%91%8A%E6%B5%8B%E7%AE%97/"},{"categories":["工作"],"content":"按收入准则重新计算 上述计算过程，是我们按照系统报表逻辑计算的。如果按收入准则，我们可以将总金额平均分摊到所有订阅天数（包括免费赠送的和加价购的）。 这个计算方法和上述过程几乎一样，无非是改变了分摊金额和开始日、结束日，这里不再演示。 ","date":"2023-07-13","objectID":"/posts/20230712221905-%E8%AE%A2%E9%98%85%E5%88%B6%E6%94%B6%E5%85%A5%E5%88%86%E6%91%8A%E6%B5%8B%E7%AE%97/:3:0","tags":["duckdb"],"title":"订阅制收入分摊测算","uri":"/posts/20230712221905-%E8%AE%A2%E9%98%85%E5%88%B6%E6%94%B6%E5%85%A5%E5%88%86%E6%91%8A%E6%B5%8B%E7%AE%97/"},{"categories":["工作"],"content":"结语 本文对订阅制销售模式的收入计算进行了详细介绍，由此可以看出依托互联网销售的企业，高度依赖信息系统。 对于这类企业，在财务审计过程中，如果只简单听取财务对计算方法的介绍，是不足的。 甚至你抽取一些订单穿行测试也是不足的，因为很可能你都不知道系统在销售活动中有免费赠送和加价购的情况，自然不清楚其收入计算逻辑。 如果直接对这类高度依赖信息系统企业的业务系统报表直接利用，可能会存在审计风险。 需要我们利用 IT 审计的工作，对系统计算逻辑以及其产生报表进行验证。 若有 IT 审计业务需求，可以联系工作邮箱： tujiabing_cd@shinewing.com ","date":"2023-07-13","objectID":"/posts/20230712221905-%E8%AE%A2%E9%98%85%E5%88%B6%E6%94%B6%E5%85%A5%E5%88%86%E6%91%8A%E6%B5%8B%E7%AE%97/:4:0","tags":["duckdb"],"title":"订阅制收入分摊测算","uri":"/posts/20230712221905-%E8%AE%A2%E9%98%85%E5%88%B6%E6%94%B6%E5%85%A5%E5%88%86%E6%91%8A%E6%B5%8B%E7%AE%97/"},{"categories":["工作"],"content":"在上一篇文章中讲到了习惯的改变， 在接下来的半年时间里，在学习和项目过程中，我将会重新梳理下自己的学习系统。 关于这方面的文章大概是 2018 年的时候写过一些，那个时候主要是总结如何考 CPA 方面的文章。 其实除了考试之外，工作过程中还是有大量的知识需要学习， 但这种目标性可能并没有要通过一门考试来得具体和清晰， 所以对于很多人来说，没有考试的时候，就没有方向了，就停滞了。 但工作中，很多时候明显能感觉到，某些方面的专业知识自己欠缺，需要静下心来，抽出时间来学习，专研。 这其实就需要我们掌握学习的方法。 我后面可能想写的学习系统主要包含三个方面： 输入 记忆 输出 第一，“输入”主要指初次学习时如何理解，消化。使用的工具主要是费曼技巧和逻辑等式。 费曼技巧既是检验自己是否真正理解的测量仪，同时也是尝试去理解知识的具体方法。 逻辑等式是梳理一门知识的底层逻辑，内在含义，真正理解它，记忆它的工具箱。 第二，“记忆”主要是指在理解消化了知识后，如何长期将其内化在自己心中，化为我用。 这里主要使用间隔记忆软件 Anki 。它不仅是考试的一个利器，也是主动掌握一门知识的大杀招。 当然，这需要建立在第一点“输入”的基础上，没有“输入”的消化理解，这样会适得其反。 第三，“输出”主要指用笔记工具打造自己第二大脑，通过写笔记辅助自己思考，深化理解。 这里主要使用双链笔记，如 Obsidian ， org-roam 这类工具。 工具是其次，主要是如何写笔记。 以上是我认为是个人比较实用的学习系统，在后面的较长的时间里，我会通过学习知识来重新梳理、总结这个流程，以及具体使用的操作方法。 在这个过程中，如果有一些比较好的心得，会发一些相关文章进行总结分享。 ","date":"2023-07-10","objectID":"/posts/20230710221028-%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F/:0:0","tags":["学习方法"],"title":"学习系统","uri":"/posts/20230710221028-%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F/"},{"categories":["工作"],"content":"半年过去了，自己想做的一些事还处于停滞状态。 虽然经常给自己找理由，每天工作很忙，还有各种乱七八糟的事，但实际上我还是浪费了大量时间。 人往往是只关注结果的，就像大家只想一步成功，只想赚快钱一样。 这就和打球时一直盯着记分牌一样可笑。 越是关注结果，往往结果越差。 一旦，实际与你预想的有一点偏差，可能你就想摆烂了。 打一场球，应该更加关注平时训练中的基础体能、基础技术、基础战术、团队配合。 最终的比分，只是这一系列长期的结果。 所以，应该改变自己的习惯，通过小步子原理改变自己的习惯。 这些习惯会引导自己的行动，而结果只是所有这些行动的必然表现。 ","date":"2023-07-09","objectID":"/posts/20230708233324-%E4%B9%A0%E6%83%AF%E6%94%B9%E5%8F%98/:0:0","tags":["学习方法"],"title":"习惯改变","uri":"/posts/20230708233324-%E4%B9%A0%E6%83%AF%E6%94%B9%E5%8F%98/"},{"categories":["工作"],"content":"我们时常听人说“要多思考，多思考……” 然而，很多时候我们并不知道什么叫多思考，怎么做叫多思考，甚至我已经觉得思考得够多了。 如果你也有这样的困惑，我建议你写笔记。 把你阅读、工作、生活、学习时脑海中产生的想法、观点、思维记录下来。 当你尝试这么去做的时候，你将审视你脑海中虚无飘渺、似是而非的想法， 你会发现，原来有些东西我并没有想清楚， 你会发现，以前模糊的东西，在思考后更加清楚了。 这个笔记不是思考过程的记录，而是思考的本身， 它就是一个思考工具。 昨天看到两个比较好的关于记笔记的视频，分享大家： 神奇的笔记法！你也能轻松开始写作【卡片笔记写作法】_哔哩哔哩_bilibili 卡片笔记实战！用 flomo 搭建我整个知识系统_哔哩哔哩_bilibili 推荐使用的笔记工具是开源免费的Obsidian 。 ","date":"2023-05-31","objectID":"/posts/20230531222527-%E5%A6%82%E4%BD%95%E9%94%BB%E7%82%BC%E8%87%AA%E5%B7%B1%E7%9A%84%E6%80%9D%E8%80%83%E8%83%BD%E5%8A%9B/:0:0","tags":["卡片笔记"],"title":"如何锻炼自己的思考能力","uri":"/posts/20230531222527-%E5%A6%82%E4%BD%95%E9%94%BB%E7%82%BC%E8%87%AA%E5%B7%B1%E7%9A%84%E6%80%9D%E8%80%83%E8%83%BD%E5%8A%9B/"},{"categories":["工作"],"content":"审计工作，或者任何需要专业知识的工作，都需要积累专业知识和项目经验。 我们时常羡慕别人渊博的知识，侃侃而谈的经验，而这些都是一点一滴的积累。 同样是一样的工作时长，同样是一样的学习时长， 为什么知识就像汹涌的海浪拍打在沙滩上，潮水退去后，没有了任何踪迹？ 我个人感受，主要有两点原因： 没有思考。 没有对思考的结果进行组织。 我们对一个知识常常当时感觉懂了，过一段时间就回想不起来。或者是审计工作中完成了一个科目的底稿，负责人问你这个科目的金额是多少都不知道。 为什么呢？ ","date":"2023-05-25","objectID":"/posts/20230525224610-%E4%B8%93%E4%B8%9A%E4%BA%BA%E5%A3%AB%E9%9C%80%E8%A6%81%E6%89%93%E9%80%A0%E8%87%AA%E5%B7%B1%E7%9A%84%E7%AC%94%E8%AE%B0%E7%B3%BB%E7%BB%9F/:0:0","tags":["卡片笔记"],"title":"专业人士需要打造自己的笔记系统","uri":"/posts/20230525224610-%E4%B8%93%E4%B8%9A%E4%BA%BA%E5%A3%AB%E9%9C%80%E8%A6%81%E6%89%93%E9%80%A0%E8%87%AA%E5%B7%B1%E7%9A%84%E7%AC%94%E8%AE%B0%E7%B3%BB%E7%BB%9F/"},{"categories":["工作"],"content":"存储强度与提取强度 要知道，我们对于记忆的提取强度与 存储强度 相关。当我们存储的强度越高，经过了反复思考的知识，在今后提取的时候越容易。 当我们对于报表科目，只是当成一个冷冰冰的数字的时候，它就像一滴水掠过你的脑海，很难留下痕迹。 当你把它和了解的企业经营情况，或者听闻的、想像的故事去产生联系。 或者多想了些为什么变动很大的原因等等一切能增加存储强度的时候，会发现当你需要的时候你能很容易回想起它。 ","date":"2023-05-25","objectID":"/posts/20230525224610-%E4%B8%93%E4%B8%9A%E4%BA%BA%E5%A3%AB%E9%9C%80%E8%A6%81%E6%89%93%E9%80%A0%E8%87%AA%E5%B7%B1%E7%9A%84%E7%AC%94%E8%AE%B0%E7%B3%BB%E7%BB%9F/:1:0","tags":["卡片笔记"],"title":"专业人士需要打造自己的笔记系统","uri":"/posts/20230525224610-%E4%B8%93%E4%B8%9A%E4%BA%BA%E5%A3%AB%E9%9C%80%E8%A6%81%E6%89%93%E9%80%A0%E8%87%AA%E5%B7%B1%E7%9A%84%E7%AC%94%E8%AE%B0%E7%B3%BB%E7%BB%9F/"},{"categories":["工作"],"content":"知识的组织 单个的知识的习得是比较容易的。 随着时间的积累，这将变得散乱，或者说完全依靠自己大脑的能力。 这将需要我们拥有一个笔记系统，它能将我们的专业知识、项目经验组织起来。 就像一粒粒的珍珠，用一根线串成项链。 我们很多人都是忽略笔记系统的。前两周组织我们部门培训，给新员工培训了基础知识，我发现大家都是不记笔记的。 我不清楚听完后还能剩下多少。 ","date":"2023-05-25","objectID":"/posts/20230525224610-%E4%B8%93%E4%B8%9A%E4%BA%BA%E5%A3%AB%E9%9C%80%E8%A6%81%E6%89%93%E9%80%A0%E8%87%AA%E5%B7%B1%E7%9A%84%E7%AC%94%E8%AE%B0%E7%B3%BB%E7%BB%9F/:2:0","tags":["卡片笔记"],"title":"专业人士需要打造自己的笔记系统","uri":"/posts/20230525224610-%E4%B8%93%E4%B8%9A%E4%BA%BA%E5%A3%AB%E9%9C%80%E8%A6%81%E6%89%93%E9%80%A0%E8%87%AA%E5%B7%B1%E7%9A%84%E7%AC%94%E8%AE%B0%E7%B3%BB%E7%BB%9F/"},{"categories":["工作"],"content":"思考工具 前面推荐过卡片盒笔记 ，它更像是一个思考工具，将我们习得的知识和经验输出成笔记，而不是摘抄或复制。 自己有的心得体会，当你用笔尝试写下来的时候，你才会发现自己似乎还有哪些没有明白。 你才会发现这个知识点似乎和之前学过的知识点之间有哪些联系。 当你记笔记的时候，将强迫自己思考，增加知识的存储强度。 所以说，它是一个思考系统，同时也是一个写作系统。 当我们不断与这个思考系统对话，产生的卡片笔记达到一定数量的时候，它才会显现出强大的作用， 这种作用是笔记与笔记之间逻辑关联生成的效用。 ","date":"2023-05-25","objectID":"/posts/20230525224610-%E4%B8%93%E4%B8%9A%E4%BA%BA%E5%A3%AB%E9%9C%80%E8%A6%81%E6%89%93%E9%80%A0%E8%87%AA%E5%B7%B1%E7%9A%84%E7%AC%94%E8%AE%B0%E7%B3%BB%E7%BB%9F/:3:0","tags":["卡片笔记"],"title":"专业人士需要打造自己的笔记系统","uri":"/posts/20230525224610-%E4%B8%93%E4%B8%9A%E4%BA%BA%E5%A3%AB%E9%9C%80%E8%A6%81%E6%89%93%E9%80%A0%E8%87%AA%E5%B7%B1%E7%9A%84%E7%AC%94%E8%AE%B0%E7%B3%BB%E7%BB%9F/"},{"categories":["工作"],"content":"审计师对于清Q一点都不陌生了。 出 Q 与清Q:意思就是senior/manager/partner在 review paper 的时候提出问题，出这些问题就是出 Q 。出完 Q要有人回答这些问题，这个过程叫做清 Q 。 很多人在答 Q 的时候心里都想着：“栓 Q ”，机械地答完后就了事了，其实并没有什么收获。 当然，随着时间的积累，慢慢的你也许会去理解别人为什么要问这个问题，同时也就衍生出今后应该怎么做比较合适。 我感觉清 Q 的这个过程，如果用心的话，是能迅速进步，并获取专业知识和经验。 毕竟从前辈的问题中，可以理解这个问题是什么，为什么，以及自己应当怎么做。 ","date":"2023-05-22","objectID":"/posts/20230522233232-%E5%83%8F%E6%B8%85q%E4%B8%80%E6%A0%B7%E9%97%AE%E8%87%AA%E5%B7%B1/:0:0","tags":["杂文"],"title":"像清Q一样问自己","uri":"/posts/20230522233232-%E5%83%8F%E6%B8%85q%E4%B8%80%E6%A0%B7%E9%97%AE%E8%87%AA%E5%B7%B1/"},{"categories":["工作"],"content":"不求其解 人都是会懒惰的，很少有人愿意主动去思考，探索，求教。 很多人就是拿着上年底稿，完成一个完形填空。 I learned very early the difference between knowing the name of something and knowing something. –Richard Philip Feynman 也许你习以为常的东西，这些名词天天重复在你的耳边，你以为你很懂了，其实并没有懂，因为你重来就没有思考过，也无法提出高质量的问题。 就像费曼说的他很早就知道知道一个事物的名字和知道一个事物的区别。 所以，我们也可以尝试模拟出 Q 的人，多向自己问一些问题。 这个概念是什么？ 为什么要这么做？ 不这样做会出什么问题？ 我还可以有什么更快的方法？ …… 当你出了这样一个一个Q ，然后通过自己探索或者请教别人把这些 Q 清掉的时候， 你会发现，自己的进步日新月异。 ","date":"2023-05-22","objectID":"/posts/20230522233232-%E5%83%8F%E6%B8%85q%E4%B8%80%E6%A0%B7%E9%97%AE%E8%87%AA%E5%B7%B1/:1:0","tags":["杂文"],"title":"像清Q一样问自己","uri":"/posts/20230522233232-%E5%83%8F%E6%B8%85q%E4%B8%80%E6%A0%B7%E9%97%AE%E8%87%AA%E5%B7%B1/"},{"categories":["工作"],"content":"知其所以然 平时复核时，听到最多的话就是：“去年底稿就是这样做的。” 费曼曾说过： 一般民众的态度是想要找到答案，而不是想要找到有方法获得答案的人。 –理查德·菲利普·费曼 如果只是想不加思考重复别人的工作，甚至是错误的工作，那么你也是一个只想要一个所谓的答案或者结果的人。 然而，这个工作最让人着迷或者有价值的却是获取这个结果所用到的方法以及思辩的过程。 所以，像清 Q 一样问自己吧。 ","date":"2023-05-22","objectID":"/posts/20230522233232-%E5%83%8F%E6%B8%85q%E4%B8%80%E6%A0%B7%E9%97%AE%E8%87%AA%E5%B7%B1/:2:0","tags":["杂文"],"title":"像清Q一样问自己","uri":"/posts/20230522233232-%E5%83%8F%E6%B8%85q%E4%B8%80%E6%A0%B7%E9%97%AE%E8%87%AA%E5%B7%B1/"},{"categories":["生活"],"content":"这周我媳妇去面试了两次。 一次是去一家卖猪饲料的公司，这家公司要在成都成立个办公室，要招三个人，分别是运营、销售、财务的岗位。 一聊，她是农大毕业的，把从小到大家里用过的饲料牌子都说了一遍，面试的 HR 惊喜的说“对，对，对，你太适合我们公司了。” 说到财务，她就是会计专业的， HR 感觉很合适，不过我媳妇就干过一、两年的财务，都还没有轮岗完过，家里带娃这几年，会计知识早忘光了。 公司也不会有人教，自己要做全盘账。 HR怂恿她花几千块钱去上个短期培训班，我心想工资就 4000 块，每天通勤半程就1.5H ，受这罪干嘛？ 后面又聊到运营岗位，我媳妇说自己运营过公众号，又吹了一通短视频，吸粉、拉新、转化， HR 感觉她又很适合。 不过，回来我们想一想，每天工作 9 点到下午 6 点，通勤 3 个小时， 4000 块，真是看不上。 过了两天，她又和我大学同学的媳妇（凤姐）去参加了场军属专项招聘会，大多是什么销售、客服的一些不太好的工作机会。 虽然工资都是三、四千左右，但要求还不怎么低。 凤姐本身是做培训的，虽然这两年行业不怎么好，但是自己上一节课也是 400 起，这些工作 4000 一个月，还要这要那的。。。。。。 还找个毛工作，还不如自己挣钱算了。 像我媳妇这样，结婚后为了带两个娃，就离开职场了，把两个娃送上小学，再想返回职场就太难了。 这个难，主要两方面原因： 没有专业经验，只能去找初级的工作，这些工作的薪资和需要的付出在这个年龄阶段，很难再接受了。因为不可能再像刚毕业那会儿不在乎工资地拼搏，需要工作和家庭的平衡。 另外，这些公司对于两个娃的母亲本身就会带着怀疑的眼光，很难愿意提供一些好的机会了，宁愿用一张白纸的年轻人。 我妈以前经常给我讲：“费力不挣钱，挣钱不费力。” 果真如此。 生活真不容易。 ","date":"2023-05-21","objectID":"/posts/20230520223558-%E6%89%BE%E5%B7%A5%E4%BD%9C/:0:0","tags":["杂文"],"title":"找工作","uri":"/posts/20230520223558-%E6%89%BE%E5%B7%A5%E4%BD%9C/"},{"categories":["生活"],"content":"出差路上读了《了不起的我》[1]一小部分，尚未读完，不过先做一下感想记录。 ","date":"2023-05-16","objectID":"/posts/20230515235147-%E4%BA%86%E4%B8%8D%E8%B5%B7%E7%9A%84%E6%88%91/:0:0","tags":["读书笔记"],"title":"了不起的我","uri":"/posts/20230515235147-%E4%BA%86%E4%B8%8D%E8%B5%B7%E7%9A%84%E6%88%91/"},{"categories":["生活"],"content":"小步子原理 “小步子原理”，简单来说，就是在改变的路上迈出小小的一步，获得一个小小的成功。让每一次的小成功，成为下一次改变的基础。 “小步子原理”不只是一个关于如何获得最终成功的策略，更是一个关于让自己有所行动的策略。 我们平常生活中功利心太重，如果提及改变，默认想要改变的是一种结果。 比如，我想成为学霸，我想成功，我想有钱等等。就算去求神拜佛，要么求升官发财，要么求远离病痛疾苦，这些都是一种结果。 这种结果的改变和我们的现状比起来，更像是一种巨变，如此之大的变化，将产生巨大的恐惧和焦虑，这种想要的改变反而变成了我们思想上的枷锁，阻碍我们迈出步伐。 而这里的“小步子原理”指的改变是我们的行为，不再意结果的行动上的变化。这种微小变化，不会让我们产生过多的恐惧。 就像电影《三傻大闹宝莱坞》中主角兰彻说的： “Follow Excellence. Success will chase you.\" [2] 当我们追求卓越，成功将会追随我们。 它的重点不是结果，而是此时此地的行动。它的核心思想，就是古希腊斯多葛学派的主张： “努力控制你所能控制的事情，并接纳你不能控制的事情。” 当我看到这里时，如遭雷击，我似乎找到自己时常焦虑、痛苦的原因了。当一件事，超出我掌握范围，又想将其做好时，我所想的都是结果，也就是在想象“好的结果”与“坏的结果”的发生。 这就是一直困扰我的地方，当按照作者的思路去想：努力控制自己的控制的事情，接受自己并不能控制事情的结果，似乎焦虑都会消失了。 这和王阳明心学中“心外无物”相似，我的心里装着宇宙的真理，心外别无他物。 ","date":"2023-05-16","objectID":"/posts/20230515235147-%E4%BA%86%E4%B8%8D%E8%B5%B7%E7%9A%84%E6%88%91/:1:0","tags":["读书笔记"],"title":"了不起的我","uri":"/posts/20230515235147-%E4%BA%86%E4%B8%8D%E8%B5%B7%E7%9A%84%E6%88%91/"},{"categories":["生活"],"content":"环境场原理 我曾把生活的乐趣分为两种：消费型快乐和创造型快乐。 在消费型快乐里，你消费的是别人创造的产品，满足的是表面上的感官刺激； 而在创造型快乐里，你在创造自己的产品。你在发挥自己的才能，辛苦地工作。在这个过程中，你会体会到一种深刻的成就感，一种自己正在变得更好的感觉。 平时周围朋友会问我哪来的时间写公众号，研究一些东西。 看到这时我才突然明白，我其实和大家是一样的，同样的上班、吃饭、睡觉、娱乐。 唯一的区别就是我们娱乐方式是“创造型快乐”，没事的时候就会折腾下程序、工具以及一些有趣的东西，同时在这个过程中会把折腾的过程通过公众号或者视频的方式记录分享。 这基本上就是我的一种娱乐方式，对我来说，这种娱乐收获的快乐比直接刷剧、旅游、游戏等感官上的快乐，更深入心灵和持久。 作者提到如果要将消费型快乐转向创造型快乐，需要给自己创造一个学习或者工作氛围浓厚的**“场”**。 而我自己就是误打误撞地创造了这样一种“场”，它不是指学习或工作所在的实体空间，而是“折腾 - 记录 - 输出 - 赞扬”的虚拟空间。 我一直沉浸在自己的“场”中，期待着这个循环产生的快乐。 ","date":"2023-05-16","objectID":"/posts/20230515235147-%E4%BA%86%E4%B8%8D%E8%B5%B7%E7%9A%84%E6%88%91/:2:0","tags":["读书笔记"],"title":"了不起的我","uri":"/posts/20230515235147-%E4%BA%86%E4%B8%8D%E8%B5%B7%E7%9A%84%E6%88%91/"},{"categories":["生活"],"content":"参考资料 ","date":"2023-05-16","objectID":"/posts/20230515235147-%E4%BA%86%E4%B8%8D%E8%B5%B7%E7%9A%84%E6%88%91/:3:0","tags":["读书笔记"],"title":"了不起的我","uri":"/posts/20230515235147-%E4%BA%86%E4%B8%8D%E8%B5%B7%E7%9A%84%E6%88%91/"},{"categories":["工作"],"content":"前两篇介绍了 duckdb 的安装与导入，阅读量太低，大部分读者都不感兴趣。 今天再用一个实际案例介绍如何进行分析，暂告一个段落。 我们用 scrapy 从“注册会计师行业统一监管平台”获取执业注册会计师信息、会计师事务所信息（数据截止：2023-04-26)。 一共三张表： 文件名 名称 agent.csv 会计师事务所信息 user.csv 执业CPA信息 fensuo.csv 总所与分所对应关系 数据下载链接： https://wwds.lanzoum.com/iWf3M0v0s9kj ","date":"2023-05-09","objectID":"/posts/20230508214520-%E6%89%A7%E4%B8%9A%E6%B3%A8%E5%86%8C%E4%BC%9A%E8%AE%A1%E5%B8%88%E7%BB%9F%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/:0:0","tags":["duckdb"],"title":"执业注册会计师统计与分析","uri":"/posts/20230508214520-%E6%89%A7%E4%B8%9A%E6%B3%A8%E5%86%8C%E4%BC%9A%E8%AE%A1%E5%B8%88%E7%BB%9F%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"数据导入 create table cpa as select * from read_csv_auto('/home/nigo/Documents/code/cpa/cpa/user.csv'); create table agent as select * from read_csv_auto('/home/nigo/Documents/code/cpa/cpa/agent.csv'); create table relation as select * from read_csv_auto('/home/nigo/Documents/code/cpa/cpa/fensuo.csv'); 选中要执行的语句（多条语句之间用分号分隔），点击“执行”按钮。 将三个文件导入为：cpa,agent,relation 三张表。 下面结合已有数据进行多维度分析（注：SQL 语句大小写不敏感，大写和小写是等同的） ","date":"2023-05-09","objectID":"/posts/20230508214520-%E6%89%A7%E4%B8%9A%E6%B3%A8%E5%86%8C%E4%BC%9A%E8%AE%A1%E5%B8%88%E7%BB%9F%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/:1:0","tags":["duckdb"],"title":"执业注册会计师统计与分析","uri":"/posts/20230508214520-%E6%89%A7%E4%B8%9A%E6%B3%A8%E5%86%8C%E4%BC%9A%E8%AE%A1%E5%B8%88%E7%BB%9F%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"执业CPA人数 select count(distinct cpa_cno) from cpa where cpa_status!=21 ( 注：cpa_status – 10:正常，31:协会代管，21:已注销， 51 ：协会代管） 执行结果： 102039 SELECT count(distinct cpa_cno): 查询结果是cpa_cno字段的去重数量，使用count()聚合函数统计数量。distinct 关键字表示去重，只统计不同的值。 FROM cpa: 从 cpa 表中查询数据。 WHERE cpa_status!=21: 使用 WHERE 子句筛选条件，排除cpa_status等于 21 的记录。!= 表示不等于。 相关知识点： 聚合函数：SQL 中的聚合函数是用来统计和汇总数据的函数，例如 count 、sum、 avg 、max、 min 等。在 SELECT 查询语句中，聚合函数通常和GROUP BY子句一起使用，对分组数据进行聚合计算。 DISTINCT 关键字：用于去重，只保留不同的数据。 WHERE 子句：用于在查询中筛选数据，只返回符合条件的数据。可以使用比较运算符（如=、!=、\u003c、\u003e、\u003c=、\u003e=）、逻辑运算符（如 AND 、OR、 NOT ）以及通配符（如%、_）等进行条件筛选。 ","date":"2023-05-09","objectID":"/posts/20230508214520-%E6%89%A7%E4%B8%9A%E6%B3%A8%E5%86%8C%E4%BC%9A%E8%AE%A1%E5%B8%88%E7%BB%9F%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/:2:0","tags":["duckdb"],"title":"执业注册会计师统计与分析","uri":"/posts/20230508214520-%E6%89%A7%E4%B8%9A%E6%B3%A8%E5%86%8C%E4%BC%9A%E8%AE%A1%E5%B8%88%E7%BB%9F%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"历年注册及注销人数 ","date":"2023-05-09","objectID":"/posts/20230508214520-%E6%89%A7%E4%B8%9A%E6%B3%A8%E5%86%8C%E4%BC%9A%E8%AE%A1%E5%B8%88%E7%BB%9F%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/:3:0","tags":["duckdb"],"title":"执业注册会计师统计与分析","uri":"/posts/20230508214520-%E6%89%A7%E4%B8%9A%E6%B3%A8%E5%86%8C%E4%BC%9A%E8%AE%A1%E5%B8%88%E7%BB%9F%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"历年注销人数 select year(dereg_date) 年度,count(distinct cpa_cno) 注销人数 from cpa where dereg_date is not null group by year(dereg_date) order by year(dereg_date) 相关知识点 ： GROUP BY 子句：用于将查询结果按照指定的列进行分组。在 SELECT 查询语句中，GROUP BY 子句通常和聚合函数一起使用，对分组数据进行聚合计算。 ORDER BY 子句：用于对查询结果进行排序。可以使用 ASC（升序，默认值）或 DESC（降序）关键字指定排序方式。 year() 函数：用于从日期/时间中提取年份。在 duckdb 中，可以使用year()函数获取日期/时间字段的年份部分。 ","date":"2023-05-09","objectID":"/posts/20230508214520-%E6%89%A7%E4%B8%9A%E6%B3%A8%E5%86%8C%E4%BC%9A%E8%AE%A1%E5%B8%88%E7%BB%9F%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/:3:1","tags":["duckdb"],"title":"执业注册会计师统计与分析","uri":"/posts/20230508214520-%E6%89%A7%E4%B8%9A%E6%B3%A8%E5%86%8C%E4%BC%9A%E8%AE%A1%E5%B8%88%E7%BB%9F%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"历年注册人数 select year(regis_date) 年度,count(distinct cpa_cno) 注册人数 from cpa where year(regis_date)\u003e2000 group by year(regis_date) order by year(regis_date) 点击表格左上角区域可以选择整个表格，也可以单独选中某一行，某一列，也可以按住 Shift 键选中多行、多列。Ctrl+c 复制数据，可以直接粘贴到 excel 中。 我们用当前注师人数+注销人数 - 注册人数去计算上年的注师人数。不过越往前，数据可能越不准。 我是 2016 年入所的，当时执业注师差不多是 10 万人，非执业和执业总数差不多 20 万。这几年过去了注师还是 10 万人，非执业和执业的总共33.4万人了（ 2023年 4 月23日）。 这几年，都新增多少家上市公司了，注师人数还是不变，可见这行早已经不吸引人了。 尤其是 2021 年注销了21,644人，当年人数负增长，估计是当时清理挂靠的人员。 ","date":"2023-05-09","objectID":"/posts/20230508214520-%E6%89%A7%E4%B8%9A%E6%B3%A8%E5%86%8C%E4%BC%9A%E8%AE%A1%E5%B8%88%E7%BB%9F%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/:3:2","tags":["duckdb"],"title":"执业注册会计师统计与分析","uri":"/posts/20230508214520-%E6%89%A7%E4%B8%9A%E6%B3%A8%E5%86%8C%E4%BC%9A%E8%AE%A1%E5%B8%88%E7%BB%9F%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"执业注师地域分布 select division_name 省份,count(distinct cpa_cno) 注师人数 from cpa where cpa_status!=21 group by division_name order by count(distinct cpa_cno) desc; 执行结果： 省 人数 北京市 12023 上海市 8200 浙江省 7105 江苏省 6955 广东省 6815 山东省 6381 四川省 5107 河南省 4269 深圳市 4243 湖北省 3716 辽宁省 3272 湖南省 3183 河北省 3036 安徽省 2988 福建省 2803 山西省 2412 陕西省 2407 重庆市 2013 天津市 1812 吉林省 1658 云南省 1624 黑龙江省 1549 内蒙古自治区 1447 广西壮族自治区 1325 江西省 1296 贵州省 1019 新疆维吾尔自治区 982 甘肃省 831 海南省 685 宁夏回族自治区 361 青海省 275 西藏自治区 247 前 7 的北京、上海、浙江、江苏、广东、山东、四川人数就占了51.54% ，除了四川是中西部省份，其余都是沿海省份。 所以，想在事务所找工作的在这些注师人数多的地方相对更容易些。 ","date":"2023-05-09","objectID":"/posts/20230508214520-%E6%89%A7%E4%B8%9A%E6%B3%A8%E5%86%8C%E4%BC%9A%E8%AE%A1%E5%B8%88%E7%BB%9F%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/:4:0","tags":["duckdb"],"title":"执业注册会计师统计与分析","uri":"/posts/20230508214520-%E6%89%A7%E4%B8%9A%E6%B3%A8%E5%86%8C%E4%BC%9A%E8%AE%A1%E5%B8%88%E7%BB%9F%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"注销注师执业年限分析 select year(dereg_date) 年度,avg(date_diff('year',regis_date,dereg_date)) 执业年数 from cpa where dereg_date is not null and regis_date is not null group by year(dereg_date) order by year(dereg_date) 相关知识点 ： date_diff() 函数：用于计算两个日期/时间之间的差值。在 SQL 中，可以使用date_diff()函数获取两个日期/时间字段之间的差值，常见的计算类型包括 year 、month、 day 、hour、 minute 、second等。 avg()平均值函数：在 SQL 中，可以使用avg()函数计算指定列的平均值。在本查询语句中，使用avg()函数计算每年执业年数的平均值。 执行结果： 可以看出离开事务所的执业注师的执业年限越来越大，不知道这是否代表几年前，执业注师面临的外部机遇更好，趁着年轻就走了；还是说事务所吸引人才的能力更强了。 ","date":"2023-05-09","objectID":"/posts/20230508214520-%E6%89%A7%E4%B8%9A%E6%B3%A8%E5%86%8C%E4%BC%9A%E8%AE%A1%E5%B8%88%E7%BB%9F%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/:5:0","tags":["duckdb"],"title":"执业注册会计师统计与分析","uri":"/posts/20230508214520-%E6%89%A7%E4%B8%9A%E6%B3%A8%E5%86%8C%E4%BC%9A%E8%AE%A1%E5%B8%88%E7%BB%9F%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"注师人数前13大所 select cpaf_name 事务所,division_province 总部所在地,cpa_num 注师人数 from agent where cpaf_status !=21 order by cpa_num desc limit 13 相关知识点 ： LIMIT 子句：用于限制查询结果的返回数量。可以指定返回记录的起始位置和返回记录的数量。在本查询语句中，只返回前 13 条记录。 执行结果： 这也就是我们平常所说的四大、八大吧，可以看出除了天健总部在杭州、中审众环总部在武汉外，其余总部都在北京和上海。 ","date":"2023-05-09","objectID":"/posts/20230508214520-%E6%89%A7%E4%B8%9A%E6%B3%A8%E5%86%8C%E4%BC%9A%E8%AE%A1%E5%B8%88%E7%BB%9F%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/:6:0","tags":["duckdb"],"title":"执业注册会计师统计与分析","uri":"/posts/20230508214520-%E6%89%A7%E4%B8%9A%E6%B3%A8%E5%86%8C%E4%BC%9A%E8%AE%A1%E5%B8%88%E7%BB%9F%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"各省老大 我们统计各省注师人数最多的事务所，一般来说这个排名和收入排名差别不大。 select * from agent_province a where 注师数\u003e= all(select max(注师数) from agent_province b where a.省=b.省 ) order by 注师数 desc 这里有个子查询，需要稍微解释下： WHERE 注师数\u003e= ALL (SELECT max(注师数) FROM agent_province b WHERE a.省 = b.省) :使用 WHERE 子句筛选条件，其中 ALL 关键字指定在子查询中，选择最大注册会计师人数的情况下，所有记录中的注册会计师人数均不小于该最大值。子查询的作用是返回与 a 表中的省份相同的省份中最大的注册会计师人数。 执行结果： 事务所 省 分类 注师人数 安永华明会计师事务所（特殊普通合伙） 上海市 分部 1101 天健会计师事务所（特殊普通合伙） 浙江省 总部 1074 普华永道中天会计师事务所（特殊普通合伙） 北京市 分部 738 容诚会计师事务所（特殊普通合伙） 安徽省 分部 419 普华永道中天会计师事务所（特殊普通合伙） 广东省 分部 264 中兴华会计师事务所（特殊普通合伙） 江苏省 分部 238 大华会计师事务所（特殊普通合伙） 深圳市 分部 232 信永中和会计师事务所（特殊普通合伙） 四川省 分部 212 容诚会计师事务所（特殊普通合伙） 福建省 分部 199 天健会计师事务所（特殊普通合伙） 重庆市 分部 187 信永中和会计师事务所（特殊普通合伙） 山东省 分部 159 希格玛会计师事务所（特殊普通合伙） 陕西省 总部 156 天健会计师事务所（特殊普通合伙） 湖南省 分部 154 中审众环会计师事务所（特殊普通合伙） 湖北省 总部 113 中审众环会计师事务所（特殊普通合伙） 云南省 分部 102 容诚会计师事务所（特殊普通合伙） 辽宁省 分部 86 中审华会计师事务所（特殊普通合伙） 天津市 总部 79 信永中和会计师事务所（特殊普通合伙） 河南省 分部 78 天华（宁夏）会计师事务所（特殊普通合伙） 宁夏回族自治区 总部 77 中兴财光华会计师事务所（特殊普通合伙） 河北省 分部 71 山西前弘会计师事务所（特殊普通合伙） 山西省 总部 60 内蒙古中路华辰会计师事务所（特殊普通合伙） 内蒙古自治区 总部 57 中审众环会计师事务所（特殊普通合伙） 黑龙江省 分部 52 祥浩（广西）会计师事务所（特殊普通合伙） 广西壮族自治区 总部 51 新疆宏昌天圆有限责任会计师事务所 新疆维吾尔自治区 总部 49 大华会计师事务所（特殊普通合伙） 贵州省 分部 43 中准会计师事务所（特殊普通合伙） 吉林省 分部 42 大信会计师事务所（特殊普通合伙） 江西省 分部 42 天职国际会计师事务所（特殊普通合伙） 海南省 分部 41 大信会计师事务所（特殊普通合伙） 甘肃省 分部 33 中准会计师事务所（特殊普通合伙） 青海省 分部 15 西藏和智博会计师事务所有限公司 西藏自治区 总部 15 对于毕业生来说，除了去四大、八大外，去当地规模最大的所也是很好的选择。 ( 注：agent_province表为计算各个总所名称及其分部在各省的注师人数 ) 计算方法如下： drop table if exists agent_province; create table agent_province as with a AS ( select top_name 事务所,division_name 省,'分部' 类别,cpa_num 注师数 from main.relation where top_name in ( select cpaf_name from agent where cpaf_status !=21 ) ), b as ( select cpaf_name 事务所,division_province 省,'总部' 类别,t1.cpa_num-ifnull(t2.cpa_num,0) 注师数 from agent t1 left join main.agent_fb_cpa t2 on t1.cpaf_name=t2.top_name where cpaf_status !=21 order by 注师数 desc ) select * from a union all select * from b 相关知识点: drop table if exists agent_province;如果存在表agent_province就删除。 create table agent_province …. 将后续的查询结果创建为一张新表agent_province。 with as 是一种常用的查询语法，用于在查询语句中创建临时命名查询，以便于在后续的查询中引用这些查询，从而简化复杂查询语句。 union all 用于合并两个或多个 SELECT 语句的结果集，并返回一个包含所有结果的单个结果集。UNION ALL 和 UNION 的不同之处在于，UNION 会去重，即只返回不同的行，而UNION ALL不去重，即返回所有行。因此，如果两个 SELECT 语句的结果集中包含相同的行，则UNION ALL会将它们都返回，而 UNION 只返回其中一个。 ","date":"2023-05-09","objectID":"/posts/20230508214520-%E6%89%A7%E4%B8%9A%E6%B3%A8%E5%86%8C%E4%BC%9A%E8%AE%A1%E5%B8%88%E7%BB%9F%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/:7:0","tags":["duckdb"],"title":"执业注册会计师统计与分析","uri":"/posts/20230508214520-%E6%89%A7%E4%B8%9A%E6%B3%A8%E5%86%8C%E4%BC%9A%E8%AE%A1%E5%B8%88%E7%BB%9F%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"结语 duckdb 的 SQL 大部份都是标准的 SQL 语句，用起来并不难。 相关的查询语句的介绍可以查看 w3school 的教程： https://www.w3school.com.cn/sql/index.asp 也可以查看 duckdb 官方文档： https://duckdb.org/docs 也可以看看以前我写的 mysql 相关的文章，基本上都差不多。 如果后续工作中还有一些值得分享的点，到时候再发文章。 刚入所时执业与非执业的人数是1:1 ，现在是1:2了，执业的比例在不断下降。 与此相对应的是执业人员工作劳累程度在不断上升。 在《注册会计师行业发展规划（ 2021 —2025 年）》中 2035 年远景目标提到： 到2035 年实现注册会计师行业发展水平与我国综合国力和国际地位相匹配，注册会计师行业成为全面领先、具有国际竞争力的高端现代服务业。 希望大家在这一行越来越好。 ","date":"2023-05-09","objectID":"/posts/20230508214520-%E6%89%A7%E4%B8%9A%E6%B3%A8%E5%86%8C%E4%BC%9A%E8%AE%A1%E5%B8%88%E7%BB%9F%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/:8:0","tags":["duckdb"],"title":"执业注册会计师统计与分析","uri":"/posts/20230508214520-%E6%89%A7%E4%B8%9A%E6%B3%A8%E5%86%8C%E4%BC%9A%E8%AE%A1%E5%B8%88%E7%BB%9F%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"数据导入 这里我们都以 csv 文件举例，如果你需要导入 excel 文件，需要先转换成 csv 文件（后面我们会介绍 xlsx2csv 工具）。 ","date":"2023-05-08","objectID":"/posts/20230507225721-duckdb%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A_%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5/:1:0","tags":["duckdb"],"title":"duckdb从入门到精通：数据导入","uri":"/posts/20230507225721-duckdb%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A_%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5/"},{"categories":["工作"],"content":"读取文件 实际上，duckdb 可以不导入到数据库中，就可以直接查询。 我们先“新建 SQL 编辑器”，这样我们就可以在里面写 SQL 语句了。 我们使用一个电商数据集[1]，在编辑器中输入代码： select * from \"C:\\Users\\data.csv\" 直接可以查询出数据结果，而不需要像一般数据库需要先建表、导入数据后才能查询。 从这一点可以看出是非常简洁、方便的。 ","date":"2023-05-08","objectID":"/posts/20230507225721-duckdb%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A_%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5/:1:1","tags":["duckdb"],"title":"duckdb从入门到精通：数据导入","uri":"/posts/20230507225721-duckdb%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A_%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5/"},{"categories":["工作"],"content":"智能导数 read_csv_auto 一般来说，如果一张表我们要经常查询还是需要将其导入到数据库中。 这时我们可以使用read_csv_auto函数，智能创建表并导入到数据库中。 create table ecommerce as select * from read_csv_auto('input.csv'); 我们打开数据库，可以看到出现了刚新建的表ecommerce，双击后，点击数据选项卡，能够查看导入的数据。 这个导数的过程非常智能，快速，比 mysql 导入速度快了不少。 导入报错解决方法 由于它是根据前面几行自动判断数据类型，可能会出现后面的数据不符合数据类型而导致出错的情况。 如： SQL Error: Invalid Input Error: Could not convert string '2.03.19' to DOUBLE in column \"物料编码\", at line 577268. 这个报错就是第 577268 行，不符合智能创建的表的该字段的数据类型。 这里我们可以参考官方文档的参数列表中的sample_size参数 [2]，让智能判断时参考多一些行数。 CREATE TABLE new_tbl AS SELECT * FROM read_csv_auto('input.csv', sample_size=600000); 这就会参考 60 万行数据，来创建合适的数据类型。或者设置sample_size=-1，这样可以参数数据中的所有行，来创建适当的数据类型。 当然也可以使用参数all_varchar=1，让所有数据以 varchar 的文本类型导入数据库，不过不建议这样做，因为无法对数字和日期进行计算。 需要注意的是 duckdb 和 mysql 不同的是需要设置严格的数据类型，例如， mysql 中 varchar 文本类型也是可以计算的，但是在 duckdb 只就不能进行计算。所以，我们需要在建表时设置正确的数据类型，数字就设置成数字类型，日期时间设置成日期时间的类型。 假如数据中有双引号包裹的千分符数字，如\"12,345.23\"，这对 duckdb来说是文本格式，将不能参与计算，为了能导入成数字格式，我们需要先将原文件中双引号中的逗号删除，可以在终端中使用 sed 命令来完成。 ( 注：linux,mac 终端中可以使用 sed 命令，Windows 可以安装wsl linux子系统使用终端 sed 命令） 删除引号内数字中逗号 如果你想替换原文件，你可以使用 -i 选项来实现原地修改，例如： sed -i 's/\\(\"\\)\\([^\",]\\+\\),\\([^\"]\\+\\)\\(\"\\)/\\1\\2\\3\\4/g' file 例如，将1,2,3,“45,678.00” 转换成1,2,3,“45678.00” 这个命令会在修改data.csv文件的同时，生成一个data.csv.bak文件作为备份。 ","date":"2023-05-08","objectID":"/posts/20230507225721-duckdb%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A_%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5/:1:2","tags":["duckdb"],"title":"duckdb从入门到精通：数据导入","uri":"/posts/20230507225721-duckdb%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A_%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5/"},{"categories":["工作"],"content":"xlsx2csv ","date":"2023-05-08","objectID":"/posts/20230507225721-duckdb%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A_%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5/:2:0","tags":["duckdb"],"title":"duckdb从入门到精通：数据导入","uri":"/posts/20230507225721-duckdb%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A_%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5/"},{"categories":["工作"],"content":"安装 xlsx2csv 是一个将 excel 文件转 csv 文件的 python 包。 安装方法： pip install xlsx2csv ","date":"2023-05-08","objectID":"/posts/20230507225721-duckdb%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A_%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5/:2:1","tags":["duckdb"],"title":"duckdb从入门到精通：数据导入","uri":"/posts/20230507225721-duckdb%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A_%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5/"},{"categories":["工作"],"content":"基础使用 在终端中将input_name.xlsx转换成output_name.csv： xlsx2csv input_name.xlsx output_name.csv 上述命令只会转换工作簿的第一张表，如果你需要转换的 xlsx 中是有多个表，那么可以使用-a参数： xlsx2csv -a input_name.xlsx output_dir_name 将会把input_name.xlsx文件所以表转换输出到output_dir_name文件夹下。 如果你要将一个文件夹下所有的工作簿转换成 csv 可以使用： xlsx2csv /path/to/input/dir /path/to/output/dir 同样的，如果文件中有多个工作表，需要使用-a参数将所有的工作表转出。 ","date":"2023-05-08","objectID":"/posts/20230507225721-duckdb%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A_%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5/:2:2","tags":["duckdb"],"title":"duckdb从入门到精通：数据导入","uri":"/posts/20230507225721-duckdb%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A_%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5/"},{"categories":["工作"],"content":"DuckDB是一个开源免费的高性能的列式数据库系统，类似 SQLite 易用，又具备 clickhouse 的性能。 作为平时使用自己笔记本做数据分析的学生、分析师来说，非常适合使用，性能比 mysql 快百倍。 如果你之前会使用 mysql 等数据库，那么可以非常快速上手使用 duckdb ，因为它也是使用标准的 SQL ，只是个别函数的不同。 如果你之前没有接触过数据也没有关系， 接下来，我们会写系列文章，打开 duckdb 的大门，从入门到精通。 你将拥有在笔记本上处理上亿行数据的能力。 首先我们将介绍安装，实际上 duckdb 没有服务器端，它是用文件来存储数据，所以我们只需要安装个图形化的管理软件 DBeaver 就可以直接使用了。 ","date":"2023-05-05","objectID":"/posts/20230504233317-duckdb%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A_%E5%AE%89%E8%A3%85%E7%AF%87/:0:0","tags":["duckdb"],"title":"duckdb从入门到精通：安装篇","uri":"/posts/20230504233317-duckdb%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A_%E5%AE%89%E8%A3%85%E7%AF%87/"},{"categories":["工作"],"content":"dbeaver安装 在 DBeaver 官网下载社区版本： 下载地址：https://dbeaver.io/download/ 双击下载好的安装包 点击 下一步: 点击 我接受: 选择For me，后点击 下一步: 默认选择后，点击 下一步: 更改安装路径后，点击 下一步: 默认点击 安装: 勾选上Create Desktop Shortcut,创建桌面快捷方式，再点击 完成: 安装完成后，打开 DBeaver: 这里问是否需要创建示例数据库，我们选择否。 到此为止，我们就安装好了 DBeaver 图形化管理界面了。 ","date":"2023-05-05","objectID":"/posts/20230504233317-duckdb%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A_%E5%AE%89%E8%A3%85%E7%AF%87/:1:0","tags":["duckdb"],"title":"duckdb从入门到精通：安装篇","uri":"/posts/20230504233317-duckdb%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A_%E5%AE%89%E8%A3%85%E7%AF%87/"},{"categories":["工作"],"content":"dbeaver安装duckdb驱动 打开 DBeaver 后，点击左上角新建连接图标，选择duckdb数据库后，点击下一步。 点击 创建: 选择我们想保存数据库文件的路径，例如这里我选择桌面文件夹（最好不要在 C 盘），创建一个名叫myduckdb文件，点击 保存: 保存后，可以看到我们将要创建的文件路径，这时，我们点击 测试连接: 由于我们还没有安装过连接 duckdb 的驱动，这时会自动弹出对话框，让我们下载驱动。直接点击 下载: 这时会自动开始下载，不过一般下载很慢，我们可以更换下下载源，加快速度。需要先点击停止的按钮后，点击 下载配置: 找到首选项 \u003e连接\u003e驱动\u003e驱动位置 ，点击添加。 输入阿里云中央仓库地址： http://maven.aliyun.com/nexus/content/groups/public/ 点击确定，然后重新下载驱动，这个时候几秒钟就可以下载完成。 我们再点击测试连接时，就可以看到连接成功了，直接点击确定，就可以进入数据库。 注：如果测试连接成功，但是点击确定后失败的，可以重启下软件 我们可以双击下myduckdb连接后，可以看到main数据库。 至此，我们就完成了 duckdb 驱动的安装，我们就可以直接使用了。 如果想在电脑上方便查看教程可以关注我的博客：nigo81.github.io ","date":"2023-05-05","objectID":"/posts/20230504233317-duckdb%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A_%E5%AE%89%E8%A3%85%E7%AF%87/:2:0","tags":["duckdb"],"title":"duckdb从入门到精通：安装篇","uri":"/posts/20230504233317-duckdb%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A_%E5%AE%89%E8%A3%85%E7%AF%87/"},{"categories":["工作"],"content":"这两天看了涂子沛的新书《第二大脑》，主要讲了如何打造自己的笔记系统，这个笔记系统是我们大脑的延伸，也是辅助我们的思考工具，知识传承载体。 作者开篇写了个题记： 我出版了近十部作品，从来没有要求自己的孩子阅读其中任何一本。但这本书例外，我希望自己的孩子以及子孙后代都认真阅读，并且尽早在他们的日常生活中使用第二大脑。 可以看出作者自己对这本书的看重，近两年涌现出很多双链笔记应用，类似Roam Research,Logseq,Obsidian等等。 他们的背后思想都是卢曼的卡片盒笔记法。 这本书更像是这类工具的具体实践，更进一步是如何打造自己的思考工具、创作流程、知识承载。 作者也正是靠这个方法在 3 个月完成了本书。 如果读者之前对卡片盒笔记法不太了解，建议可以阅读本书。 如果对这个方法十分清楚，并在平时中已大量实践，可能会有一些共鸣，但也许不能汲取到太多新的观点。 同时推荐大家看下卡片盒笔记法的官方文章： https://zettelkasten.de/introduction/zh/ 以下是阅读该文章时重要观点的摘抄和思考： ","date":"2023-05-01","objectID":"/posts/20230501215943-%E7%AC%AC%E4%BA%8C%E5%A4%A7%E8%84%91/:0:0","tags":["卡片笔记"],"title":"第二大脑","uri":"/posts/20230501215943-%E7%AC%AC%E4%BA%8C%E5%A4%A7%E8%84%91/"},{"categories":["工作"],"content":"卡片盒笔记概念 卡片盒笔记系统是一款个性化的，用于思考和写作的工具。它具有超文本(hypertext)的特点，让你的所思所想互相连接形成网络。与其他系统不同的是，你创造的是一张由你的想法、看法、灵感、或者遇到的具体的知识组成的思想之网(web of thoughts)，而不是孤立的笔记。它强调笔记之间的连接关系，而非把所有笔记堆在一起。 我们今天所知的卡片盒笔记法，由尼克拉斯 - 卢曼(Niklas Luhmann) 创造并发扬光大，它是目前最强大的思考和笔记工具。 ","date":"2023-05-01","objectID":"/posts/20230501215943-%E7%AC%AC%E4%BA%8C%E5%A4%A7%E8%84%91/:1:0","tags":["卡片笔记"],"title":"第二大脑","uri":"/posts/20230501215943-%E7%AC%AC%E4%BA%8C%E5%A4%A7%E8%84%91/"},{"categories":["工作"],"content":"卡片盒笔记特点 它是如同网页一般的超文本； 它坚持笔记原子化的原则(Atomicity)； 它是个性化的； 超文本：笔记之间相互联系（双链），原子化：每条笔记包含且只包含一条知识。个性化：个人思考工具。 ","date":"2023-05-01","objectID":"/posts/20230501215943-%E7%AC%AC%E4%BA%8C%E5%A4%A7%E8%84%91/:2:0","tags":["卡片笔记"],"title":"第二大脑","uri":"/posts/20230501215943-%E7%AC%AC%E4%BA%8C%E5%A4%A7%E8%84%91/"},{"categories":["工作"],"content":"单个卡片构成 每条笔记由三部分组成： 唯一标识符：它为你的笔记提供一个明确的地址； 笔记的正文：这是你记录的笔记内容，一般为一段简短的原子化的信息； 参考文献：如果你的内容来源于外部，你可以在每条笔记的底部写上信息来源，如果你记录的是你自己的想法，则留空。 唯一标识符就是创建某种类似 ID 的编号，让这条笔记唯一，这样就可以方便后续的引用和查找。笔记正文需要用自己的话写这部分内容，避免完全摘抄，只有是自己思考加工过的东西，才属于自己，才有可能形成自己的工具箱。 输入卡片盒的内容应该是知识而非信息 Knowledge instead of information. 参考文献一般位于在笔记卡片的底部，用来说明信息的来源。一般为 卡片盒笔记系统外部的参考文献，比如书籍、论文或者网络上的文章。 ","date":"2023-05-01","objectID":"/posts/20230501215943-%E7%AC%AC%E4%BA%8C%E5%A4%A7%E8%84%91/:3:0","tags":["卡片笔记"],"title":"第二大脑","uri":"/posts/20230501215943-%E7%AC%AC%E4%BA%8C%E5%A4%A7%E8%84%91/"},{"categories":["工作"],"content":"专注当下项目与广泛笔记间的妥协 当我们在做一个 Project 的时候，往往会遇到偏离主线的知识，我们在思考、记录笔记时经常会偏离主线发散，同时在发散的过程中我们会惊喜地发现带来很多副产品。 但是如果过于发散，可能会影响到我们的主线任务，因此，我们需要在专注当下项目与广泛笔记之间进行妥协和平衡。 完成项目的过程会产生各种各样的副产品，这些副产品会成为未来项目的宝贵知识。 ","date":"2023-05-01","objectID":"/posts/20230501215943-%E7%AC%AC%E4%BA%8C%E5%A4%A7%E8%84%91/:4:0","tags":["卡片笔记"],"title":"第二大脑","uri":"/posts/20230501215943-%E7%AC%AC%E4%BA%8C%E5%A4%A7%E8%84%91/"},{"categories":["工作"],"content":"参考文献 https://zettelkasten.de/introduction/zh/ ","date":"2023-05-01","objectID":"/posts/20230501215943-%E7%AC%AC%E4%BA%8C%E5%A4%A7%E8%84%91/:5:0","tags":["卡片笔记"],"title":"第二大脑","uri":"/posts/20230501215943-%E7%AC%AC%E4%BA%8C%E5%A4%A7%E8%84%91/"},{"categories":["工作"],"content":"一个朋友给我推荐了一个数据 duckdb 让我去试用下。 我试用后，感觉作为平时在本地进行数据分析的 IT 审计来说，完全可以丢掉mysql,sqlserver这些数据库了。 先说下 duckdb 的优势： 不需要安装服务器端。类似 sqllite 将数据存储在文件中，不需要安装服务器端。 列式数据库。 mysql 是行式数据库，而 duckdb 和 clickhouse 一样是列式数据库，且运行时调用所有 CPU 计算性能能比 mysql 快上百倍。 大数据量。平时我们使用自己笔记本（一般轻薄本），如果使用 mysql 基本上上千万行就有点处理慢了。而 duckdb 我测试了下 8 亿行数据也在 20 秒内反应出来。 导数方便并快速。 使用 sql 语句。你会 sql 语句，就可以马上上手，基本上没有太大的迁移成本。 全平台。支持windows,linux,mac。 开源免费。 可以和 python 等编程语言无缝结合。 我使用了下，感觉非常智能、强大、粗暴。 后面我可能会写一系列教程来介绍它，让大家目前还在用 mysql 的朋友可以无成本迁移到 duckdb 上来。我觉得这是值得的。 这里我先简单给大家说明下有多简单。 ","date":"2023-04-23","objectID":"/posts/20230423202616-it%E5%AE%A1%E8%AE%A1%E5%8F%AF%E4%BB%A5%E6%89%94%E6%8E%89mysql%E4%BA%86_%E6%96%B0%E7%A5%9E%E5%99%A8duckdb%E6%9D%A5%E4%B8%B4/:0:0","tags":["duckdb"],"title":"IT审计可以扔掉mysql了，新神器duckdb来临！","uri":"/posts/20230423202616-it%E5%AE%A1%E8%AE%A1%E5%8F%AF%E4%BB%A5%E6%89%94%E6%8E%89mysql%E4%BA%86_%E6%96%B0%E7%A5%9E%E5%99%A8duckdb%E6%9D%A5%E4%B8%B4/"},{"categories":["工作"],"content":"图形化管理工具 使用 mysql 的朋友可能一般都会用 navicat 等图形化管理工具。 duckdb 我们可以使用 dbeaver 图形化管理工具，它是开源免费的。 安装好后 dbeaver 后，新建一个连接，选择 duckdb ，点击 next 。 要知道 duckdb 不需要安装服务器端，只需要创建一个文件，我们输入一个文件名。点击下Test Connection将会自动安装对应驱动。 安装好驱动后，直接 Finish. 这就安装好了！安装好了！ 我相信安装过mysql+navicat或者 sqlserver的人应该能体会到，这个安装有多简单！ ","date":"2023-04-23","objectID":"/posts/20230423202616-it%E5%AE%A1%E8%AE%A1%E5%8F%AF%E4%BB%A5%E6%89%94%E6%8E%89mysql%E4%BA%86_%E6%96%B0%E7%A5%9E%E5%99%A8duckdb%E6%9D%A5%E4%B8%B4/:1:0","tags":["duckdb"],"title":"IT审计可以扔掉mysql了，新神器duckdb来临！","uri":"/posts/20230423202616-it%E5%AE%A1%E8%AE%A1%E5%8F%AF%E4%BB%A5%E6%89%94%E6%8E%89mysql%E4%BA%86_%E6%96%B0%E7%A5%9E%E5%99%A8duckdb%E6%9D%A5%E4%B8%B4/"},{"categories":["工作"],"content":"导入数据 很多人在使用 mysql 的时候觉得使用 navicat 导入向导比较方便，主要是这可以省去建表的时间，但当你用导入向导的时候速度非常慢。 比如我这里有个销售订单的 csv 文件，一共2.6G。我只需要写语句： create table 销售订单 as select * from read_csv_auto('/home/nigo/销售订单.csv') 一共花费 46 秒。 虽然这导入数据速度比 clickhouse 要慢不少，但比 mysql 不知道快了多少倍。 我经常看到同事导一个几 G 的数据用 navicat 导入向导在那里傻等着，估计半个小时往上。 你双击下刚新建的表，可以看到每个字段都按最合适的数据类型给创建好了，这不比自己写建表语句香么？ 这也太智能了。 ","date":"2023-04-23","objectID":"/posts/20230423202616-it%E5%AE%A1%E8%AE%A1%E5%8F%AF%E4%BB%A5%E6%89%94%E6%8E%89mysql%E4%BA%86_%E6%96%B0%E7%A5%9E%E5%99%A8duckdb%E6%9D%A5%E4%B8%B4/:2:0","tags":["duckdb"],"title":"IT审计可以扔掉mysql了，新神器duckdb来临！","uri":"/posts/20230423202616-it%E5%AE%A1%E8%AE%A1%E5%8F%AF%E4%BB%A5%E6%89%94%E6%8E%89mysql%E4%BA%86_%E6%96%B0%E7%A5%9E%E5%99%A8duckdb%E6%9D%A5%E4%B8%B4/"},{"categories":["工作"],"content":"处理数据量 我相信大部分用自己笔记本运行 mysql 做数据分析的，最多也就处理个千万行。 并且当千万行的时候，笔记本很可能跑不出来了。 那么 duckdb 可以跑多少数据量呢？ 前面我用 clickhouse 在2019年产的 5000 块的联系小新pro 笔记本上跑过 8 亿行数据。 今天，我们也直接上 8 亿数据。 但是这个数据量，我用 dbeaver 跑的时候直接崩溃。不过这不是 duckdb 的问题，而是 dbeaver 的问题。 我直接使用 pyhton 跑。 我们先跑个总的数据量： 一共8.9亿行数据，跑出来花了0.45秒。 再来按一个字段聚合求和，花了12.72秒。我试过相同数据，在 clickhouse 上跑要 16 秒，居然比 clickhouse 还快，有点离谱。 ","date":"2023-04-23","objectID":"/posts/20230423202616-it%E5%AE%A1%E8%AE%A1%E5%8F%AF%E4%BB%A5%E6%89%94%E6%8E%89mysql%E4%BA%86_%E6%96%B0%E7%A5%9E%E5%99%A8duckdb%E6%9D%A5%E4%B8%B4/:3:0","tags":["duckdb"],"title":"IT审计可以扔掉mysql了，新神器duckdb来临！","uri":"/posts/20230423202616-it%E5%AE%A1%E8%AE%A1%E5%8F%AF%E4%BB%A5%E6%89%94%E6%8E%89mysql%E4%BA%86_%E6%96%B0%E7%A5%9E%E5%99%A8duckdb%E6%9D%A5%E4%B8%B4/"},{"categories":["工作"],"content":"结语 以上功能，我感觉无论哪个方面都可以吊打 mysql 了。 从方便程度和全平台支持角度，也可以吊打 clickhosue 了。 尤其是对我们这种在自己笔记本本地跑数据的人来说，很适用了。 我今天粗略看了下官方文档，感觉到它更强大的是和 python 的无缝链接，以及一些特殊但非常实用的独特函数。 如果有机会，我后面会出系列教程。 感觉我们部门所有人都可以抛弃 mysql 了。 官方网站：https://duckdb.org/ ","date":"2023-04-23","objectID":"/posts/20230423202616-it%E5%AE%A1%E8%AE%A1%E5%8F%AF%E4%BB%A5%E6%89%94%E6%8E%89mysql%E4%BA%86_%E6%96%B0%E7%A5%9E%E5%99%A8duckdb%E6%9D%A5%E4%B8%B4/:4:0","tags":["duckdb"],"title":"IT审计可以扔掉mysql了，新神器duckdb来临！","uri":"/posts/20230423202616-it%E5%AE%A1%E8%AE%A1%E5%8F%AF%E4%BB%A5%E6%89%94%E6%8E%89mysql%E4%BA%86_%E6%96%B0%E7%A5%9E%E5%99%A8duckdb%E6%9D%A5%E4%B8%B4/"},{"categories":["工作"],"content":"2023年 2 月17日证监会制定的《监管规则适用指引——发行类第 5 号》 5-13 中涉及“用户真实性与变动合理性”分析，“包括新增用户的地域分布与数量”，同样 5-14 中“多指标分析性复核“也要求“相关核查包括但不限于用户变动合理性”。 可见对于 IPO 信息系统专项核查中我们需要计算“新增用户”这个数据。 ","date":"2023-04-22","objectID":"/posts/20230422212447-%E6%96%B0%E5%A2%9E%E7%94%A8%E6%88%B7%E6%95%B0%E8%AE%A1%E7%AE%97/:0:0","tags":["IT审计"],"title":"新增用户数计算","uri":"/posts/20230422212447-%E6%96%B0%E5%A2%9E%E7%94%A8%E6%88%B7%E6%95%B0%E8%AE%A1%E7%AE%97/"},{"categories":["工作"],"content":"如何定义新增用户 对于不同的行业或数据，新增用户的定义是不同的。 一种常见的方式是根据用户是否在某个时间段内首次登录应用来判断是否为新增用户。 另一种方式是根据用户是否完成了某些关键行为来判断是否为有效新增用户。例如，对于电商应用，关键行为可能是下单或付款； 对于教育应用，关键行为可能是观看课程或提交作业。这种方式可以更好地反映用户的价值和留存率。 可以看出，这里我们判断的有两个关键点，也就是将“新增”这两个字拆开：“新”和“增”的约定，即： 时间段 关键行为 ","date":"2023-04-22","objectID":"/posts/20230422212447-%E6%96%B0%E5%A2%9E%E7%94%A8%E6%88%B7%E6%95%B0%E8%AE%A1%E7%AE%97/:1:0","tags":["IT审计"],"title":"新增用户数计算","uri":"/posts/20230422212447-%E6%96%B0%E5%A2%9E%E7%94%A8%E6%88%B7%E6%95%B0%E8%AE%A1%E7%AE%97/"},{"categories":["工作"],"content":"如何计算新增用户 这里我们还是以电商为例，我们以下单作为首次关键行为，至少时间段我个人理解有两种。 ","date":"2023-04-22","objectID":"/posts/20230422212447-%E6%96%B0%E5%A2%9E%E7%94%A8%E6%88%B7%E6%95%B0%E8%AE%A1%E7%AE%97/:2:0","tags":["IT审计"],"title":"新增用户数计算","uri":"/posts/20230422212447-%E6%96%B0%E5%A2%9E%E7%94%A8%E6%88%B7%E6%95%B0%E8%AE%A1%E7%AE%97/"},{"categories":["工作"],"content":"历史所有期间 我们考虑将历史所有期间作为判断这次购买是否为首次购买用户的判断标准。也就是说当我计算 2022 年订单时，只要用户在 2022 年之前任意期间购买过，那么都算老用户。 那么我们可以写SQL: SELECT YEAR( first_order_date ) AS 年, COUNT( DISTINCT `客户`) AS 新客户数量 FROM (SELECT `客户`, MIN( `订单日期` ) AS first_order_date FROM `销售订单` GROUP BY `客户` ) AS first_orders GROUP BY YEAR ( first_order_date ) 这里我们直接计算订单数据中所有用户首次购买日期，然后根据这个首次购买日期聚合，计算出每年的新用户数量。 当然，你也可以按月去聚合，计算出申报期内所有月份的新用户数。 ","date":"2023-04-22","objectID":"/posts/20230422212447-%E6%96%B0%E5%A2%9E%E7%94%A8%E6%88%B7%E6%95%B0%E8%AE%A1%E7%AE%97/:2:1","tags":["IT审计"],"title":"新增用户数计算","uri":"/posts/20230422212447-%E6%96%B0%E5%A2%9E%E7%94%A8%E6%88%B7%E6%95%B0%E8%AE%A1%E7%AE%97/"},{"categories":["工作"],"content":"某一段区间 当然，我们也可以不考虑历史所有期间，仅考虑一段期间来判断这个用户是否为新用户。 例如，我们以年为区间作为判断依据，如当年购买且上年无购买行为的定义为新用户（注：个人理解）。 select count(distinct `客户`) as 新客户数量 from `销售订单` where `客户` not in ( select distinct `客户` from `销售订单` where year(`订单日期`)=2021 ) and year(`订单日期`)=2022 这就可以计算 2022 年有购买行为且 2021 年无购买行为的新增客户。 当然，你也可以按月设定这个区间。 ","date":"2023-04-22","objectID":"/posts/20230422212447-%E6%96%B0%E5%A2%9E%E7%94%A8%E6%88%B7%E6%95%B0%E8%AE%A1%E7%AE%97/:2:2","tags":["IT审计"],"title":"新增用户数计算","uri":"/posts/20230422212447-%E6%96%B0%E5%A2%9E%E7%94%A8%E6%88%B7%E6%95%B0%E8%AE%A1%E7%AE%97/"},{"categories":["工作"],"content":"如何计算留存用户数 与新增用户数相对应的就是留存用户数。 某段时间内的新增用户，经过一段时间后，仍继续使用应用的，为留存用户。 这里我们就可以计算留存率=留存用户数 /新增用户数 * 100% 如果是按年统计应该还比较容易，因为你会计算新增用户数，就能计算留存用户数，从而计算出留存率。 但如果要按月统计的话，我不知道该怎么写 SQL ，感觉还是得用 Python 循环计算每个月的容易点。 ","date":"2023-04-22","objectID":"/posts/20230422212447-%E6%96%B0%E5%A2%9E%E7%94%A8%E6%88%B7%E6%95%B0%E8%AE%A1%E7%AE%97/:3:0","tags":["IT审计"],"title":"新增用户数计算","uri":"/posts/20230422212447-%E6%96%B0%E5%A2%9E%E7%94%A8%E6%88%B7%E6%95%B0%E8%AE%A1%E7%AE%97/"},{"categories":["工作"],"content":"晚上和一位审计同事聊天，他已经连续加班五个通宵了，每天凌晨 4 、5点回去，早上 9 点又继续。 他心理压力很大，自己都开始怀疑自己了。 前几天公众号的一个刚进事务所的朋友后台留言给我 绝啦 上班前面试被老板 pua 说审计很苦的，你受不了哦。 我心里想能有多苦，老娘很能吃苦的，入了事务所后从每天 10 下班 12 点前睡觉爱干净爱运动爱早起变成现在，每天十一点下班路上买点烤串带瓶红星二锅头回到酒店打开电视，脑子已经很久没有分泌多巴胺了” 我当时没有回复她，因为我自己都忙不过来，也不知道能说些什么。 我又想起之前一个项目，给一个同事打电话，说着说着她就哭起来了：“客户要怼我，券商要怼我，连所里的人也要怼我。。。。。” 赶紧安慰下她，让她回去先休息下。 这行还真是挣的“窝囊费”。 有天项目组下班路上开玩笑说：“要是半夜路上看到几个背着双肩包的，一定就是同行。” 确实，审计这行的人确实不容易，网络上也没有我们的声音，估计都还在加班吧。 根据我的观察，压力大的，一般是刚入行不到 1 年的人，或者责任心过于强的人。 前者可能需要熬过一个年报，适应工作内容和工作节奏。后者可能需要自己和自己和解。 当然，工作过程中，也会遇到形形色色的奇葩，谁叫我们是中介机构呢？ 不过，人就是一面镜子，与人交往过程中，你看到的是你自己的影像。 当你对我不友好时，其实我心理也在默念SB(Super Boy) 。 我也无数次想摔门而出，老子不干了的冲动。 都这么苦了，至于为什么有人还在事务所干？ 也许，为了养家糊口吧， 也许还有些这个工作让自己不舍的地方吧。 离4.30还有十几天了，希望还在奋战的同行们，苦中作乐，马上年报就过了。 空了一起喝酒。 ","date":"2023-04-16","objectID":"/posts/20230416221634-%E4%B8%BA%E5%95%A5%E6%9C%89%E4%BA%BA%E6%83%B3%E4%B8%8D%E9%80%9A%E5%88%B0%E4%BA%8B%E5%8A%A1%E6%89%80%E5%81%9A%E5%AE%A1%E8%AE%A1/:0:0","tags":["杂文"],"title":"为啥有人想不通到事务所做审计？","uri":"/posts/20230416221634-%E4%B8%BA%E5%95%A5%E6%9C%89%E4%BA%BA%E6%83%B3%E4%B8%8D%E9%80%9A%E5%88%B0%E4%BA%8B%E5%8A%A1%E6%89%80%E5%81%9A%E5%AE%A1%E8%AE%A1/"},{"categories":["生活"],"content":"下班坐 1 个小时地铁回来， 往常地铁口熙熙攘攘的小摊贩也只剩下一家。 路上偶然刷到一个专栏文章， 故事中，仿佛又看到过去的自己。 我也是喜欢独处的人，喜欢自己一个人静静地宅着，研究些自己感兴趣的东西，漫无目的地读些杂书。 但这些东西，越来越远，以至于经常会想如何赚到钱，然后做一个自由职业者，宅着。 今天看到特别好的一句话：“在确定性上积累，在不确定性上低成本试错。” 希望自己多读书、多想、多做，早日实现能够独处的机会。 ","date":"2023-04-12","objectID":"/posts/20230412225425-%E7%8B%AC%E5%A4%84/:0:0","tags":["杂文"],"title":"独处","uri":"/posts/20230412225425-%E7%8B%AC%E5%A4%84/"},{"categories":["生活"],"content":"普通人没有哪个挣钱是轻松的， 寒窗苦读，抑或起早贪黑，不过为五斗米折腰， 谁曾经还没有点廉价的梦想吗？ 也许你不信命，奋斗过，拼搏过，廉价的梦想就像缓缓升起的五彩斑斓的气球 不过你的身上还背负了全家的希望，也许到头还是为五斗米折腰 不过呢，怕啥呢，人死 diao 朝天，努力的意义就是为了自由， 自由可能不是能做自己开心的事， 而是随时可以不做不开心的事。 翻滚吧，骚年！ ","date":"2023-04-02","objectID":"/posts/20230402214623-%E8%87%AA%E7%94%B1/:0:0","tags":["杂文"],"title":"自由","uri":"/posts/20230402214623-%E8%87%AA%E7%94%B1/"},{"categories":["工作"],"content":"领导问我上市公司审计收费是与资产规模还是什么相关？ 虽然各省注协提供了一个收费的参考标准： 显示出计费基数是资产总额或营业收入。 但是，我还是想从上市公司历年收费数据出发，用数据找出和哪个报表科目具有强相关关系。 ","date":"2023-03-28","objectID":"/posts/20230328110553-%E4%B8%8A%E5%B8%82%E5%85%AC%E5%8F%B8%E5%AE%A1%E8%AE%A1%E6%94%B6%E8%B4%B9%E4%B8%8E%E6%8A%A5%E8%A1%A8%E7%A7%91%E7%9B%AE%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90/:0:0","tags":["python"],"title":"上市公司审计收费与报表科目相关性分析","uri":"/posts/20230328110553-%E4%B8%8A%E5%B8%82%E5%85%AC%E5%8F%B8%E5%AE%A1%E8%AE%A1%E6%94%B6%E8%B4%B9%E4%B8%8E%E6%8A%A5%E8%A1%A8%E7%A7%91%E7%9B%AE%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"数据获取 通过 Tushare 金融数据接口批量获取 A 股上市公司 2000 年以来资产负债表、利润表、审计收费数据。 将数据导入 mysql 数据库，三张表拼接成一张表。 注： 1.部分审计收费金额缺失，我们在分析时将剔除这部分缺失数据 2.2008年以前审计收费数据缺失严重，我们从 2008 年开始统计分析 ","date":"2023-03-28","objectID":"/posts/20230328110553-%E4%B8%8A%E5%B8%82%E5%85%AC%E5%8F%B8%E5%AE%A1%E8%AE%A1%E6%94%B6%E8%B4%B9%E4%B8%8E%E6%8A%A5%E8%A1%A8%E7%A7%91%E7%9B%AE%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90/:1:0","tags":["python"],"title":"上市公司审计收费与报表科目相关性分析","uri":"/posts/20230328110553-%E4%B8%8A%E5%B8%82%E5%85%AC%E5%8F%B8%E5%AE%A1%E8%AE%A1%E6%94%B6%E8%B4%B9%E4%B8%8E%E6%8A%A5%E8%A1%A8%E7%A7%91%E7%9B%AE%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"各市场板块审计收费统计 利用 Python 连接 mysql 数据库，对审计收费聚合统计中位数、平均值、最大值、最小值。 import pandas as pd import pymysql connect = pymysql.connect( host='127.0.0.1', db='book', user='root', passwd='1234', charset='utf8') sql = \"\"\" select * from audit_fees where market in ('主板','中小板','创业板','北交所','科创板') and month(end_date) = 12 and audit_fees !=0 and audit_fees is not null \"\"\" df = pd.read_sql(con=connect,sql=sql) # 将audit_fees单位转换为万元 df['audit_fees'] = df['audit_fees'] / 10000 # # 定义需要计算的统计量 agg_dict = { 'audit_fees': ['median', 'mean', 'max', 'min'] } # 按 market 分组，计算多个统计量 result = df.groupby(['end_date','market']).agg(agg_dict) result = result.applymap('{:,.2f}'.format) result = result.reset_index() result.to_excel('上市公司各板块审计收费统计.xlsx') print(result) 执行结果： ( 单位：万元 ) 年度 市场 中位数 平均数 最大值 最小值 2008 中小板 40.00 43.88 270.00 12.00 2008 主板 50.00 194.48 22,100.00 10.00 2009 中小板 40.00 48.21 280.00 12.00 2009 主板 55.00 179.15 20,700.00 10.00 2009 创业板 50.00 80.21 275.00 10.00 2010 中小板 50.00 55.12 390.00 12.00 2010 主板 60.00 201.47 28,100.00 10.00 2010 创业板 39.50 74.29 444.50 8.00 2011 中小板 50.00 61.55 601.30 15.00 2011 主板 65.00 196.44 22,300.00 10.00 2011 创业板 40.00 49.14 310.00 10.00 2012 中小板 56.00 64.36 350.00 1.00 2012 主板 70.00 191.47 22,200.00 16.00 2012 创业板 45.00 48.77 280.00 15.00 2013 中小板 60.00 70.28 674.16 17.00 2013 主板 74.00 196.89 18,500.00 20.00 2013 创业板 50.00 52.12 180.00 20.00 2014 中小板 65.00 77.20 678.61 15.00 2014 主板 76.00 195.71 19,900.00 20.00 2014 创业板 50.00 59.90 459.54 20.00 2015 中小板 75.00 90.00 1,380.00 20.00 2015 主板 80.00 206.06 21,400.00 20.00 2015 创业板 60.00 67.66 780.00 10.00 2016 中小板 80.00 101.25 1,620.00 20.00 2016 主板 85.00 203.95 21,300.00 10.00 2016 创业板 64.00 75.93 950.00 10.00 2017 中小板 88.00 110.98 1,495.00 23.00 2017 主板 90.00 203.74 21,500.00 4.00 2017 创业板 70.00 84.91 1,000.00 25.00 2018 中小板 95.00 121.43 1,851.70 20.00 2018 主板 90.05 209.90 23,200.00 4.00 2018 创业板 75.00 94.35 1,000.00 16.00 2018 北交所 25.00 28.50 120.00 9.00 2018 科创板 30.00 30.00 30.00 30.00 2019 中小板 100.00 131.32 2,270.93 20.00 2019 主板 98.00 219.77 22,900.00 4.00 2019 创业板 80.00 95.94 900.00 8.00 2019 北交所 20.00 27.95 220.00 7.00 2019 科创板 70.00 87.80 660.00 15.00 2020 中小板 100.00 135.82 2,423.78 30.00 2020 主板 100.00 218.44 23,700.00 4.00 2020 创业板 80.00 97.08 1,075.00 10.00 2020 北交所 27.00 31.41 130.00 9.00 2020 科创板 70.00 86.57 690.00 15.00 2021 中小板 110.00 140.79 2,244.59 31.80 2021 主板 100.00 212.40 17,600.00 3.50 2021 创业板 80.00 103.79 1,200.00 10.00 2021 北交所 40.00 39.59 130.00 9.00 2021 科创板 70.00 97.58 2,032.46 20.00 2022 中小板 100.00 132.69 763.00 43.00 2022 主板 100.70 332.72 14,800.00 11.74 2022 创业板 71.00 98.37 448.00 40.00 2022 北交所 36.50 38.41 60.00 14.80 2022 科创板 72.10 106.98 636.00 30.00 ( 注： 2022 年数据截止至 2023 年3月 27 日，大部分数据暂未公布 ) ","date":"2023-03-28","objectID":"/posts/20230328110553-%E4%B8%8A%E5%B8%82%E5%85%AC%E5%8F%B8%E5%AE%A1%E8%AE%A1%E6%94%B6%E8%B4%B9%E4%B8%8E%E6%8A%A5%E8%A1%A8%E7%A7%91%E7%9B%AE%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90/:2:0","tags":["python"],"title":"上市公司审计收费与报表科目相关性分析","uri":"/posts/20230328110553-%E4%B8%8A%E5%B8%82%E5%85%AC%E5%8F%B8%E5%AE%A1%E8%AE%A1%E6%94%B6%E8%B4%B9%E4%B8%8E%E6%8A%A5%E8%A1%A8%E7%A7%91%E7%9B%AE%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"审计收费中位数年分布图 根据上表数据，我们画出中位数年波动图： 可以看到从 2019 年开始主板、中小板、创业板、科创板的审计收费中位数基本上就没有增长了，仅北交所收费有所增长。 审计已经收不起来费了。 从 2021 年上市公司年报审计收费数据来看，主板和中小板收费在 100 万，创业板收费 80 万，科创板收费 70 万，北交所收费 40 万，就算是中游水平了。 ","date":"2023-03-28","objectID":"/posts/20230328110553-%E4%B8%8A%E5%B8%82%E5%85%AC%E5%8F%B8%E5%AE%A1%E8%AE%A1%E6%94%B6%E8%B4%B9%E4%B8%8E%E6%8A%A5%E8%A1%A8%E7%A7%91%E7%9B%AE%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90/:3:0","tags":["python"],"title":"上市公司审计收费与报表科目相关性分析","uri":"/posts/20230328110553-%E4%B8%8A%E5%B8%82%E5%85%AC%E5%8F%B8%E5%AE%A1%E8%AE%A1%E6%94%B6%E8%B4%B9%E4%B8%8E%E6%8A%A5%E8%A1%A8%E7%A7%91%E7%9B%AE%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"2021年审计收费箱型图分析 我们再画一个 2021 年审计收费的箱型图，更直观看下收费水平： 箱型图（Box plot），也叫盒须图，是一种用于可视化数据分布的图表。它展示了数据的五个关键统计量：最小值、最大值、中位数、上四分位数和下四分位数，并使用一组箱子和线条来表示这些统计量。 箱型图中实体部分由Q1(25%)-Q3(75%)分位线组成，实体中间横线表示中位数。只要超过实体部分，那就超过了75%的项目收费了。 所以如果是主板超过 178 万、中小板超过 158 万、创业板超过 120 万、科创板超过 100 万、北交所超过 50 万，那就超过75%同板块的收费了，应该算收费比较高的大项目了。 ","date":"2023-03-28","objectID":"/posts/20230328110553-%E4%B8%8A%E5%B8%82%E5%85%AC%E5%8F%B8%E5%AE%A1%E8%AE%A1%E6%94%B6%E8%B4%B9%E4%B8%8E%E6%8A%A5%E8%A1%A8%E7%A7%91%E7%9B%AE%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90/:4:0","tags":["python"],"title":"上市公司审计收费与报表科目相关性分析","uri":"/posts/20230328110553-%E4%B8%8A%E5%B8%82%E5%85%AC%E5%8F%B8%E5%AE%A1%E8%AE%A1%E6%94%B6%E8%B4%B9%E4%B8%8E%E6%8A%A5%E8%A1%A8%E7%A7%91%E7%9B%AE%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"高收费项目所在会计师事务所 我们以上面超过 178 万认为高收费项目，统计 2021 年高收费项目超过 10 个的会计师事务所： select audit_agency,format(sum(audit_fees),2) 大项目收费, count(1) 大项目数量, format(sum(audit_fees)/count(1),2) 平均单价 from audit_fees where end_date='2021-12-31' and audit_fees\u003e=1780000 group by audit_agency having count(1)\u003e=10 order by sum(audit_fees) desc ( 注：使用数据中 2021 年有 268 个上市公司审计收费缺失，另外存在审计机构为会计师分所等多个名称情况，统计数据可能不准确，仅作参考） 执行结果： 四大仍然占据着收费高的大项目， 2021 年4个上亿审计收费的银行、保险、电信行业均是四大审计。 其次就是立信、天健、信永中和、大华、容诚、致同、天职、大信、中审众环等国内大所。 ","date":"2023-03-28","objectID":"/posts/20230328110553-%E4%B8%8A%E5%B8%82%E5%85%AC%E5%8F%B8%E5%AE%A1%E8%AE%A1%E6%94%B6%E8%B4%B9%E4%B8%8E%E6%8A%A5%E8%A1%A8%E7%A7%91%E7%9B%AE%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90/:5:0","tags":["python"],"title":"上市公司审计收费与报表科目相关性分析","uri":"/posts/20230328110553-%E4%B8%8A%E5%B8%82%E5%85%AC%E5%8F%B8%E5%AE%A1%E8%AE%A1%E6%94%B6%E8%B4%B9%E4%B8%8E%E6%8A%A5%E8%A1%A8%E7%A7%91%E7%9B%AE%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"审计收费相关性分析 接着我们回到主题，审计收费究竟与什么报表科目最相关？ 这里我们是将资产负债表、利润表、审计收费拼成一张大表，计算各字段之间的相关系统矩阵，找出相关系统最大值的科目名称。 import pandas as pd df = pd.read_csv('your_data.csv') df = df.fillna(0) corr = df.corr() corr.to_excel('相关系统矩阵.xlsx') print('over') 执行后我们可以得到相关系数矩阵如下： 筛选出和审计收费相关系数最高的 10 个报表科目如下： 科目名称 相关系数 期末总股本 0.889652237 利润总额 0.836708374 营业利润 0.835990408 净利润(含少数股东损益) 0.834132119 负债及股东权益总计 0.812169663 资产总计 0.812169662 应付职工薪酬 0.811363931 综合收益总额 0.809026198 负债合计 0.806048206 现金及存放中央银行款项 0.80327793 通常情况下，以下规则适用于相关性系数的判断： 相关性系数的绝对值小于0.3表示相关性很弱。相关性系数的绝对值在0.3和 0.7 之间表示相关性中等。相关性系数的绝对值大于等于0.7表示相关性很强。但是需要注意的是，这些规则只是一般性的判断，具体情况需要根据数据的实际情况来判断。另外，需要注意的是，相关系数只是反映了变量之间的线性相关性，而不是其他可能存在的关系，例如非线性相关性、因果关系等。 因此，在使用相关系数来分析数据时，需要综合考虑数据的实际情况和背景知识，以及其他可能存在的关系，而不是仅仅依赖于相关系数的大小来做出结论。 结合上述数据和实务，上市公司的利润和资产规模与审计收费相关性最强。 ","date":"2023-03-28","objectID":"/posts/20230328110553-%E4%B8%8A%E5%B8%82%E5%85%AC%E5%8F%B8%E5%AE%A1%E8%AE%A1%E6%94%B6%E8%B4%B9%E4%B8%8E%E6%8A%A5%E8%A1%A8%E7%A7%91%E7%9B%AE%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90/:6:0","tags":["python"],"title":"上市公司审计收费与报表科目相关性分析","uri":"/posts/20230328110553-%E4%B8%8A%E5%B8%82%E5%85%AC%E5%8F%B8%E5%AE%A1%E8%AE%A1%E6%94%B6%E8%B4%B9%E4%B8%8E%E6%8A%A5%E8%A1%A8%E7%A7%91%E7%9B%AE%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"相关数据下载 我将本文使用到的数据分享大家： ","date":"2023-03-28","objectID":"/posts/20230328110553-%E4%B8%8A%E5%B8%82%E5%85%AC%E5%8F%B8%E5%AE%A1%E8%AE%A1%E6%94%B6%E8%B4%B9%E4%B8%8E%E6%8A%A5%E8%A1%A8%E7%A7%91%E7%9B%AE%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90/:7:0","tags":["python"],"title":"上市公司审计收费与报表科目相关性分析","uri":"/posts/20230328110553-%E4%B8%8A%E5%B8%82%E5%85%AC%E5%8F%B8%E5%AE%A1%E8%AE%A1%E6%94%B6%E8%B4%B9%E4%B8%8E%E6%8A%A5%E8%A1%A8%E7%A7%91%E7%9B%AE%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"2000-2022年上市公司资产负债表 https://wwds.lanzoum.com/b01ql5e7a 密码:bh0s ","date":"2023-03-28","objectID":"/posts/20230328110553-%E4%B8%8A%E5%B8%82%E5%85%AC%E5%8F%B8%E5%AE%A1%E8%AE%A1%E6%94%B6%E8%B4%B9%E4%B8%8E%E6%8A%A5%E8%A1%A8%E7%A7%91%E7%9B%AE%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90/:7:1","tags":["python"],"title":"上市公司审计收费与报表科目相关性分析","uri":"/posts/20230328110553-%E4%B8%8A%E5%B8%82%E5%85%AC%E5%8F%B8%E5%AE%A1%E8%AE%A1%E6%94%B6%E8%B4%B9%E4%B8%8E%E6%8A%A5%E8%A1%A8%E7%A7%91%E7%9B%AE%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"2000-2022年上市公司利润表 https://wwds.lanzoum.com/b01ql5ejc 密码:b3ju ","date":"2023-03-28","objectID":"/posts/20230328110553-%E4%B8%8A%E5%B8%82%E5%85%AC%E5%8F%B8%E5%AE%A1%E8%AE%A1%E6%94%B6%E8%B4%B9%E4%B8%8E%E6%8A%A5%E8%A1%A8%E7%A7%91%E7%9B%AE%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90/:7:2","tags":["python"],"title":"上市公司审计收费与报表科目相关性分析","uri":"/posts/20230328110553-%E4%B8%8A%E5%B8%82%E5%85%AC%E5%8F%B8%E5%AE%A1%E8%AE%A1%E6%94%B6%E8%B4%B9%E4%B8%8E%E6%8A%A5%E8%A1%A8%E7%A7%91%E7%9B%AE%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"2008年-2022年上市公司审计收费 https://wwds.lanzoum.com/b01ql5fdc 密码:e0zu ","date":"2023-03-28","objectID":"/posts/20230328110553-%E4%B8%8A%E5%B8%82%E5%85%AC%E5%8F%B8%E5%AE%A1%E8%AE%A1%E6%94%B6%E8%B4%B9%E4%B8%8E%E6%8A%A5%E8%A1%A8%E7%A7%91%E7%9B%AE%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90/:7:3","tags":["python"],"title":"上市公司审计收费与报表科目相关性分析","uri":"/posts/20230328110553-%E4%B8%8A%E5%B8%82%E5%85%AC%E5%8F%B8%E5%AE%A1%E8%AE%A1%E6%94%B6%E8%B4%B9%E4%B8%8E%E6%8A%A5%E8%A1%A8%E7%A7%91%E7%9B%AE%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"前面玩过了 chatgpt ，这两天我又试用了下 AI 在绘图方面的效果。 我尝试了两款工具：=Midjourney= ，=stable-diffusion-webui= 。 Midjourney 是一个商业应用，注册后在浏览器上输入一些prompt 提示词，就可以生成 4 张图片。 你可以选择其中一张不断深度调整，得到你想要的。 比如我用翻译软件翻译了“一个骑在火箭上的审计师，超现实”后，输入“An auditor riding a rocket in the pride of space. surrealism –ar 2:1”。 就可以给我非常不错的图案。 不过 Midjourney 是一个商业网站，免费额度有限，而且免费生成的图不能商用。 不过它确实最容易上手，只需要看看 B 站上的教学视频，能正确上网就可以使用，出的图也非常不错。 然后，我又试用了开源免费的stable-diffusion-webui, 它可以在本地部署，需要有比较好的显卡。 正好我台式机有张 3080 显卡，照着 github 上的安装教程进行了安装。 这个过程稍微比较复杂，需要的时间也比较久。 安装好后，可以在本地的浏览器上打开，同样的可以输入一些文字，直接出图。 刚安装的时候使用的模型出的图不是很好，可以在civitai 网站上找一些模型。 这个过程比较麻烦，需要在网上看大量教程。 不过我也就折腾了下面三个： Stable Diffusion 模型（ modules ）：不同的图像生成算法。 Embedding 嵌入式：将某个风格的描述文字 prompt 用一个词代替，可以重复使用一种风格。 Lora: 生成不同风格的算法。 后面两个在点击“生成”下面像照片一样的按钮后就可以看到相关信息。需要在civitai 网站上去下载对应的包，拷贝到本地对应文件夹中就可以使用。 我看了很多网上教程，也就只折腾了上面三项内容，不过这已经让我感受到他的强大了。 比如，我想生成“一张桌子上有电子计算器和审计报告”的图片，直接输入： (high quality,masterpiece,detail),Finance,Electronic Calculator and audit report on the desk with Greenery. Style-Info 大概 4 、5秒就给我出了 4 张图（主要看显卡性能） 基本上 1 、2秒就可以出一张图，真的太强了。 在 civitai 上你可以看到太多风格的图了，我们都可以在本地上生成类似的。 展示下今天生成的部分图片： 我玩了一天，已经沉迷其中了。 ","date":"2023-03-20","objectID":"/posts/20230319232329-%E5%88%A9%E7%94%A8ai%E7%94%9F%E6%88%90%E5%9B%BE%E7%89%87/:0:0","tags":["stable-diffusion"],"title":"利用AI生成图片","uri":"/posts/20230319232329-%E5%88%A9%E7%94%A8ai%E7%94%9F%E6%88%90%E5%9B%BE%E7%89%87/"},{"categories":["生活"],"content":" 爷爷是一名阴阳先生，因为肺癌于阳历 2 月13日走了，遵从他算的日子今天将他安葬。 该做的已经都做了。我还是比较理性，没有过多悲伤，也许这对于他来说少受折磨。 去世那天媳妇一直哭，她在朋友圈发了自己的怀念之词。 这里借用媳妇的感言，悼念爷爷。 记得第一次以女朋友身份来时，爷爷拉着我，扒拉出一张九宫格样的纸，认真确认我的生辰八字和孙子的来合。 边写写画画边露出满意的笑容，当初心想这风水协会的名誉主席给未来孙媳妇的见面礼果真不一般噶。 然后他严肃和身边的孙子说：“我说夹冰啊，你流年 35 要走桃花，你可不能太得意去给老子外边沾花惹草啊！”孙子嬉笑着挠了挠头，“嘿！你娃儿笑啥子哟！我认真和你说话呢，我们 T 家可不兴这家风。”爷爷严肃地说。 我就在想，这爷爷还真可以有哈，万一哪天真花天酒地了，也有他替我先打断孙子的腿。 爷爷与时俱进，活到老学到老的精神一直鞭策着我们年轻一代。 八十好几还刷短视频关心天下大小事，智能机各种功能还能麻溜地操作，甚至我还惊讶不到年尾他收付款总额会超 VX 限额。 回老家时，他不是出去忙就是在家钻研自己喜欢的书籍，当然这些也是他的饭碗。 闲暇时间会慢悠慢悠点杆烟咳嗽着他的老烟嗓和我们谈笑风生，这个老顽童开起玩笑来每个点都能戳中我的笑点。 他似乎里里外外都能干得了，砍下竹子麻溜捆扎好拖回家，不到一下午功夫，几个好看又实用的竹筛，箩筐背篓就到位了。 四川的抄手是他教我包成元宝状的，饺子是他告诉我还有其他不同的包法，肉包子告诉我调馅，烧白甜肉给我手写教程配方，蒸的醪糟配汤圆很香，折腾蜂箱酿的土蜂蜜很甜…文化不太高可硬笔软笔字都写的忒好，对了好像还有治疗胃病和医乳腺炎的偏方还没教我，他心里更是装满了我们大家庭的老老少少，总之就是我心里的完美爷爷。 和婆婆相濡以沫白头偕老了几十年，顾家的爷爷似乎从未和婆婆拌嘴红脸过，一致让我认为婆婆是最幸福的女人。 去年底陪爷爷去医院检查，拿到不好的确诊结果。我站在病房外平复了好一会深呼吸才踏进去，见到他时眼泪不争气绷不住地流，却换他来不断给我灌输生死观安慰我 前几天因为孩子开学要走了，去看望爷爷，拉着他被点滴扎满淤青的手，虽然没什么力气了，但能感受到他用尽了全身力气握紧我，也是这一握成了我们的永别。 昨晚做了梦，梦里爷爷在和我们捉迷藏，很多人陪着好像是要走了，又好像是没有。上午忙完开学事情，总觉得梦境不好下午和妈打电话问情况，妈说昨晚爷爷一直叫我名字，家人问什么事也没说出来。爷爷您是可惜这么些年教我的风水知识白瞎了？遗憾我没能成为您得意的关门女弟子吗？？！说的好好的突然间妈挂了电话，说爸守着爷爷那边不行了，立马赶去了医院，就这样，我算是电话聊着与爷爷的相关和爷爷说了天上和人间的再见！ 爷爷兴许是累了吧，他要藏起来了，我们倒想这是个捉迷藏的游戏，我们想您时，您要即刻结束游戏，慈祥微笑地朝我们挥手走来，要说享福您确实没有，说苦了一辈子也无不是。 两个孩子看到我在家失声痛哭，来给我拥抱给我安慰，让妈妈别哭了，男祖祖走了还有女祖祖陪我们，虽然她没了男祖祖会很伤心，但我们会珍惜女祖祖爱她照顾她。 从几岁孩子口中出来的一番话把我感动了，趁机给他们上了一堂关于生命的课。 希望孩子能从真实不虚的生活中懂得生命的意义，敬重生命是世间最大的事，享受生命的同时也要学会去珍惜，去感恩。 让祖祖平日里教我们的——衣食是大事，勤俭是美德，心静是大气，善良是大爱，宽容是真情的良好家风一直传承下去！ 爷爷，这会您来时的路和归去的路我们都已给您点亮了 ","date":"2023-03-14","objectID":"/posts/20230314204739-%E6%82%BC%E5%BF%B5%E7%88%B7%E7%88%B7/:0:0","tags":["杂文"],"title":"悼念爷爷","uri":"/posts/20230314204739-%E6%82%BC%E5%BF%B5%E7%88%B7%E7%88%B7/"},{"categories":["工作"],"content":"如果你阅读过《把你的英语用起来》，那么你会了解“透析法”习得英语词汇。 今天就给大家安利一款浏览器插件Relingo，让你不再怕英文阅读。 也许你以前用过很多翻译插件，不认识的单词可以一键查询，或者直接翻译整段甚至整篇的文章。 我之前也是用的类似的插件，例如：沙拉查词。 但这些插件会有些问题，当生词很多的时候，查词会影响打断阅读体验。 而如果整篇翻译，那么将失去阅读英文原文的意义。 而这个插件，彻底改变了这一现状。 ","date":"2023-03-12","objectID":"/posts/20230312231334-%E9%80%9A%E8%BF%87%E9%98%85%E8%AF%BB%E4%B9%A0%E5%BE%97%E8%8B%B1%E8%AF%AD_%E6%8F%92%E4%BB%B6%E5%8A%A9%E6%89%8Brelingo/:0:0","tags":["英语"],"title":"通过阅读习得英语，插件助手Relingo","uri":"/posts/20230312231334-%E9%80%9A%E8%BF%87%E9%98%85%E8%AF%BB%E4%B9%A0%E5%BE%97%E8%8B%B1%E8%AF%AD_%E6%8F%92%E4%BB%B6%E5%8A%A9%E6%89%8Brelingo/"},{"categories":["工作"],"content":"自动标注生词 当你初始安装插件时，会让你选择你的英语水平，它会根据你的英语水平去猜测你的生词。 它将这些生词会标注出来，并显示期中文含义，直接省去了查词的步骤，可以专注于阅读。 当有些“生词”是你认识的时候，你不想显示中文，可以将鼠标停留在单词上，它会显示含义，直接点击“掌握”，以后就不再出现了。 ","date":"2023-03-12","objectID":"/posts/20230312231334-%E9%80%9A%E8%BF%87%E9%98%85%E8%AF%BB%E4%B9%A0%E5%BE%97%E8%8B%B1%E8%AF%AD_%E6%8F%92%E4%BB%B6%E5%8A%A9%E6%89%8Brelingo/:1:0","tags":["英语"],"title":"通过阅读习得英语，插件助手Relingo","uri":"/posts/20230312231334-%E9%80%9A%E8%BF%87%E9%98%85%E8%AF%BB%E4%B9%A0%E5%BE%97%E8%8B%B1%E8%AF%AD_%E6%8F%92%E4%BB%B6%E5%8A%A9%E6%89%8Brelingo/"},{"categories":["工作"],"content":"手动查询生词及翻译 如果有些词它没有标注，但是你又不认识，你可以双击或者鼠标划词，将会显示含义，点击“添加生词”，后续这个词就是显示翻译。 如果想翻译整段文字，可以直接点击下左侧的图标（一般鼠标悬停就会出现），将翻译整段文字。 ","date":"2023-03-12","objectID":"/posts/20230312231334-%E9%80%9A%E8%BF%87%E9%98%85%E8%AF%BB%E4%B9%A0%E5%BE%97%E8%8B%B1%E8%AF%AD_%E6%8F%92%E4%BB%B6%E5%8A%A9%E6%89%8Brelingo/:2:0","tags":["英语"],"title":"通过阅读习得英语，插件助手Relingo","uri":"/posts/20230312231334-%E9%80%9A%E8%BF%87%E9%98%85%E8%AF%BB%E4%B9%A0%E5%BE%97%E8%8B%B1%E8%AF%AD_%E6%8F%92%E4%BB%B6%E5%8A%A9%E6%89%8Brelingo/"},{"categories":["工作"],"content":"导出生词 打开插件，可以选择自己的生词本，你还可以将生词导出成 Anki ，可以随时复习记忆（注：该功能为付费功能）。 ","date":"2023-03-12","objectID":"/posts/20230312231334-%E9%80%9A%E8%BF%87%E9%98%85%E8%AF%BB%E4%B9%A0%E5%BE%97%E8%8B%B1%E8%AF%AD_%E6%8F%92%E4%BB%B6%E5%8A%A9%E6%89%8Brelingo/:3:0","tags":["英语"],"title":"通过阅读习得英语，插件助手Relingo","uri":"/posts/20230312231334-%E9%80%9A%E8%BF%87%E9%98%85%E8%AF%BB%E4%B9%A0%E5%BE%97%E8%8B%B1%E8%AF%AD_%E6%8F%92%E4%BB%B6%E5%8A%A9%E6%89%8Brelingo/"},{"categories":["工作"],"content":"翻译字幕 如果你在 Youtube 上学习，它还可以自动翻译字幕，同时也像阅读文章一样标注字幕上的生词。 ","date":"2023-03-12","objectID":"/posts/20230312231334-%E9%80%9A%E8%BF%87%E9%98%85%E8%AF%BB%E4%B9%A0%E5%BE%97%E8%8B%B1%E8%AF%AD_%E6%8F%92%E4%BB%B6%E5%8A%A9%E6%89%8Brelingo/:4:0","tags":["英语"],"title":"通过阅读习得英语，插件助手Relingo","uri":"/posts/20230312231334-%E9%80%9A%E8%BF%87%E9%98%85%E8%AF%BB%E4%B9%A0%E5%BE%97%E8%8B%B1%E8%AF%AD_%E6%8F%92%E4%BB%B6%E5%8A%A9%E6%89%8Brelingo/"},{"categories":["工作"],"content":"价格 这个插件基础功能是免费的，基本上免费的就够使用了。 但当我看到它的时候，我太喜欢了，所以就直接购买了终身版的早鸟价：49.99美元，差不多 300 多。 其实Relingo的功能并不复杂，但很难得的是它给了我们阅读英文的沉浸式体验，让我们在阅读长篇英文的时候不再害怕。 ","date":"2023-03-12","objectID":"/posts/20230312231334-%E9%80%9A%E8%BF%87%E9%98%85%E8%AF%BB%E4%B9%A0%E5%BE%97%E8%8B%B1%E8%AF%AD_%E6%8F%92%E4%BB%B6%E5%8A%A9%E6%89%8Brelingo/:5:0","tags":["英语"],"title":"通过阅读习得英语，插件助手Relingo","uri":"/posts/20230312231334-%E9%80%9A%E8%BF%87%E9%98%85%E8%AF%BB%E4%B9%A0%E5%BE%97%E8%8B%B1%E8%AF%AD_%E6%8F%92%E4%BB%B6%E5%8A%A9%E6%89%8Brelingo/"},{"categories":["工作"],"content":"前面提到过在上上个项目中，客户给了订单数据的数据库，有 500 多张表。 让 chatgpt 写了段批量将数据下载的代码： import pymysql import pandas as pd # 建立 MySQL 数据库连接 conn = pymysql.connect( host='your_host', db='your_db_name', user='user', passwd='password', charset='utf8') # 循环遍历每个表，导出为 CSV 文件 for i in range(512): try: print(\"开始第%s张表\" % i) table_name = f\"chapter_orders{i}\" query = \"select * from {table_name}\" df = pd.read_sql(query, conn) file_name = f\"{table_name}.csv\" df.to_csv(file_name, index=False) except: pass # 关闭数据库连接 conn.close() 但是同事并没有这么做，因为她笔记本就 256G 的硬盘，空间不够。 而她在客户提供的 msyql 数据库中，把每几十张表需要的字段合成一张大表，大概合了 8 张表。 但是后面发现执行的语句有误，需要重新跑所有的数据，而刚好她在合并表的并没有加需要的字段。 让她本地搞吧，但是一张表下载下来 200 多M， 500 多张表要 100 多G，她电脑根本不行。 就算她下载下来，自己笔记本用 mysql 也搞不定这么大的数据量。 让她在客户提供的数据库上重新再来一遍吧，又不知道要费多少工夫。 头疼。 我自己来吧。 先是执行上述 python 代码，将 500 多张表下载到我笔记本上，花费大概 30 多个小时。 然后在笔记本上开启大数据杀器， clickhouse 。 写个 Bash 脚本，批量将 500 多个 CSV 文件导入clickhouse. for file in *.csv; do sed -n '2,$p' \"$file\" | clickhouse client --query 'insert into chapter FORMAT CSV' --date_time_input_format=best_effort echo \"$file\" done clickhouse导入数据比 mysql 快多了，大概 200 多M的 csv 文件，平均 2 秒一个。 用 DBeaver 连接 clickhouse ，就可以写 SQL 了。 看一下数据量： select count(1) from chapter; 共计：895,049,813 接近 9 亿行数据。 只需要 2 秒就能跑出上面结果，很难想象用 mysql 跑个 9 亿的数据是怎么样。而且还是我这个 2019 年出厂的联想小新 pro 的笔记本上。 在笔记本上跑个稍微复杂点的 SQL ，也一般不超过 30 秒就出结果。 clickhouse,YYDS。 只要是上千万的数据，我感觉用它都更加方便，省时。 再比如上个项目，同事两个百万级的表也 join 反应不出来，电脑直接崩死。 有时候感觉心累，反应不出来，我也不能怪人。电脑容量不够，我也没法提供电脑。有些客户要个数据都难，更别说让他们提供服务器了。就算提供服务器了，给你搭建个 mysql 环境，大数据量下，照样跑不出来。 其实想想，不会也有不会的好处，没有哪个项目会因为技术问题而停滞。 会有会的做法，不会有不会的做法。 开心就好。 ","date":"2023-03-08","objectID":"/posts/20230308220543-5000%E5%85%83%E7%AC%94%E8%AE%B0%E6%9C%AC%E5%A4%84%E7%90%868%E4%BA%BF%E8%A1%8C%E6%95%B0%E6%8D%AE%E9%87%8F/:0:0","tags":["clickhouse"],"title":"5000元笔记本处理8亿行数据量","uri":"/posts/20230308220543-5000%E5%85%83%E7%AC%94%E8%AE%B0%E6%9C%AC%E5%A4%84%E7%90%868%E4%BA%BF%E8%A1%8C%E6%95%B0%E6%8D%AE%E9%87%8F/"},{"categories":["工作"],"content":"前面发过 chatgpt 几篇文章： \u003cAI改变未来的审计\u003e \u003cchatgpt在会计师事务所中的运用 - 审计篇\u003e \u003cchatgpt在会计师事务所中的运用 -IT 审计篇\u003e 后面如果有机会，可能会写写咨询篇、税务篇、造价篇。 不过这些工作我不是特别熟悉，有机会所内的同事可以和我交流交流，有使用场景的话，我可以再写文章。 当然很多朋友看了文章，但是没法使用心里也痒痒的，确实 chatgpt 在国内是无法访问的。 世面上有很多借这波热度做了很多小程序、 app 来骗流量、骗钱的。 要知道 chatgpt 官网:https://chat.openai.com/chat 是免费使用的。 今天一个朋友给我发了个国内可以免费使用 chatgpt 的网站，我试了下，确实可用。 想尝试的会计师事务所的朋友可以尝试尝试： 网址：https://xc.com/ (点击文末“阅读原文”就可以访问） 在电脑上或者手机上都可以访问、提问。 不需要注册、不需要魔法、不需要钱！ 不过我大概试了下，这个网站有两个问题： 速度比较慢。相比 chatgpt 官网，回答速度慢了很多，不过作为尝试，还是可以忍受。 好像不能理解上下文。 这一点比较致命，因为 chatgpt 精髓就是能理解上下文，能通过对话聊出你需要的东西。 可以看到这个网站，并不能记忆前面我问过的问题。 作为对比， chatgpt 是可以正确理解上下文的： 实际上 chatgpt 官网你可以创建多个对话，在每一个对话内，他都知道你前面问过什么，可以像人一样聊天。当需要问一个新的无关的话题时，只需要新建一个 chat 。 所以如果没有上下文联系的话， chatgpt 的能力只能发挥30%。 不过大家作为一个免费替代和尝试也是不错的。 最后再贴下网址： https://xc.com/ ","date":"2023-03-07","objectID":"/posts/20230307215212-%E5%9B%BD%E5%86%85%E5%8F%AF%E4%BB%A5%E5%85%8D%E8%B4%B9%E4%BD%BF%E7%94%A8chatgpt%E7%9A%84%E7%BD%91%E7%AB%99/:0:0","tags":["chatgpt"],"title":"国内可以免费使用chatgpt的网站","uri":"/posts/20230307215212-%E5%9B%BD%E5%86%85%E5%8F%AF%E4%BB%A5%E5%85%8D%E8%B4%B9%E4%BD%BF%E7%94%A8chatgpt%E7%9A%84%E7%BD%91%E7%AB%99/"},{"categories":["工作"],"content":"最近在做一个电商项目的 IT 审计，其中涉及很多业财数据核对工作。 例如: 第三方电商平台与电商 ERP 系统订单核对 电商 ERP 系统订单与出库单核对 电商 ERP 系统订单与第三方支付流水数据核对 电商 ERP 系统订单与财务收入核对 等等。 这期间，我关注到一个以前我并没有太关注的一个问题，那就是数据清洗。 尤其是第三方支付数据，比如微信支付、支付宝支付，企业提供的这些数据，面临几个困难点。 文件多。一个账号可能按月导就 12 个文件，那么多个账号文件数量就比较庞大了。 脏数据多。导出来的文件前几行是一些非数据的说明文字，文件后几行是非数据的汇总信息。中间数据中也有些特殊符号，如`直接导入数据库会影响计算。 其实这种数据清洗工作，由小朋友来处理，并不能处理非常好。因为他们采用人工处理，而人工必定会出错。 因此，针对这些数据清洗的问题，我们采用 Bash 脚本来批量处理。 如果你使用的 Mac 或者 Linux 系统，天然自带 Bash 脚本(shell)，也就是终端。 如果你使用的 Windows 系统，你可以在软件商店安装 wsl ，也就是一个 Linux 子系统,如 ubuntu 发行版。 我们以上图中支付宝流水为例，介绍如何进行数据清洗工作。 假设文件名为 test.csv ","date":"2023-03-06","objectID":"/posts/20230306224629-%E7%94%B5%E5%95%86it%E5%AE%A1%E8%AE%A1%E4%B8%AD%E7%9A%84%E7%AC%AC%E4%B8%89%E6%96%B9%E6%94%AF%E4%BB%98%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/:0:0","tags":["IT审计"],"title":"电商IT审计中的第三方支付数据清洗","uri":"/posts/20230306224629-%E7%94%B5%E5%95%86it%E5%AE%A1%E8%AE%A1%E4%B8%AD%E7%9A%84%E7%AC%AC%E4%B8%89%E6%96%B9%E6%94%AF%E4%BB%98%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/"},{"categories":["工作"],"content":"掐头 文件中数据是从第 5 行开始的，因此我们需要丢弃掉前 4 行数据。 我们在终端中输入命令: tail -n +5 test.csv \u003e new.csv tail 命令用于打印文件的末尾几行。 -n 选项用于指定要打印的行数。在 -n 选项后使用+符号，后跟一个数字，表示从该行数开始打印文件的末尾行。例如，tail -n +5 表示打印文件从第 5 行开始到文件末尾的所有行。 (注：tail -n 数字本身表示打印文件末尾几行） 执行命令后，我们可以看到已经把头掐掉了。 ","date":"2023-03-06","objectID":"/posts/20230306224629-%E7%94%B5%E5%95%86it%E5%AE%A1%E8%AE%A1%E4%B8%AD%E7%9A%84%E7%AC%AC%E4%B8%89%E6%96%B9%E6%94%AF%E4%BB%98%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/:1:0","tags":["IT审计"],"title":"电商IT审计中的第三方支付数据清洗","uri":"/posts/20230306224629-%E7%94%B5%E5%95%86it%E5%AE%A1%E8%AE%A1%E4%B8%AD%E7%9A%84%E7%AC%AC%E4%B8%89%E6%96%B9%E6%94%AF%E4%BB%98%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/"},{"categories":["工作"],"content":"去尾 但是文件末尾的 4 行是我们不需要的，我们还要去尾。 我们在终端中输入命令： head -n -4 test.csv \u003e new.csv head 命令用于打印文件的前几行。 -n 选项用于指定要打印的行数。- 符号，后跟一个数字，表示打印一定数量的行，但不包括文件的最后几行。 （注：head -n 数字，本身表示打印文件前几行） 执行后，我们可以看到，已经把尾去掉了。 ","date":"2023-03-06","objectID":"/posts/20230306224629-%E7%94%B5%E5%95%86it%E5%AE%A1%E8%AE%A1%E4%B8%AD%E7%9A%84%E7%AC%AC%E4%B8%89%E6%96%B9%E6%94%AF%E4%BB%98%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/:2:0","tags":["IT审计"],"title":"电商IT审计中的第三方支付数据清洗","uri":"/posts/20230306224629-%E7%94%B5%E5%95%86it%E5%AE%A1%E8%AE%A1%E4%B8%AD%E7%9A%84%E7%AC%AC%E4%B8%89%E6%96%B9%E6%94%AF%E4%BB%98%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/"},{"categories":["工作"],"content":"掐头去尾 当然，以上是分开的两步，实际上我们可以合成一步操作。 只需要用到管道命令|。 tail -n +5 test.csv | head -n -4 \u003e new.csv 这里的管道命令|，可以将一个命令的输出作为另一个命令的输入，从而使多个命令可以协作完成某个任务。 执行命令后： 这样，我们就完成了单个文件的任务。 ","date":"2023-03-06","objectID":"/posts/20230306224629-%E7%94%B5%E5%95%86it%E5%AE%A1%E8%AE%A1%E4%B8%AD%E7%9A%84%E7%AC%AC%E4%B8%89%E6%96%B9%E6%94%AF%E4%BB%98%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/:3:0","tags":["IT审计"],"title":"电商IT审计中的第三方支付数据清洗","uri":"/posts/20230306224629-%E7%94%B5%E5%95%86it%E5%AE%A1%E8%AE%A1%E4%B8%AD%E7%9A%84%E7%AC%AC%E4%B8%89%E6%96%B9%E6%94%AF%E4%BB%98%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/"},{"categories":["工作"],"content":"批量处理文件 然而，我们需要这样处理的文件不只是一个，可能是几十上百个。 我们只需要在上面知识基础上增加一个循环。 在 bash 脚本中，循环的语法是： for variable in list do commands done 还有需要注意的是，每个文件第 5 行都是表头，我合并的时候，只需要保留一个表头，要实现这一点，我们还需要一个变量，让第一个文件从第 5 行输出，后面的文件都从第 6 行输出。 而 Bash 脚本中使用变量很简单： a=1 echo $a 我们要给变量赋值只需要a=1 ,而要引用变量时，就加个 $符号。 上述代码执行会，打印显示出数字 1 。 我们将以上所有知识串联起来： offset=5 head=4 for file in *.csv; do tail -n +$offset \"$file\" | head -n -$head \u003e\u003e 账务明细汇总.csv offset=6 done 将上面代码粘贴到终端回车运行后，将处理所有的 csv 文件并输出到账务明细汇总.csv文件中。 需要注意的是\u003e输出到文件会覆盖已存在的，而\u003e\u003e输出到文件是 追加，我们这里是想合并所有文件，所以使用的追加。 可以看出短短几行命令，将可以将成千上万的文件处理并合并。 这比让小朋友一个一个手工处理准确、高效多了。 ","date":"2023-03-06","objectID":"/posts/20230306224629-%E7%94%B5%E5%95%86it%E5%AE%A1%E8%AE%A1%E4%B8%AD%E7%9A%84%E7%AC%AC%E4%B8%89%E6%96%B9%E6%94%AF%E4%BB%98%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/:4:0","tags":["IT审计"],"title":"电商IT审计中的第三方支付数据清洗","uri":"/posts/20230306224629-%E7%94%B5%E5%95%86it%E5%AE%A1%E8%AE%A1%E4%B8%AD%E7%9A%84%E7%AC%AC%E4%B8%89%E6%96%B9%E6%94%AF%E4%BB%98%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/"},{"categories":["工作"],"content":"特殊符号处理 上面讲了掐头去尾的工作,但实际上这些数据中间还有很多特殊字条，如果不处理，将在后面的数据核对中带来很多问题。 例如，每个字段后都有一个制表符。还有像微信流水中每个字段前面都会多一个`特殊符号。 我看到同事在导数前并没有去处理这些，而是在导入数据库后，再用update更新需要用到的字段。个人认为这是非常麻烦的。 而在终端中用 Bash 脚本进行这些文本处理是非常高效的。 我们这里需要使用sed命令。 sed -i 's/被替换的字符/替换的字符/g' 文件名 (注：-i参数代表在原文件上修改，注意备份数据） 我们以去除制表符为例。 sed -i 's/\\t//g' new.csv s 代表 sed 命令的替换操作,这里\\t代表制表符，g 代表全局替换。 我们以去除特殊符号`为例。 sed -i 's/`//g' new.csv 这个命令很简洁，而且需要替换的字符还可以使用正则表达式，非常灵活。 ","date":"2023-03-06","objectID":"/posts/20230306224629-%E7%94%B5%E5%95%86it%E5%AE%A1%E8%AE%A1%E4%B8%AD%E7%9A%84%E7%AC%AC%E4%B8%89%E6%96%B9%E6%94%AF%E4%BB%98%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/:5:0","tags":["IT审计"],"title":"电商IT审计中的第三方支付数据清洗","uri":"/posts/20230306224629-%E7%94%B5%E5%95%86it%E5%AE%A1%E8%AE%A1%E4%B8%AD%E7%9A%84%E7%AC%AC%E4%B8%89%E6%96%B9%E6%94%AF%E4%BB%98%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/"},{"categories":["工作"],"content":"结语 本文介绍了几个实用的 Bash 脚本命令，可以方便解决数据清洗中的难题。 勤快人有勤快人的干法，懒人有懒人的干法， 而我宁愿做一个懒人。 ","date":"2023-03-06","objectID":"/posts/20230306224629-%E7%94%B5%E5%95%86it%E5%AE%A1%E8%AE%A1%E4%B8%AD%E7%9A%84%E7%AC%AC%E4%B8%89%E6%96%B9%E6%94%AF%E4%BB%98%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/:6:0","tags":["IT审计"],"title":"电商IT审计中的第三方支付数据清洗","uri":"/posts/20230306224629-%E7%94%B5%E5%95%86it%E5%AE%A1%E8%AE%A1%E4%B8%AD%E7%9A%84%E7%AC%AC%E4%B8%89%E6%96%B9%E6%94%AF%E4%BB%98%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/"},{"categories":["生活"],"content":"成都的雨只在晚上下， 绵绵的夜雨，如雾漫舞， 凌晨的过道前，吐一口烟， 随风飘散，隐藏在夜色中柔和的街灯的光晕中。 忽明忽暗的烟蒂弹出， 如流星般划过。 成都的雨只在晚上下， 清晨你只见得到潮湿的地面， 也许它只是怕影响第二天出行的社畜。 ","date":"2023-03-05","objectID":"/posts/20230304234506-%E6%88%90%E9%83%BD%E7%9A%84%E9%9B%A8/:0:0","tags":["杂文"],"title":"成都的雨","uri":"/posts/20230304234506-%E6%88%90%E9%83%BD%E7%9A%84%E9%9B%A8/"},{"categories":["工作"],"content":"上篇我们介绍了 chatgpt 对于财务审计有哪些作用，今天我们继续介绍下 chatgpt 在IT审计中的应用。 我个人认为作为会计师事务所的 IT 审计， chatgpt 无疑是一个神器，我们相对其他版块的同事享受到的福利更多。 在 IT 审计工作中，我们日常做得比较多的事情有： 写方案、报告等文字处理工作. 做控制测试工作，涉及到大量 IT 基础知识。 做数据核对分析工作，涉及到写 sql 、python代码。 有了 chatgpt ，相当于有了最高级别的、免费的老师，随时可以指导你的工作。 至少，目前我用了两个月的感觉如此。 那么我们从上述三方面工作入手，看它有多强。 ","date":"2023-03-01","objectID":"/posts/20230228224513-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_it%E5%AE%A1%E8%AE%A1%E7%AF%87/:0:0","tags":["效率","chatpgt"],"title":"chatgpt在会计师事务所中的运用-IT审计篇","uri":"/posts/20230228224513-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_it%E5%AE%A1%E8%AE%A1%E7%AF%87/"},{"categories":["工作"],"content":"写方案 前面有一个国际项目，领导让我写一个英文的信息系统一般控制的 IT 审计方案。 要知道，我看英语还行，但写真不行，大学六级都没有过。 不过不要慌，我有 chatgpt 。 直接给我个框架，然后在此基础上改改，就可以交了。 不过领导还是让外语好的同事修改了下。 至少这也比我从 0 开始强多了。 ","date":"2023-03-01","objectID":"/posts/20230228224513-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_it%E5%AE%A1%E8%AE%A1%E7%AF%87/:1:0","tags":["效率","chatpgt"],"title":"chatgpt在会计师事务所中的运用-IT审计篇","uri":"/posts/20230228224513-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_it%E5%AE%A1%E8%AE%A1%E7%AF%87/"},{"categories":["工作"],"content":"文字润色 之前我写过一篇文章语文水平捉急 其实 chatgpt 可以当我们语文老师的，你只需要把你的一段文字告诉它，让它帮你润色下。 当然，如果你有觉得语言风格更好的文字，可以把数据喂给它，让它模仿。 ","date":"2023-03-01","objectID":"/posts/20230228224513-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_it%E5%AE%A1%E8%AE%A1%E7%AF%87/:2:0","tags":["效率","chatpgt"],"title":"chatgpt在会计师事务所中的运用-IT审计篇","uri":"/posts/20230228224513-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_it%E5%AE%A1%E8%AE%A1%E7%AF%87/"},{"categories":["工作"],"content":"询问专业知识 在 IT 审计中，尤其是ITGC(信息系统一般控制）中涉及到大量 IT 知识，而我们很多从业人员，相关 IT 背景比较缺失。 那么在工作中，我们可以通过向 chatgpt 获取支持。 我们还是以上面“机房管理”为例， 比如，如果我们不清楚 IT 审计中对机房物理环境要求有哪些？需要执行哪些审计程序？需要获取哪些审计证据？ 直接把问题甩给它： 你看，它回答得还是非常不错的。 如果你觉得它回答得比较笼统，你还可以针对某个细节，让他展开说说： 一直问到你觉得可以执行的程度。 （需要注意的是，某些专业知识它可能回答的是错误的，需要辨别） ","date":"2023-03-01","objectID":"/posts/20230228224513-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_it%E5%AE%A1%E8%AE%A1%E7%AF%87/:3:0","tags":["效率","chatpgt"],"title":"chatgpt在会计师事务所中的运用-IT审计篇","uri":"/posts/20230228224513-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_it%E5%AE%A1%E8%AE%A1%E7%AF%87/"},{"categories":["工作"],"content":"辅助写代码 前面一个项目，同事向我求助，企业提供的数据库里的订单数据分成的是 500 多张表，我们要进行分析或者核对需要将这些表合在一起。 我问她：“去年你们怎么做的？” 她说：“去年是 xxx 加班加点几天时间，手工从数据库里导出来，合一起的。” 我说：“那你现在的需求就是批量导数下来，并合在一起嘛?” 这种问题真的太简单了，只需要你会提问，再加上稍微懂一点代码就可以。 你看，这样不就是问一嘴就能批量把数据批量导出来吗? 再问一嘴，怎么合并，就完成了。 当然，你如果想在数据库上完成合并，你照样可以问它。主要看你的需求是什么。 ","date":"2023-03-01","objectID":"/posts/20230228224513-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_it%E5%AE%A1%E8%AE%A1%E7%AF%87/:4:0","tags":["效率","chatpgt"],"title":"chatgpt在会计师事务所中的运用-IT审计篇","uri":"/posts/20230228224513-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_it%E5%AE%A1%E8%AE%A1%E7%AF%87/"},{"categories":["工作"],"content":"代码解说员 如果你拿到上年底稿中，别人写了一段代码看不懂，你可以提问: “请解释下下面代码的含义： xxx ” 这解释得实在太清楚了。 不仅可以解释代码， Excel 公式看不懂，也可以让它解释。 所里同事都以为我 Excel 用得很厉害，其实我 Excel 不怎么行，只是会点 VBA 。经常财审同事发我的很多公式我都看不懂。 那么这个时候懒得查函数的具体用法，就可以直接问chatgpt: 自己结合着 Excel 的数据，也可以看得明明白白。 ","date":"2023-03-01","objectID":"/posts/20230228224513-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_it%E5%AE%A1%E8%AE%A1%E7%AF%87/:5:0","tags":["效率","chatpgt"],"title":"chatgpt在会计师事务所中的运用-IT审计篇","uri":"/posts/20230228224513-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_it%E5%AE%A1%E8%AE%A1%E7%AF%87/"},{"categories":["工作"],"content":"Bug修补器 如果你写了段 bug ，又不知道怎么解决。 以前我们当然可以在搜索引擎上搜索，一般也能很好的找到答案， 现在有了 chatgpt ，能更节省我们去尝试判断的时间。 比如，昨天实习生装上 navicat ，连接 mysql 数据库时连接不上，报错： 2059 - authentication plugin 'caching_sha2_password' cannot be loaded 我翻开自己笔记，直接把答案发给了她。 现在我们可以直接提问： 不过，怎么用英文在给我回答？赶紧停止掉。 你这是太瞧得起我了，“请用中文回答” 它这个解决方案也是我笔记中记录的方案，不过它更友善的是将原因也给说明了。 对于很多对 SQL 不熟练的同事来说，经常写一段代码，执行就报错，自己又没有调试的能力。 这个时候，你只需要对它说：“帮我修改下面代码的 bug ：xxx”，它就能自动帮你修改好： 你看，它不仅指出你代码中存在的问题，还把 bug 给你修改好，给你贴出来了，你仅仅需要做的就是复制、粘贴。 哪个老师能做到这样？！！！ 强不强？ ","date":"2023-03-01","objectID":"/posts/20230228224513-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_it%E5%AE%A1%E8%AE%A1%E7%AF%87/:6:0","tags":["效率","chatpgt"],"title":"chatgpt在会计师事务所中的运用-IT审计篇","uri":"/posts/20230228224513-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_it%E5%AE%A1%E8%AE%A1%E7%AF%87/"},{"categories":["工作"],"content":"结语 IT审计在会计师事务所越来越被重视， 作为一名 IT 审计师，需要学习大量的 IT 、财务相关知识。 如果想有所收获，这条学习之路并不轻松。 而 ChatGpt 无疑是我们 IT 审计工作中最好的助手和老师。 当然，需要我们自己拥有好奇心和学习欲望的指引。 ","date":"2023-03-01","objectID":"/posts/20230228224513-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_it%E5%AE%A1%E8%AE%A1%E7%AF%87/:7:0","tags":["效率","chatpgt"],"title":"chatgpt在会计师事务所中的运用-IT审计篇","uri":"/posts/20230228224513-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_it%E5%AE%A1%E8%AE%A1%E7%AF%87/"},{"categories":["生活"],"content":"昨天在 B 站刷到一位关注的 UP 主的视频，其中他主要讲了他改了晚睡的习惯，变成每天早起 2 小时，效率大幅提高的事。 其中提到想法的来源于《巨人的工具》一书。 相信一般刷到后会激动一下，然后就忍耐不住，想早睡早起。 但我仔细想想，我穷、我一事无成是因为没早起吗？ 似乎不是，确实任何问题，或者别人给你宣传一个概念的时候，先问是不是，再说为什么。 有时候，我们会陷入盲目的自我感动，我有多努力，我花了多少时间。 但很少问这对我的目标有帮助吗？ 是朝着我要的方向在前进吗？ 这个过程是有效的吗？ 以前大概有 7 、8年的时间，每天早上 6 点或者 6 点半起床，但每天过得是混沌的，无意义的。 而当选择新的目标，准备备考 6 门CPA的时候，每天是10:30起床的，但每天都有使不完的劲。 相比别人能赚钱的人，我是因为没早起，努力不够吗？ 我想主要还是因为运气、资源和能力。 很多时候我们喜欢把因素归结于无关紧要的事上，自我感动、自我施压。 也许应该选最懒的路，这是一个长期或者中期的目标，是个躺着也能带来体面收入的方式。 而实现这一路径的短期目标，应该迈出最勤奋的步伐。 而我们常常被拥挤的人群所裹挟，漫无目的地匆匆而行。 而那条最懒的路，往往是少有人走的路，人幽曲静，罕有人至。 ","date":"2023-02-26","objectID":"/posts/20230226210851-%E9%80%89%E6%9C%80%E6%87%92%E7%9A%84%E8%B7%AF_%E8%B5%B0%E6%9C%80%E5%8B%A4%E5%A5%8B%E7%9A%84%E6%AD%A5/:0:0","tags":["感悟"],"title":"选最懒的路，走最勤奋的步","uri":"/posts/20230226210851-%E9%80%89%E6%9C%80%E6%87%92%E7%9A%84%E8%B7%AF_%E8%B5%B0%E6%9C%80%E5%8B%A4%E5%A5%8B%E7%9A%84%E6%AD%A5/"},{"categories":["工作"],"content":"ChatGpt在 2022 年12月的时候刚出来，我就进行注册和试用。 在这两个多月的时间里，它不仅是一个工具，更像一个免费的老师, 辅助我工作。 ChatGPT是由 OpenAI 开发的一种基于大规模预训练的语言模型，它是能够理解语义的。 这点很强大，不像以前我们用过的人工智障机器人。 在会计师事务所，相信大家也被这个破圈的技术所吸引，但还不知道实际工作中能有什么用。 我将分几篇文章，尽量抛砖引玉，激发大家的使用思路。 ","date":"2023-02-25","objectID":"/posts/20230225214827-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_%E5%AE%A1%E8%AE%A1%E7%AF%87/:0:0","tags":["效率","chatgpt"],"title":"chatgpt在会计师事务所中的运用-审计篇","uri":"/posts/20230225214827-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_%E5%AE%A1%E8%AE%A1%E7%AF%87/"},{"categories":["工作"],"content":"完成批量处理工作 chatgpt是可以帮你写代码、改代码、查 bug 的，而且非常专业。 而我们审计师以前不会写代码，苦于在 Excel 和Word中进行各种重复操作。 那么现在，我们只需要告诉它我想实现什么功能，你说得越具体，它完成得越好。 例如，我们在编制 Excel 底稿，完成后，需要对每张表的格式进行统一。 以前我们是手工操作，那么现在不需要了。 我们打开浏览器，直接让它帮我写一段 VBA 代码，完成我想要设置的具体格式，直接能生成出我需要的代码。 生成后我们，在 Excel 中打开宏编辑器(快捷键Alt+F11)，选中我们的工作簿名称，点击右键，插入模块。 将代码粘贴过来后，按 F5 运行（也可以通过“视图” - “工具栏” - “调试”，调出调试窗口，点击按钮） 执行后，我们可以看到每张表的格式批量调整了， 但是它好像把我的“审计目标”、“审计过程”以前是红色变成了黑色， 我还是想保留以前的颜色，怎么办？ 我们继续和 chatgpt 对话，让他帮我们搞定： 可以看到，它是能记忆以前对话的内容的，我们可以像和人交流一样，告诉他我的想法就可以。 同样的，我把重新生成的代码粘贴过去，执行一遍。但是我发现，代码执行效率很慢，我又向它提问：“反应时长太长，能否优化下执行效率” 他又重新给我生成了代码。 最后就完成帮我解决了这个问题。 这样是不是将我们以前批量操作的工作，可以自动完成了？爽吧。 作为表哥、表姐的我们一定还能想到很多工具中需要重复处理的事项，你只需要具体说给他，他就可以给你生成 VBA 代码批量完成。 例如，刚刚是调整 Excel 格式，那么我们是不是还可以批量调整 Word 格式？ 每次写报告的时候，我都很烦调格式，尤其是表格的格式，利用这种方式，我相信能节省很多时间。 再比如，合并工作簿、工作表这些操作你都不再需要到处找什么小工具了，它能很好帮你解决。 这个能用到什么程度，取决于你的想象和提问水平。 ","date":"2023-02-25","objectID":"/posts/20230225214827-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_%E5%AE%A1%E8%AE%A1%E7%AF%87/:1:0","tags":["效率","chatgpt"],"title":"chatgpt在会计师事务所中的运用-审计篇","uri":"/posts/20230225214827-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_%E5%AE%A1%E8%AE%A1%E7%AF%87/"},{"categories":["工作"],"content":"Excel、Word操作助手 对于审计新人，当 Excel 、Word操作不熟练的时候，它能像老师一样教会你。 ","date":"2023-02-25","objectID":"/posts/20230225214827-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_%E5%AE%A1%E8%AE%A1%E7%AF%87/:2:0","tags":["效率","chatgpt"],"title":"chatgpt在会计师事务所中的运用-审计篇","uri":"/posts/20230225214827-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_%E5%AE%A1%E8%AE%A1%E7%AF%87/"},{"categories":["工作"],"content":"问已知函数使用方法 比如，我们可以问一些不熟悉的函数的用法： ","date":"2023-02-25","objectID":"/posts/20230225214827-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_%E5%AE%A1%E8%AE%A1%E7%AF%87/:2:1","tags":["效率","chatgpt"],"title":"chatgpt在会计师事务所中的运用-审计篇","uri":"/posts/20230225214827-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_%E5%AE%A1%E8%AE%A1%E7%AF%87/"},{"categories":["工作"],"content":"根据需求问实现方法 假如，有些时候我们连该用什么函数都不知道，只知道我要实现什么功能，也可以把具体描述说给它，让它给我们解决方案: 假设 Sheet1 表中有年龄和员工号两列数，我在 Sheet2 中有一列员工号，需要查找对应的年龄。 我们可以将需求描述给它： 它能够给我们推荐使用函数，但这个结果并不是正确的。熟悉 vlookup 的知道，查找的列需要在第一列，而这个是在最后一列。 那么我们可以继续纠正它： 我们将公式粘贴到 Excel 中： 可以看到完美解决了我的问题，同时它也把具体函数的用法也讲解给我们了。 这其实比你的现场高级别的同事讲解得还清楚些。 ","date":"2023-02-25","objectID":"/posts/20230225214827-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_%E5%AE%A1%E8%AE%A1%E7%AF%87/:2:2","tags":["效率","chatgpt"],"title":"chatgpt在会计师事务所中的运用-审计篇","uri":"/posts/20230225214827-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_%E5%AE%A1%E8%AE%A1%E7%AF%87/"},{"categories":["工作"],"content":"私人专业助理 ","date":"2023-02-25","objectID":"/posts/20230225214827-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_%E5%AE%A1%E8%AE%A1%E7%AF%87/:3:0","tags":["效率","chatgpt"],"title":"chatgpt在会计师事务所中的运用-审计篇","uri":"/posts/20230225214827-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_%E5%AE%A1%E8%AE%A1%E7%AF%87/"},{"categories":["工作"],"content":"税率问题 前些天在做一家电商项目的 IT 审计，其中需要对订单金额进行测算和核对。 由于计算涉及到欧洲各国的增值税率，但是订单表中没有，我找负责的业务老师，她说她也是网上查的。 好吧，但是我不想一个一个的查，就向 chatgpt 发起了提问： 看样子还不错，但是有些问题： 我需要的一些国家和地区的税率没有列示出来。 给的答案是一段文本，还需要自己去整理成表格。 那么我们，再进一步将需要的所有国家和地区告诉它，让它查，并且只要标准税率，用表格形式展示给我： 这是它返回给我的答案，无论给它中文、英文还是缩写，他都行！ 这样，我可以直接复制粘贴到 Excel ，用 vlookup 就可以将订单表中涉及到不同国家的税率补全了。 ","date":"2023-02-25","objectID":"/posts/20230225214827-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_%E5%AE%A1%E8%AE%A1%E7%AF%87/:3:1","tags":["效率","chatgpt"],"title":"chatgpt在会计师事务所中的运用-审计篇","uri":"/posts/20230225214827-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_%E5%AE%A1%E8%AE%A1%E7%AF%87/"},{"categories":["工作"],"content":"专业问题 比如，我不懂怎么现金流量表编制，我可以一步步问它怎么去做，它给的回答如果不具体，你可以继续针对一个小问题让它具体讲解，甚至举例。 不过，很显然，对于这种过度专业的问题，它的回答并没有那么好，可能各训练的数据量有关，甚至会出现一本正经胡说八道的情况，这一点需要仔细判断，不可全信。 即使如此，它能对这些专业问题给出思路和框架，还是很有益的。 ","date":"2023-02-25","objectID":"/posts/20230225214827-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_%E5%AE%A1%E8%AE%A1%E7%AF%87/:3:2","tags":["效率","chatgpt"],"title":"chatgpt在会计师事务所中的运用-审计篇","uri":"/posts/20230225214827-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_%E5%AE%A1%E8%AE%A1%E7%AF%87/"},{"categories":["工作"],"content":"结语 本篇针对审计过程中可能用到的方向进行了介绍，限于财务审计工作经验只有两年，可能并不全面和深入，需要读者自己探索。 同时，限于篇幅，上述还只挖掘出 chatgpt 功效的一小部分。 它还有很强大的写作、翻译、摘要等应用场景， 后续针对 IT 审计、咨询方向，也会介绍下可能的应用。 很多地方对于不同方向的工作应该都是有益的。 ","date":"2023-02-25","objectID":"/posts/20230225214827-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_%E5%AE%A1%E8%AE%A1%E7%AF%87/:4:0","tags":["效率","chatgpt"],"title":"chatgpt在会计师事务所中的运用-审计篇","uri":"/posts/20230225214827-chatgpt%E5%9C%A8%E4%BC%9A%E8%AE%A1%E5%B8%88%E4%BA%8B%E5%8A%A1%E6%89%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8_%E5%AE%A1%E8%AE%A1%E7%AF%87/"},{"categories":["工作"],"content":"最近财审同事在做一个专项审计项目，主要是对行业特定补贴进行审计。 我们做 IT 审计团队进行协助，主要完成补贴计算的自动化。 刚开始我向财审同事了解的时候，就感觉这种项目有个特点就是费人。 大大小小的补贴类型有 10 个,每一个类型还需要细分成大概 4 个。 加在一起共计 30-40 个类型。 每一种类型的计算，根据补贴政策如果用 Excel 计算，会非常复杂和麻烦。 单独一个做着可能还行，但一个人要是负责几个，能做下来的话，我是打心眼里觉得真有耐心。 要是中间数导错了，数更新了，需要重新进行，那更是抓狂。 而我们 IT 审计团队则是将每一类计算逻辑，用 python 代码来实现。 说实话，这个工作量也不小。 但，用代码有以下几个好处： 相同逻辑可以复用。 多次审计项目，一次写完，多次复用。 准确率高。 我把所有类型的补贴计算，都抽象成通用函数，放在一个base模块中。 这样，写每一个类型的代码，都可以调用基础模块的函数，这样如果逻辑有变化，我只需要修改基础函数即可，而不用单独去修改每一个补贴计算的代码。这将节省大量时间。 很直观的变化就是，以前需要人工 3 天用 Excel 计算的活，现在用 python 跑，只需要 10 多分钟。 就算中间需要更新数据，重算，也大不了计算机后台算 10 分钟而已。 准确率也不会因为人工的失误或者粗心而出错。 这不经又让我想起，我在初级时和别的部门合作算一个资产证券化的项目，她负责数学建模，我负责用 VBA 编码。 将之前算一次需要 3 个小时，被券商折磨得死去活来的项目，变成改动参数 10 秒出结果。 喝着奶茶，填着工时。 总之，如果你这个工作是一个周期性的重复工作，有计算或操作逻辑，每次又会耗费大量时间，同时又还没有重要得能让公司花钱上系统。 那么，可以考虑使用 Python 这种快速编码，花费一次时间，躺平。 无论是企业或者会计师事务所有这类需求，我们可以合作咨询项目。 我的企业邮箱：tujiabing_cd@shinewing.com ","date":"2023-02-20","objectID":"/posts/20230219233707-python%E5%9C%A8%E6%9C%BA%E5%9C%BA%E8%A1%A5%E8%B4%B4%E4%B8%93%E9%A1%B9%E5%AE%A1%E8%AE%A1%E7%9A%84%E8%BF%90%E7%94%A8/:0:0","tags":["python","IT审计"],"title":"python在涉及复杂运算的专项审计中的运用","uri":"/posts/20230219233707-python%E5%9C%A8%E6%9C%BA%E5%9C%BA%E8%A1%A5%E8%B4%B4%E4%B8%93%E9%A1%B9%E5%AE%A1%E8%AE%A1%E7%9A%84%E8%BF%90%E7%94%A8/"},{"categories":["工作"],"content":"时常别人问我问题，我一般都会说你先去问百度。 因为在我看来，他问的这些问题在网上有丰富的资料，也有现成的答案。 但前几天一位刚入行的朋友，问我一个 Excel 的问题，她描述了一大堆她想要实现的功能。 她说，她自己都不知道该怎么问问题，因为她感觉都不懂，不知如何入手。 突然，我能意识到，刚进入某个陌生领域的时候，可能真的连问题都问不出来。 因为，在这个陌生领域，我只知道我要实现某个目标，而具体所有要做的都完全不懂。 这时，我又会回想起“如何造一枚导弹”这个问题上来，同样的这也是一个复杂的系统工程。 对于普通人来说，你怀着疑问问别人：“我刚入行，不太懂，想问下如何造一门导弹？” 我相信，别人一定会翻你一个白眼，态度好点的会问：“能不能说具体点你的问题？” 你可能会补充到：“我就是想把一枚炸弹，能精确地投送到几千公里以外的地方，在目标点爆炸。\" 没错，我接触到的大部分人都是这么问问题的，我觉得当你这么问的时候，可能压根就没有想实际去解决它。 在很长一段时间，我自己也没有意识到，如何准确问问题也是一种能力，这种能力是我们缺失的，它叫分解能力。 ","date":"2023-02-12","objectID":"/posts/20230212195147-%E5%A6%82%E4%BD%95%E5%88%B6%E9%80%A0%E4%B8%80%E6%9E%9A%E5%AF%BC%E5%BC%B9/:0:0","tags":["效率"],"title":"如何制造一枚导弹","uri":"/posts/20230212195147-%E5%A6%82%E4%BD%95%E5%88%B6%E9%80%A0%E4%B8%80%E6%9E%9A%E5%AF%BC%E5%BC%B9/"},{"categories":["工作"],"content":"分解能力 一枚导弹说到底就一个炸弹，顶部装着炸药的战斗部，而要送到几千公里外，就需要燃料，也就是推进系统。当然要想准确送到目的地，就还需要导航系统、姿势控制系统等。最后还需要承载着以上系统的外壳主体。 你看这个大的问题可以拆分成小的问题。当然，对于这种庞大的系统工程来说，还需要不停地进行拆分。 例如导航问题，在正常环境下可能使用卫星定位，但在有卫星信号弱时可能会使用惯性导航，那么这个问题又可以拆分下去。 当然，以上的拆分应该达到工程上可执行的地步，否则你告诉别人把大象装进冰箱只需要三步一样，没有太多的意义。 对于一名工人来说，问题最后可能已经拆解为“如何生产某个材质、某个尺寸的螺丝钉？”。 当你向一名老工人问出这种问题的时候，别人一般是可以帮你解答的。 所以，我们的问题应当分解为可执行的层面，这才是有意义的。 ","date":"2023-02-12","objectID":"/posts/20230212195147-%E5%A6%82%E4%BD%95%E5%88%B6%E9%80%A0%E4%B8%80%E6%9E%9A%E5%AF%BC%E5%BC%B9/:1:0","tags":["效率"],"title":"如何制造一枚导弹","uri":"/posts/20230212195147-%E5%A6%82%E4%BD%95%E5%88%B6%E9%80%A0%E4%B8%80%E6%9E%9A%E5%AF%BC%E5%BC%B9/"},{"categories":["工作"],"content":"整合能力 以前上军事课，老师说“战斗力是什么？战斗力就是人、武器、以及人和武器的结合。” 你看，单独的两个系统间，他们的结合也都会是重要的一部分。 当我们将一个问题或系统分解成一个个子问题或子系统后，在分别解决子问题后，还需要考虑他们之间的融合。 而这种整合往往在建设之初就会考虑。系统与系统间是如何协调、如何通信、如何作用的？ 这种整合能力很多时候，比某个单个系统的性能更重要。 以我们建设国产大飞机为例，当我们战略上决定要建设自己的大飞机时，我们可能很多方面都是空白的。 也许有人说，发动机最重要，我们先突破发动机。 也许有人说，我们航空材料不行，我们先突破材料。 也许有人说，控制系统不行，我们先建设控制系统。 这和我们面对一个陌生领域是一样的不知所措。那么国家是怎么做的呢？ 什么都不会，那我们先做组装吧，就像玩乐高一样，我造不出来的就进口，在组装的过程中，我才可能了解整个建设流程、环节。 才可能了解到具体我是有哪些缺失，以及其重要性，及后续发展的先后顺序。 当我们一无所知，先了解整个大系统的框架，搞清楚整个流程，然后再去分解，逐步突破每一个模块。 其实想想我们的航母也是这样的，先买下瓦良格号，有了整个船体和建造图纸，再去突破整细节。 这就是先有了整合能力，再有了分解能力。 ","date":"2023-02-12","objectID":"/posts/20230212195147-%E5%A6%82%E4%BD%95%E5%88%B6%E9%80%A0%E4%B8%80%E6%9E%9A%E5%AF%BC%E5%BC%B9/:2:0","tags":["效率"],"title":"如何制造一枚导弹","uri":"/posts/20230212195147-%E5%A6%82%E4%BD%95%E5%88%B6%E9%80%A0%E4%B8%80%E6%9E%9A%E5%AF%BC%E5%BC%B9/"},{"categories":["工作"],"content":"个人的选择 对于一个复杂系统，个人是无法全部完成的。 往小了说一点，一个项目、一单生意，每个人应该清楚自己的能力和位置。 现实生活中并不需要每个人精通各个环节，这对现代社会分工来说，也是不可行、效率低下的。 比如，在事务所，一个项目，你有客户资源，有品牌，有售前能力，有承做能力。 这一切都有了，那还打工个毛线，早自己单干了。 那么一定是有这个平台你所不具备的。 对于每个人来说，其实要做的更多的是将自己的长处无限放大,让自己在分解任务中的某个领域成为绝对的专家，而不是去补齐短板，成为每个环节的普通人，除非自己有整个系统的整合能力这种不可或缺的能力。 现实生活中又不是学生时代的考试，你可以将分解任务外包。 比如，你有客户资源，那么你可以将承做外包出去，让别人做。 如果你有团队，具备承做能力，也可以利用平台的资源生存。 同样的，如果是项目经理，那么你也可以将任务分解，将具体环节外包给同事，而自己负责整个项目的整合。 最后，如果自己在学习某个具体的知识领域，再没有可以外包的了，也应该利用整合+分解能力，逐个击破，最终掌握。 当然，最好能形成T字型的知识结构，能在某一方面成为绝对的专家，这样才能参与到更大的系统建设或者社会分工中。 ","date":"2023-02-12","objectID":"/posts/20230212195147-%E5%A6%82%E4%BD%95%E5%88%B6%E9%80%A0%E4%B8%80%E6%9E%9A%E5%AF%BC%E5%BC%B9/:3:0","tags":["效率"],"title":"如何制造一枚导弹","uri":"/posts/20230212195147-%E5%A6%82%E4%BD%95%E5%88%B6%E9%80%A0%E4%B8%80%E6%9E%9A%E5%AF%BC%E5%BC%B9/"},{"categories":null,"content":"个人介绍 我的昵称是nigo，一条逆行的狗。 毕业于国防科学技术大学，注册会计师，边防连队任职步兵排长 3 年，复员后从事财务审计 2 年，此后从事 IT 审计至今。 个人利用擅长 python 、sql、 clickhouse 等技术进行数据分析。 爱好折腾 Linux 、emacs。 ","date":"2023-02-11","objectID":"/about/:1:0","tags":null,"title":"个人介绍","uri":"/about/"},{"categories":null,"content":"微信公众号 2018年 4 月开通微信公众号：逆行的狗，记录平时审计工作中所思、所学、所想。 最开始写过一堆用于审计的 VBA 工具，认识了一些志同道合的朋友。 平时发文较多的主要是在微信公众号上。 ","date":"2023-02-11","objectID":"/about/:2:0","tags":null,"title":"个人介绍","uri":"/about/"},{"categories":null,"content":"BiliBili 在 B 站的账号是nigo81，有时会录制一些关于 python 、sql、 Linux 相关的视频。 ","date":"2023-02-11","objectID":"/about/:3:0","tags":null,"title":"个人介绍","uri":"/about/"},{"categories":null,"content":"出版物 在工作期间在电子工业出版社出版过两本书，每本书都在 B 站上传了对应的配套视频。 《审计效率手册》 《 IT 审计：用SQL+Python提升工作效率》 虽然自己不是什么专家，但平时工作中比较喜欢学习和思考，所以写作对自己来说也就是学习和思考的输出，这对我是非常有益的。 ","date":"2023-02-11","objectID":"/about/:4:0","tags":null,"title":"个人介绍","uri":"/about/"},{"categories":["生活"],"content":"写公众号写了几年，很多历史文章在微信上查看并不方便，毕竟是个封闭的系统。 今天用 hugo 在github上搭建了个免费的博客，搭配着 emacs 中的 ox-hugo 插件，可以一键发布到博客。 由于平时也是使用的 emacs 写公众号文章，所以顺便也就可以发布在博客上了。 今天把 2022 年8月以来的文章都迁移到博客上了，之前的文章也会陆续迁移。 这样也方便大家能够搜索或者使用 RSS 订阅。 博客地址：https://nigo81.github.io/ 参考文章： 21天学会 Emacs ：第 11 天使用org mode写博客_哔哩哔哩_bilibili 主题文档 - 基本概念 - LoveIt ox-hugo - Org to Hugo exporter 利用 GitHub-Actions 将Hugo博客自动发布到 GitHub 和Gitee Pages - 简书 结合Github Action实现自动上传 Algolia 索引 - 凡梦星尘 ","date":"2023-02-11","objectID":"/posts/20230211232820-%E6%96%87%E7%AB%A0%E8%BF%81%E7%A7%BB%E5%88%B0%E5%8D%9A%E5%AE%A2/:0:0","tags":["效率"],"title":"文章迁移到博客","uri":"/posts/20230211232820-%E6%96%87%E7%AB%A0%E8%BF%81%E7%A7%BB%E5%88%B0%E5%8D%9A%E5%AE%A2/"},{"categories":["效率"],"content":"作为重度知识使用者，我使用过很多笔记软件。 包括为知笔记、印象笔记、 gingko 、vimwiki。 其中停留在 vimwiki 的时间比较长，它是编辑器之神 vim 的一个插件，用它积累了很多学习、工作的笔记，全部是本地的 makrdown 文件，共享盘同步。 从去年 8 月开始，用上了 emacs ，这个被称为神之编辑器的东西，确实让人上瘾，几乎可以用它来做任何事情。 这个编辑器不仅属于程序员，其实很多国外学术圈的人也很多人使用。 目前我使用它记录笔记、工作安排、 GTD 、写 Python 、写公众号、听收音机、发邮件、读 RSS 。 ","date":"2023-02-10","objectID":"/posts/20230205232142-%E8%AE%A9%E4%BA%BA%E4%B8%8A%E7%98%BE%E7%9A%84emacs/:0:0","tags":["emacs"],"title":"让人上瘾的emacs","uri":"/posts/20230205232142-%E8%AE%A9%E4%BA%BA%E4%B8%8A%E7%98%BE%E7%9A%84emacs/"},{"categories":["效率"],"content":"读书笔记 在看书时，可以方便地一边记笔记、一边看 PDF ，可以全部使用键盘。 使用dictionary-overlay插件，可以在阅读英文时，遇到不懂的单词可以直接标注，后面再次出现也会显示中文。 使用popweb插件可以直接实时查有道词典。 搭配着这两个插件，基本上我也不怕读英文文档了。 ","date":"2023-02-10","objectID":"/posts/20230205232142-%E8%AE%A9%E4%BA%BA%E4%B8%8A%E7%98%BE%E7%9A%84emacs/:1:0","tags":["emacs"],"title":"让人上瘾的emacs","uri":"/posts/20230205232142-%E8%AE%A9%E4%BA%BA%E4%B8%8A%E7%98%BE%E7%9A%84emacs/"},{"categories":["效率"],"content":"org-mode emacs最强大的就是 org-mode ，可以方便组织文字、图片、链接 每一层级可以方便的折叠，展开，非常有逻辑性。 同时，对于学习代码来说，他还可以直接运行，因此我们可以进行文学编程。 只需要在代码块中按下C-c C-c就可以将代码结果运行出来。 如果你喜欢双链笔记，可以使用org-roam插件。 ","date":"2023-02-10","objectID":"/posts/20230205232142-%E8%AE%A9%E4%BA%BA%E4%B8%8A%E7%98%BE%E7%9A%84emacs/:2:0","tags":["emacs"],"title":"让人上瘾的emacs","uri":"/posts/20230205232142-%E8%AE%A9%E4%BA%BA%E4%B8%8A%E7%98%BE%E7%9A%84emacs/"},{"categories":["效率"],"content":"编写代码 搭配上lsp-bridge插件，可以瞬间变成一个成熟的 IDE ，尤其是如果平时要写多个语言，那么在一个编辑中写书，更高效。 毕竟快捷键都是一套自己熟悉的。 ","date":"2023-02-10","objectID":"/posts/20230205232142-%E8%AE%A9%E4%BA%BA%E4%B8%8A%E7%98%BE%E7%9A%84emacs/:3:0","tags":["emacs"],"title":"让人上瘾的emacs","uri":"/posts/20230205232142-%E8%AE%A9%E4%BA%BA%E4%B8%8A%E7%98%BE%E7%9A%84emacs/"},{"categories":["效率"],"content":"GTD org-agenda 是非常强大的任务管理插件。 在工作时，如果有一项任务来临，按下C-c c就可以弹出记录。 输入待办事项、开始时间或结束时间、重要程度 也可以使用番茄钟等对任务的时间消耗进行记录。 ","date":"2023-02-10","objectID":"/posts/20230205232142-%E8%AE%A9%E4%BA%BA%E4%B8%8A%E7%98%BE%E7%9A%84emacs/:4:0","tags":["emacs"],"title":"让人上瘾的emacs","uri":"/posts/20230205232142-%E8%AE%A9%E4%BA%BA%E4%B8%8A%E7%98%BE%E7%9A%84emacs/"},{"categories":["效率"],"content":"RSS 可以订阅自己喜欢的一些博客文章或者播客、 B 站关注的 UP 主。 ","date":"2023-02-10","objectID":"/posts/20230205232142-%E8%AE%A9%E4%BA%BA%E4%B8%8A%E7%98%BE%E7%9A%84emacs/:5:0","tags":["emacs"],"title":"让人上瘾的emacs","uri":"/posts/20230205232142-%E8%AE%A9%E4%BA%BA%E4%B8%8A%E7%98%BE%E7%9A%84emacs/"},{"categories":["效率"],"content":"邮件 最近也把邮件客户端省了，打开 emacs 就可以查阅和发送邮件。 对联系人也是可以直接补全的。 当收到邮件时，还可以和前面org-agenda结合将邮件做一项待办任务，后面再进行处理。 ","date":"2023-02-10","objectID":"/posts/20230205232142-%E8%AE%A9%E4%BA%BA%E4%B8%8A%E7%98%BE%E7%9A%84emacs/:6:0","tags":["emacs"],"title":"让人上瘾的emacs","uri":"/posts/20230205232142-%E8%AE%A9%E4%BA%BA%E4%B8%8A%E7%98%BE%E7%9A%84emacs/"},{"categories":["效率"],"content":"结语 emacs是一个存在了 40 多年的自由软件，到现在也还具有强大的生命力，可以预见未来的 40 年也将继续存在。 它是神之编辑器，在 windows 、Linux、 Mac 上都可以使用。 如果感兴趣可以看下陈斌写的《一年成为 Emacs 高手 (像神一样使用编辑器)》 https://github.com/redguardtoo/mastering-emacs-in-one-year-guide/blob/master/guide-zh.org 刚开始上手配置比较困难，可以直接使用他的配置文件： https://github.com/redguardtoo/emacs.d 它的配置文件应该是支持 windows 、mac、 linux 的。 不过后面自己熟悉后，还是可以折腾一份自己的配置，毕竟自己能掌控的才是最好的。 ","date":"2023-02-10","objectID":"/posts/20230205232142-%E8%AE%A9%E4%BA%BA%E4%B8%8A%E7%98%BE%E7%9A%84emacs/:7:0","tags":["emacs"],"title":"让人上瘾的emacs","uri":"/posts/20230205232142-%E8%AE%A9%E4%BA%BA%E4%B8%8A%E7%98%BE%E7%9A%84emacs/"},{"categories":["工作"],"content":"随着个人信息保护法等相关法律的出台，以电商为代表的互联网平台加强了个人信息保护。 以前导出的订单信息中，包含有个人信息，后面就加上了掩码了。 最近做的一个项目，天猫平台导出订单，直接连字段都没有了， 什么昵称、姓名、 ID 、电话、详细地址统统没有。 首发问答 54 条第 53 问，又明确让 IT 审计进行数据分析。 这还分析个毛啊。 其实以前相关字段有掩码，还可以用昵称+电话或者地址什么的拼一个代表用户的唯一 ID 。 现在就没了，没法了。 咨询了一些其它项目，发现有些店铺是可以导出的，有些店铺是无法导出的。 可能和店铺类型有关。 目前通过请教同事我唯一能想到的办法是： 用管理员账号导数。 有些信息普通账号导不出来，管理员账号就可以导出来。 利用能利用的数据拼。 订单里没有，看能不能用发货的地址等信息替代购买人。如果连发货等其他数据导出来都没有用户信息，可能没法了。 记得上条，用管理员账号导。 网上搜索上有没有平台固有的订单规律。 同事告诉我，天猫平台同一个用户订单后 6 位是相同的，我打开自己淘宝一看，惊奇发现真的我近一年买的商品订单后 6 位是相同的。 这个数字相当于就是一个用户 ID 了。 不过没有官方的公开规律，不知道是否可用。 最后，我想说请监管机构也学习下个人信息保护法，不要在问询函中问这种问题了。 臣妾 审计师做不到。 ","date":"2023-02-02","objectID":"/posts/20230202232727-%E7%94%B5%E5%95%86ipo%E9%A1%B9%E7%9B%AEit%E5%AE%A1%E8%AE%A1%E4%B8%AD%E4%B8%AA%E4%BA%BA%E4%BF%A1%E6%81%AF%E7%BC%BA%E5%A4%B1%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/:0:0","tags":["IT审计"],"title":"电商IPO项目IT审计中个人信息缺失解决办法","uri":"/posts/20230202232727-%E7%94%B5%E5%95%86ipo%E9%A1%B9%E7%9B%AEit%E5%AE%A1%E8%AE%A1%E4%B8%AD%E4%B8%AA%E4%BA%BA%E4%BF%A1%E6%81%AF%E7%BC%BA%E5%A4%B1%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/"},{"categories":["工作"],"content":"年前，财审经理丁老师发了我他们一位中级同事黄老师做的一个自动化工具，让我帮忙看看。 年前太忙了，一直拖到了今天晚上才看，实在不好意思。 这个工具解决的问题就是利用按键精灵实现用友 NC 系统批量自动导出科目余额表、序时账、辅助科目余额表。 对于主体上百家的企业来说，如果客户只是给账号，需要自己导数的时候，就能明白这多有用了。 这个操作是什么？不就是 RPA 嘛，反正这些名词换来换去，实质都一样。 发我的压缩包里有： 详细的操作教程视频。 操作步骤文档。 RPA脚本。 连操作过程中可能遇到的问题都在视频中进行了提示，真的很用心了，太优秀了。 除了牛逼之外，我更想说爱思考的人真帅。 爱思考，是种面对问题，主观去改进现状，解决问题的牛逼技能。 绝大部分人是缺失这种能力的。 如果导数要导三天，大家可能都宁愿老老实实不费脑子地导三天。 而爱思考的可能宁愿花一周，找一种更优的方法，却能解决更长久的问题。 也许你会说这同事电脑水平高，我更认同是更具有创造力。 这种能力是可迁移的，优秀的人往往是多方面优秀。 我说：“丁老师呀，让黄老师来我们部门吧。” 丁老师过了一分钟才回复我说：“他 cpa 也考完了，舍不得。”感觉我要抢他宝贝一样。 最后我想说黄老师牛逼，爱思考的人真帅！ ","date":"2023-01-30","objectID":"/posts/20230130232842-%E7%88%B1%E6%80%9D%E8%80%83%E7%9A%84%E4%BA%BA%E7%9C%9F%E5%B8%85/:0:0","tags":["审计"],"title":"爱思考的人真帅","uri":"/posts/20230130232842-%E7%88%B1%E6%80%9D%E8%80%83%E7%9A%84%E4%BA%BA%E7%9C%9F%E5%B8%85/"},{"categories":["生活"],"content":"我的假期今天结束了， 每天睡到 9 点过，大概有四五天去陪了爷爷，尽量在他最后的日子里多看看他。 生命终有尽头，人人皆须面对。 窗外人世间纷纷扰扰，屋内两老人孤孤单单。 其实作为从小在外读书的我来说，和爷爷婆婆待的时间很少， 以至于坐一起，也并没有太多的话， 以前爷爷身体好的时候，话题最多的时候就是他试图教我算命和风水。 每天就是带着两个孩子一起去看看他们， 有一天，涵涵带着楼下买的“消消乐”游戏卡片，三张相同的就可以消除，看谁最后剩下的卡片最少。 婆婆看到涵涵在玩，就过来和他一起玩， 对于成年人来说可能会感觉无聊的游戏，但婆婆和涵涵玩了一下午。 当时就有点感慨，不知是“老还小”还是每天真的太孤单无聊了。 晚上我问涵涵，今天你和祖祖谁赢了，他说：“祖祖牛逼惨了，一直赢，运气太好了。” 人随着年纪的增长，会觉得一年的时光过得越来越快， 小时候，如果我 5 岁，一年就是我人生的1/5，一年的时间好长，好长。 人大了，一年的时光只是人生的几十分之一，时间好快，好快。 其实，现实的当下永远是最好的时光，它承载着过去，延续着未来。 自己应当勇敢去做自己想做的事，不怕失败，不怕困难，不怕嘲笑。 其实除了生死健康之事，其它没有什么大不了的，这只是起点到终点的过程罢了， 唯有随心而活，快意逍遥，这才可能不留遗憾， 而不是拿着别人给你设计好的剧本，进行长达几十年的演出。 新年尹始，希望所有人身体健康， 我自己愿望是学有所成，努力赚钱。 ","date":"2023-01-27","objectID":"/posts/20230127223229-%E4%B8%80%E7%82%B9%E6%9D%82%E6%83%B3/:0:0","tags":["杂文"],"title":"一点杂想","uri":"/posts/20230127223229-%E4%B8%80%E7%82%B9%E6%9D%82%E6%83%B3/"},{"categories":["工作"],"content":"今天，有同事让生成下 2022 年陈版主答疑汇编，好的，安排。 既然生成了答疑汇编也做一个小小的总结。 (注：以下分析仅依据记录 cpa 业务探讨版块版主回答的帖子） ","date":"2023-01-11","objectID":"/posts/20230111235048-2022%E5%B9%B4%E4%BC%9A%E8%AE%A1%E8%A7%86%E9%87%8E%E8%AE%BA%E5%9D%9B%E7%AD%94%E7%96%91%E6%80%BB%E7%BB%93/:0:0","tags":["sql","审计"],"title":"2022年中国会计视野论坛答疑总结","uri":"/posts/20230111235048-2022%E5%B9%B4%E4%BC%9A%E8%AE%A1%E8%A7%86%E9%87%8E%E8%AE%BA%E5%9D%9B%E7%AD%94%E7%96%91%E6%80%BB%E7%BB%93/"},{"categories":["工作"],"content":"全年话题数及回答数 -- 回答数 select count(*) from chenyiwei_bbs where year(comment_time)=2022; -- 话题数 select count(distinct link) from chenyiwei_bbs where year(comment_time)=2022; 全年回答了 5086 个话题，共计 6286 次回复。 ","date":"2023-01-11","objectID":"/posts/20230111235048-2022%E5%B9%B4%E4%BC%9A%E8%AE%A1%E8%A7%86%E9%87%8E%E8%AE%BA%E5%9D%9B%E7%AD%94%E7%96%91%E6%80%BB%E7%BB%93/:1:0","tags":["sql","审计"],"title":"2022年中国会计视野论坛答疑总结","uri":"/posts/20230111235048-2022%E5%B9%B4%E4%BC%9A%E8%AE%A1%E8%A7%86%E9%87%8E%E8%AE%BA%E5%9D%9B%E7%AD%94%E7%96%91%E6%80%BB%E7%BB%93/"},{"categories":["工作"],"content":"回答数量月度分布 select month(comment_time) 月份,count(*) 回答数量 from chenyiwei_bbs where year(comment_time)=2022 group by month(comment_time) order by month(comment_time) 月份 回答数量 1 513 2 339 3 662 4 557 5 470 6 486 7 583 8 477 9 574 10 512 11 547 12 566 ","date":"2023-01-11","objectID":"/posts/20230111235048-2022%E5%B9%B4%E4%BC%9A%E8%AE%A1%E8%A7%86%E9%87%8E%E8%AE%BA%E5%9D%9B%E7%AD%94%E7%96%91%E6%80%BB%E7%BB%93/:2:0","tags":["sql","审计"],"title":"2022年中国会计视野论坛答疑总结","uri":"/posts/20230111235048-2022%E5%B9%B4%E4%BC%9A%E8%AE%A1%E8%A7%86%E9%87%8E%E8%AE%BA%E5%9D%9B%E7%AD%94%E7%96%91%E6%80%BB%E7%BB%93/"},{"categories":["工作"],"content":"回答数量小时分布 这里我们分别按提问时间和回答时间统计各小时区间的数量： -- 回答小时分布 select hour(comment_time) 小时,count(*) 回答数量 from chenyiwei_bbs where year(comment_time)=2022 group by hour(comment_time) order by hour(comment_time) -- 提问小时分布 select hour(question_time) 小时,count(*) 提问数量 from chenyiwei_bbs where year(comment_time)=2022 group by hour(question_time) order by hour(question_time) 小时 回答数量 提问数量 0 141 89 1 174 45 2 278 16 3 281 6 4 374 3 5 262 2 6 164 28 7 39 29 8 14 140 9 93 403 10 341 654 11 475 535 12 343 272 13 191 285 14 352 474 15 492 501 16 528 583 17 477 514 18 337 310 19 226 245 20 165 315 21 151 304 22 152 308 23 236 225 通过提问人和回答人的小时分布对比就知道和大佬之间的差距。 ","date":"2023-01-11","objectID":"/posts/20230111235048-2022%E5%B9%B4%E4%BC%9A%E8%AE%A1%E8%A7%86%E9%87%8E%E8%AE%BA%E5%9D%9B%E7%AD%94%E7%96%91%E6%80%BB%E7%BB%93/:3:0","tags":["sql","审计"],"title":"2022年中国会计视野论坛答疑总结","uri":"/posts/20230111235048-2022%E5%B9%B4%E4%BC%9A%E8%AE%A1%E8%A7%86%E9%87%8E%E8%AE%BA%E5%9D%9B%E7%AD%94%E7%96%91%E6%80%BB%E7%BB%93/"},{"categories":["工作"],"content":"回答数量最多日期TOP5 select date_format(comment_time,'%Y-%m-%d') 日期,count(*) 回答数量 from chenyiwei_bbs where year(comment_time)=2022 group by date_format(comment_time,'%Y-%m-%d') order by count(*) desc limit 5; 日期 回答数量 2022-06-30 67 2022-02-22 54 2022-11-27 51 2022-12-22 51 2022-11-15 51 630亮了 ","date":"2023-01-11","objectID":"/posts/20230111235048-2022%E5%B9%B4%E4%BC%9A%E8%AE%A1%E8%A7%86%E9%87%8E%E8%AE%BA%E5%9D%9B%E7%AD%94%E7%96%91%E6%80%BB%E7%BB%93/:4:0","tags":["sql","审计"],"title":"2022年中国会计视野论坛答疑总结","uri":"/posts/20230111235048-2022%E5%B9%B4%E4%BC%9A%E8%AE%A1%E8%A7%86%E9%87%8E%E8%AE%BA%E5%9D%9B%E7%AD%94%E7%96%91%E6%80%BB%E7%BB%93/"},{"categories":["工作"],"content":"工作天数 select count(distinct(date_format(comment_time,'%Y-%m-%d'))) 日期 from chenyiwei_bbs where year(comment_time)=2022 全年回贴共计 271 天，要知道 2022 年也就 248 个工作日。 ","date":"2023-01-11","objectID":"/posts/20230111235048-2022%E5%B9%B4%E4%BC%9A%E8%AE%A1%E8%A7%86%E9%87%8E%E8%AE%BA%E5%9D%9B%E7%AD%94%E7%96%91%E6%80%BB%E7%BB%93/:5:0","tags":["sql","审计"],"title":"2022年中国会计视野论坛答疑总结","uri":"/posts/20230111235048-2022%E5%B9%B4%E4%BC%9A%E8%AE%A1%E8%A7%86%E9%87%8E%E8%AE%BA%E5%9D%9B%E7%AD%94%E7%96%91%E6%80%BB%E7%BB%93/"},{"categories":["工作"],"content":"提问最多Top5 select question_author 提问人,count(*) 对话数 from chenyiwei_bbs where year(comment_time)=2022 group by question_author order by count(*) desc limit 5; 提问人 对话数 liuweisheng 213 Ryan_q 87 yjhly2011 56 zhs7403 43 天之蓝2022 42 其实能思考提出这么多问题的也是大佬。 ","date":"2023-01-11","objectID":"/posts/20230111235048-2022%E5%B9%B4%E4%BC%9A%E8%AE%A1%E8%A7%86%E9%87%8E%E8%AE%BA%E5%9D%9B%E7%AD%94%E7%96%91%E6%80%BB%E7%BB%93/:6:0","tags":["sql","审计"],"title":"2022年中国会计视野论坛答疑总结","uri":"/posts/20230111235048-2022%E5%B9%B4%E4%BC%9A%E8%AE%A1%E8%A7%86%E9%87%8E%E8%AE%BA%E5%9D%9B%E7%AD%94%E7%96%91%E6%80%BB%E7%BB%93/"},{"categories":["工作"],"content":"热门提问词汇 查询出全年提问标题： select distinct(title) from chenyiwei_bbs where year(comment_time)=2022 导出成 txt 文件，并用 Python 进行分词，取频率前 200 词汇绘制词云图。 读完数据，只有佩服。 ","date":"2023-01-11","objectID":"/posts/20230111235048-2022%E5%B9%B4%E4%BC%9A%E8%AE%A1%E8%A7%86%E9%87%8E%E8%AE%BA%E5%9D%9B%E7%AD%94%E7%96%91%E6%80%BB%E7%BB%93/:7:0","tags":["sql","审计"],"title":"2022年中国会计视野论坛答疑总结","uri":"/posts/20230111235048-2022%E5%B9%B4%E4%BC%9A%E8%AE%A1%E8%A7%86%E9%87%8E%E8%AE%BA%E5%9D%9B%E7%AD%94%E7%96%91%E6%80%BB%E7%BB%93/"},{"categories":["工作"],"content":"下载地址： https://wwds.lanzoum.com/b01nyhiod 密码:1mki ","date":"2023-01-11","objectID":"/posts/20230111235048-2022%E5%B9%B4%E4%BC%9A%E8%AE%A1%E8%A7%86%E9%87%8E%E8%AE%BA%E5%9D%9B%E7%AD%94%E7%96%91%E6%80%BB%E7%BB%93/:8:0","tags":["sql","审计"],"title":"2022年中国会计视野论坛答疑总结","uri":"/posts/20230111235048-2022%E5%B9%B4%E4%BC%9A%E8%AE%A1%E8%A7%86%E9%87%8E%E8%AE%BA%E5%9D%9B%E7%AD%94%E7%96%91%E6%80%BB%E7%BB%93/"},{"categories":["工作"],"content":"在 IT 审计的数据分析中，如果数据量稍微大点，获取数据我们一般都是 csv 文件。 如果客户给了很多 Excel 文件，我一般也会批量转成 csv 文件合并成一个， 再将数据导入到 Mysql 数据库中。 我自己在导完数后，一般会对行数进行校验，看原文件多少行，以及导入数据库多少行，确认数据导入正确。 昨天我发现导入数据库后的行数比 CSV 文件行数少，且没有报错。 其实之前我也遇到过两次这种问题，但当时数据量是上亿行和千万行，实在难以找到原因。 昨天的一个数据只有 4 万行，为了了解原因，用二分法经过大概 20 次数据对比，肉眼找到出问题的那行。 发现原因是字段内有换行符 。 ","date":"2023-01-10","objectID":"/posts/20230110221307-mysql%E5%AF%BC%E5%85%A5csv%E6%96%87%E4%BB%B6%E5%B0%91%E8%A1%8C%E5%8E%9F%E5%9B%A0%E6%8E%A2%E7%B4%A2/:0:0","tags":["sql","IT审计"],"title":"mysql导入csv文件少行原因探索","uri":"/posts/20230110221307-mysql%E5%AF%BC%E5%85%A5csv%E6%96%87%E4%BB%B6%E5%B0%91%E8%A1%8C%E5%8E%9F%E5%9B%A0%E6%8E%A2%E7%B4%A2/"},{"categories":["工作"],"content":"换行符 这里我们举一个例子： 这张表里有两行数据，其中第二行“商品名称”中有换行符。 我们将数据导入到 mysql 数据库会看到也是只有两行 但是你用命令行wc -l查看数据行数或者用记事本打开就会有 4 行数据： 这就是为什么我们查看 csv 的行数比我们导入数据库中的行数多的原因。 那么我们看看解决方法。 ","date":"2023-01-10","objectID":"/posts/20230110221307-mysql%E5%AF%BC%E5%85%A5csv%E6%96%87%E4%BB%B6%E5%B0%91%E8%A1%8C%E5%8E%9F%E5%9B%A0%E6%8E%A2%E7%B4%A2/:1:0","tags":["sql","IT审计"],"title":"mysql导入csv文件少行原因探索","uri":"/posts/20230110221307-mysql%E5%AF%BC%E5%85%A5csv%E6%96%87%E4%BB%B6%E5%B0%91%E8%A1%8C%E5%8E%9F%E5%9B%A0%E6%8E%A2%E7%B4%A2/"},{"categories":["工作"],"content":"去除CSV文件中的换行符 我们可以使用 pandas 库读取 csv 文件，并用 replace 函数将换行符\\n替换为空。 import pandas as pd df = pd.read_csv('数据.csv') df = df.replace('\\n', '', regex=True) df.to_csv('数据_new.csv',index=False) 可以看到输出的文件中换行符被替换了。 当然，一般我们处理的数据会非常大，如果这样一次性读取会超过电脑内存，这时我们可以使用分块读取，分块处理。 import pandas as pd def replace_newlines(input_file, output_file): chunksize = 10**6 #1MB flag = True for chunk in pd.read_csv(input_file, chunksize=chunksize, engine='python'): # Process each chunk chunk = chunk.replace('\\n', '', regex=True) # write the chunk to the output_file if flag: chunk.to_csv(output_file,mode='w',header=True,index=False) flag = False else: chunk.to_csv(output_file,mode='a',header=False,index=False) if __name__ == \"__main__\": replace_newlines('数据.csv','数据_pandas.csv') 我们可以看到数据也被正确处理了，当然，这里没有拿大数据来演示。 ","date":"2023-01-10","objectID":"/posts/20230110221307-mysql%E5%AF%BC%E5%85%A5csv%E6%96%87%E4%BB%B6%E5%B0%91%E8%A1%8C%E5%8E%9F%E5%9B%A0%E6%8E%A2%E7%B4%A2/:2:0","tags":["sql","IT审计"],"title":"mysql导入csv文件少行原因探索","uri":"/posts/20230110221307-mysql%E5%AF%BC%E5%85%A5csv%E6%96%87%E4%BB%B6%E5%B0%91%E8%A1%8C%E5%8E%9F%E5%9B%A0%E6%8E%A2%E7%B4%A2/"},{"categories":["工作"],"content":"去除Excel文件的换行符 如果给的 Excel 文件，需要转成 CSV 文件，那么你仍然可以使用上面 pandas 的处理方法，区别只是读取 csv 文件变成了读取 excel 文件。 使用pd.read_excel()即可读取 Excel 文件。如果想输出成 Excel ，可以使用pd.to_excel()即可。 当然，我们还可以使用更简单的方法。 python有个xlsx2csv库，可以直接将 Excel 转成 csv 文件。 安装方法： pip install xlsx2csv 我们可以看到直接这样转换， csv 文件中还是会有换行符。 通过xlsx2csv --help可以查看帮助文档。 我们可以看到有两个参数可以使用： -e :会将\\r\\n\\t等符号变成字符串。 --no-line-breaks ：会将换行符替换成空格。 （注： windows 换行符为\\r\\n， Linux 换行符为\\n) 因此我们只需要使用这两个参数即可。 ","date":"2023-01-10","objectID":"/posts/20230110221307-mysql%E5%AF%BC%E5%85%A5csv%E6%96%87%E4%BB%B6%E5%B0%91%E8%A1%8C%E5%8E%9F%E5%9B%A0%E6%8E%A2%E7%B4%A2/:3:0","tags":["sql","IT审计"],"title":"mysql导入csv文件少行原因探索","uri":"/posts/20230110221307-mysql%E5%AF%BC%E5%85%A5csv%E6%96%87%E4%BB%B6%E5%B0%91%E8%A1%8C%E5%8E%9F%E5%9B%A0%E6%8E%A2%E7%B4%A2/"},{"categories":["工作"],"content":"结语 其实昨天如果不是为了找这个原因，也可以手工一个一个 excel 去导入。 但这样其实自己是没有任何收获的。 4万多行，二分法肉眼才找到出问题那行。 耗费了一晚上研究清楚这个问题产生原因，将来各种情况的解决方法，无疑以后再次遇到的时候将直接上手解决。 重剑无锋，大巧不工。 ","date":"2023-01-10","objectID":"/posts/20230110221307-mysql%E5%AF%BC%E5%85%A5csv%E6%96%87%E4%BB%B6%E5%B0%91%E8%A1%8C%E5%8E%9F%E5%9B%A0%E6%8E%A2%E7%B4%A2/:4:0","tags":["sql","IT审计"],"title":"mysql导入csv文件少行原因探索","uri":"/posts/20230110221307-mysql%E5%AF%BC%E5%85%A5csv%E6%96%87%E4%BB%B6%E5%B0%91%E8%A1%8C%E5%8E%9F%E5%9B%A0%E6%8E%A2%E7%B4%A2/"},{"categories":["工作"],"content":"最近项目上的活已经干不过来了。 已经没有人了，我自己开底稿也开了两周了，接下来还得继续开底稿，项目已经堆在一起了。 不管多忙，我一直有一个感觉，如果忙到每天只有输出的话，这样你会发现自己会长时间陷入一种停滞状态。 就是你不断在做项目，但你可能成长很少。 只有你花时间把输入和输出结合起来的时候，这段时间一定是你进步最大的。 工作是干不完的，一直不停输出，基本上你只是一台机器，你所输出的没有总结、复盘、反馈、提升。 所以，无论怎么忙，做项目一定要抱着学习的态度，心里想着我从这个项目上能学习到什么。 哪怕实在忙得不行了，一点时间都没有了，也应该想想如何取舍和摸鱼，也就是所谓的要把有限的审计资源投入到风险最大的地方。 做项目虽然是打工、搬砖，但一定要给自己打工、给自己搬砖。 通过这个项目我要能获取到知识、经验，哪怕这就是一个平平无奇，自己做过很多次的项目，也应该想想这次我可以从哪些方面做些以前没注意到的事，增加自己的知识和能力。 其实，这种为自己打工的态度挺受用的， 因为无论怎么干，你获取到的工资都是一样的， 但有了这种思路，你会收获到任何人都剥夺不了你的技能，而这些技能是通用的，将来你无论在哪里都还用得上。 也许，就也就是一种收获， 同时，输入+输出的循环作用下，自己不断的思考、加工，你会发现这段时间是自己进步最大的时候。 而不带任何思考的不断为完成工作的输出，只能是单纯贩卖自己的时间换取微薄的工资，做一台不断折旧的机器。 ","date":"2023-01-02","objectID":"/posts/20230102231959-%E5%BF%99%E5%AD%A3%E6%9D%A5%E4%BA%86/:0:0","tags":["杂文"],"title":"忙季来了","uri":"/posts/20230102231959-%E5%BF%99%E5%AD%A3%E6%9D%A5%E4%BA%86/"},{"categories":["工作"],"content":"2022年结束了，总体来讲，这一年我不太满意。 进步较少，迷惘较多。 以下对 2022 年初的目标进行复盘，以及对 2023 年计划进行设定。 ","date":"2022-12-31","objectID":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/:0:0","tags":["杂文"],"title":"2022年总结和2023年计划","uri":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/"},{"categories":["工作"],"content":"技术方面 ","date":"2022-12-31","objectID":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/:1:0","tags":["杂文"],"title":"2022年总结和2023年计划","uri":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/"},{"categories":["工作"],"content":"2022年目标完成情况 学习掌握精通 clickhouse 大数据分析 这个目标已完成，并在实际项目上得到了运用。在做一个游戏公司的 IT 审计过程中，在我自己 5000 元的笔记本上也能处理亿级数据量。 只要硬件环境足够，处理 T 级数据量不在话下。虽然所里没提供服务器，但去年我自己也买了一台 2 万的台式机，利用 clickhouse 数据处理能力基本上足够了。 学习掌握Vue+Django网页全栈开发 没有完成目标。只掌握了用 Django 写后端的技术，还未掌握前端框架 Vue 。 主要原因是平时工作上用不上。学习动力不足，也有点畏难心理。 ","date":"2022-12-31","objectID":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/:1:1","tags":["杂文"],"title":"2022年总结和2023年计划","uri":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/"},{"categories":["工作"],"content":"2023年目标设定 考 oscp 证书 之前一个项目上接触了漏洞扫描和渗透测试，发现自己对信息安全知识还比较薄弱，打算通过考试系统学习下渗透测试。 oscp(进攻性安全专家认证)，考试也没有笔试， 6 台主机， 24 小时攻入拿到最高权限，然后 24 小时写报告。 计划 2023 年6月前通过考试。 学习掌握Vue+Django网页全栈开发 继续完成去年没有完成的任务，还是先动手写一个简单的网页上手，比如做一个内部用的招投标信息收集的网站。 用scrapy+gerapy获取平时目标网站的招投标信息，用vue+django写个网站可以前台检索看。 ","date":"2022-12-31","objectID":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/:1:2","tags":["杂文"],"title":"2022年总结和2023年计划","uri":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/"},{"categories":["工作"],"content":"阅读方面 ","date":"2022-12-31","objectID":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/:2:0","tags":["杂文"],"title":"2022年总结和2023年计划","uri":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/"},{"categories":["工作"],"content":"2022年目标完成情况 计划全年读 6 本书已完成，已读的书有： 《底层逻辑》 《一个数学家的叹息》 《暗时间》重读 《父与子》 《这书能让你戒烟》 《 Neo4j 权威指南》 《数字化审计实务指南》 《 ClickHouse 原理解析与应用实践》 《共产党宣言》 ","date":"2022-12-31","objectID":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/:2:1","tags":["杂文"],"title":"2022年总结和2023年计划","uri":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/"},{"categories":["工作"],"content":"2023年目标设定 照旧计划全年读 6 本书 ","date":"2022-12-31","objectID":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/:2:2","tags":["杂文"],"title":"2022年总结和2023年计划","uri":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/"},{"categories":["工作"],"content":"投资方面 ","date":"2022-12-31","objectID":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/:3:0","tags":["杂文"],"title":"2022年总结和2023年计划","uri":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/"},{"categories":["工作"],"content":"2022年目标完成情况 账户市值到 100 万未达成，主要计算的时候把帮父母买的钱算进去了，今年他们拿去买房了。 今年亏损 8 万，账户还剩 55 万。 ","date":"2022-12-31","objectID":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/:3:1","tags":["杂文"],"title":"2022年总结和2023年计划","uri":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/"},{"categories":["工作"],"content":"2023年目标设定 账户市值到 80 万。 ","date":"2022-12-31","objectID":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/:3:2","tags":["杂文"],"title":"2022年总结和2023年计划","uri":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/"},{"categories":["工作"],"content":"写作及自媒体方面 ","date":"2022-12-31","objectID":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/:4:0","tags":["杂文"],"title":"2022年总结和2023年计划","uri":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/"},{"categories":["工作"],"content":"2022年目标完成情况 年初关注人数：58,291人。年末关注人数：71,823人。 离计划的 8 万人差距不小，主要还是公众号已经没落了，微信公众号整体都在走下坡路，大家刷短视频的时间更多。所以，现在关注人数之类的已经不重要了。 今年 6 月出版了新书《 IT 审计:用SQL+Python提升工作效率》。 ","date":"2022-12-31","objectID":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/:4:1","tags":["杂文"],"title":"2022年总结和2023年计划","uri":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/"},{"categories":["工作"],"content":"2023年目标设定 维持公众号平均四五千的阅读率就好了。 和林铖再把《审计效率手册》里面的内容更新下，出第二版。 B站偶尔更新下平时自己学习的内容。 ","date":"2022-12-31","objectID":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/:4:2","tags":["杂文"],"title":"2022年总结和2023年计划","uri":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/"},{"categories":["工作"],"content":"遛娃及健康 平时工作、出差比较多，陪娃的时间比较少，感觉也很难做到了。 11月买了辆自行车，开始骑行锻炼，不过最近一个月都在出差，也有一个月没有骑了。 2023年全年计划至少骑行 1500KM 。降低体脂率，保持比较健康的身体。 ","date":"2022-12-31","objectID":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/:5:0","tags":["杂文"],"title":"2022年总结和2023年计划","uri":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/"},{"categories":["工作"],"content":"结语 2022年已过，留下了不少困惑、遗憾，不过幸运的是全家身体都健康，也没什么灾难。 2023年，继续打工挣钱，学习屠龙技，保守平常心，练就金刚身，不惧艰难事。 ","date":"2022-12-31","objectID":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/:6:0","tags":["杂文"],"title":"2022年总结和2023年计划","uri":"/posts/20221231214704-2022%E5%B9%B4%E6%80%BB%E7%BB%93%E5%92%8C2023%E5%B9%B4%E8%AE%A1%E5%88%92/"},{"categories":["工作"],"content":"我们部门一部分业务是 IT 审计，平时是需要用到 Python 的。 这个东西是需要动手写的，光看、光听是学不会的。 前面财审同事做一个项目，需要计算机场补贴，这中间涉及到大量条件判断，用 Excel 人工非常耗时。 我们协助去写些自动化的 Python 工具，实现自动化批量计算。 给想学的同事都布置了任务，希望能从解决问题的过程中学习。 另外， 去年同事列了 60 多个招标网站的爬虫需求，想每天自动获取信息，然后把与我们服务相关的信息发送邮件到领导那里。 同事之前用 requests 库写了爬虫，但毛病是每次还得开了机才能运行，而且还是只能运行在 windows 上运行。 由于换了她 mac 电脑，之前的居然无效了。 这种大量爬虫正常逻辑应该是用 scrapy 框架写，然后用爬虫管理系统如 gerapy 、scrapy web等做定时任务，放在那里就不用管了。 周末花时间根据这个案例，录制了 2 个多小时的视频，上传到 B 站，希望大家能空闲的时候能动手写下。 遇到任何不懂的东西，具备动手学、动手干，是非常了不起的本事。 绝大部分人倒在第一步。 “三年天下无敌，十年战战兢兢” 迈过第一步，刚开始会觉得自己天下无敌， 随着知道的越多，才发现自己不行。 这需要自己不断地学习，更深入的学习，让自己更专业。 少说空话，动手干，比什么都强。 ","date":"2022-12-11","objectID":"/posts/20221211223131-%E5%8A%A8%E6%89%8B%E5%B9%B2/:0:0","tags":["效率"],"title":"动手干","uri":"/posts/20221211223131-%E5%8A%A8%E6%89%8B%E5%B9%B2/"},{"categories":["生活"],"content":"有时感到生活就是日复一日， 一天到头，屁事没干， 还会不停地自我怀疑， 感觉没有什么太大的价值， 这样一种心理现象， 要是放以前，就叫作“工作不饱和” 晚上十一点，骑着单车在天府大道， 这个点宽阔的马路上已经没有什么人了， 感受着凉风的抚摸， 聆听着隐藏在黑夜里的宁静， 微小的汗珠在摇摆中渗出额头， 在这初冬的凉风作用下， 一种莫名的畅快洗涤全身。 很久没有体会过运动的快乐了， 它是一种从身体到精神的塑造， 一种尚武的精神， 野蛮其体魄，文明其精神。 ","date":"2022-11-23","objectID":"/posts/20221123233550-%E6%97%A0%E9%A2%98_2022_11_23/:0:0","tags":["杂文"],"title":"无题 2022-11-23","uri":"/posts/20221123233550-%E6%97%A0%E9%A2%98_2022_11_23/"},{"categories":["生活"],"content":"上个月公司体检，检查我有轻度脂肪肝，我也从未想过自己有一天会和这个词有关。 主要自己平时从来都不锻炼身体，平时吃得又太好了。 为了改变，想着还是搞项运动吧。自己一直比较喜欢自行车，要不还是骑车锻炼吧。 说干就干，在京东买了辆 1000 元的山地车，昨天到货，按着教程组装上。 晚上等涵涵做完作业，我就出门骑车了。 沿着天府大道一路向北，天府五街、三街，一直快骑到金融城附近，又折返回来。 骑车还是比跑步要轻松些，吹着风，不冷不热， 看着马路旁繁华的写字楼， 时不时旁边穿过外卖小哥， 似乎生活的节奏慢了下来。 运动完感觉挺好的，以后争取没出差的时候每天都出去遛一圈。 今天我的小学弟给我寄了一个礼物， 他的工作就是炒股，每次见面都会聊聊股票。 很有意思的是他现在的女朋友还是去年通过我的公众号认识的， 计划后面结婚了。 她女朋友也很有意思，之前在杭州的一家事务所工作了 5 、6年时间。 然后 19 年辞职去一家软件公司做类似产品经理的岗位。 可以说完全跨行了，我还是非常佩服她的勇气。 不过她说又有点想回事务所，我感觉有可能是干审计不会太心累。 有时候听着别人的故事，也许他们随性而活，敢拼敢闯，做了一些自己也曾想像过的事， 心里还是会有些触动， 人生嘛，做些自己喜欢的事，挺好。 当听别人故事多了，有时候想是不是可以做一档连线节目， 通过对话的形势把这些故事分享给大家， 也许每个人都有脆弱的、犹豫的瞬间， 和我们一样经历的人的故事也许会给那一瞬间的自己以力量。 不知道公众号朋友有没有兴趣，也不知道大家想听什么？ 如果可以后面我可以尝试看看。 ","date":"2022-11-21","objectID":"/posts/20221121225209-%E9%AA%91%E8%A1%8C/:0:0","tags":["杂文"],"title":"骑行","uri":"/posts/20221121225209-%E9%AA%91%E8%A1%8C/"},{"categories":["工作"],"content":"前天和财审同事约好下午 4 点去客户那，我3:40到了，给同事发消息说我在楼下等他。 突然发现我和他约的时间是4:30……. 生活中我真的是马大哈。 我平时也没有到咖啡店的习惯， 穿着西裤的我，直接一屁股坐在马路旁的花坛边，打开电脑干点活。 突然微信里收到一条信息。 这是 16 年和我一起入职的一个小组的同事 SY ， 她说：“佳兵，我今天才关注你的公众号，一口气看了好多文章。那些关于追求自己的热爱、实现差异化、提高执行力方面的文字，看了之后真心有启发。真的，好棒！也让我回想起了在所工作的经历，累是真累，但大家是真好。” 她是我们当时最优秀的，我们小组一共 4 个新初级，第一个年报后她是唯一一个升职的。 我记得那个时候，她做的货币资金是最难的，基本上 14 项要函证的内容她都集齐了，做的东西都很漂亮，就和她人一样。但因为太累，她差不多干了 1 年就离职了。 而我那个时候，还在粘死数，预审完留给接手的黄狗一堆没有实质性内容的实质性底稿。 那个时候好累啊， 但那个时候也很快乐。 我在部队待了 8 年的时间，战友情是很特殊的情谊，它是在一起摸爬滚打，一起吃苦，一起完成重大任务的基础上建立起来的。 现在我到任何一个城市，都能找到以前的战友，也许以前并不是走得那么近，但一个电话，一定是能喝场酒的。 为什么呢？也许是因为对那个集体、那段岁月的怀念。 而当我来事务所干审计的时候，我在我们组也找到和战友情一样的情谊。 就像我给黄狗一堆屎一样的底稿，她除了经常嘲笑我外，二话不说，还是帮我完成了。 我们是可以在一个战壕里战斗的，可以背靠背相信对方的，可以相互帮助共同完成任务的。 也许正是因为一起吃过苦，所以以前的同事即使大部分都离职了，但还是每年能有机会聚会。 我问 SY 你现在在做什么？ 原来，她离职后就去练记忆术了，一年后顺利考到了世界记忆大师，在往记忆教练这个方向发展。 真的很佩服她，居然跨度这么大。 我高中的时候也研究过记忆术，当时看世界记忆力锦标赛的时候非常向往成为世界记忆力大师。 没想到 SY 那么有勇气和毅力。 平时很多人会感到迷茫，不知道干审计以后自己出去能干什么。 其实还有很多人，不被自己过去拘束，勇敢地追求自己的梦想， 也许这一路上并不顺利，但当你读到她的故事，就能感受到人生的精彩。 而这样的人还有很多， 当大家像被上了发条的木偶一样在即定的赛道上亦步亦趋时， 他们选择了逆行， 追寻着心中闪耀着的微小的梦想。 ","date":"2022-11-16","objectID":"/posts/20221116225214-%E6%88%91%E7%9A%84%E5%90%8C%E4%BA%8B/:0:0","tags":["杂文"],"title":"我的同事","uri":"/posts/20221116225214-%E6%88%91%E7%9A%84%E5%90%8C%E4%BA%8B/"},{"categories":["工作"],"content":"手机号码归属地解析 根据《2020 首发业务若干问题解答》第 53 问， IT 审计需要对互联网终端客户情况是否存在异常进行分析。 其中的分析维度就包含了消费者的地域分布。 当我们拿到的客户的数据，可能发现并没有终端用户所在的省、市信息， 只有终端用户的手机号码或者身份证等信息。 为了能进行地域分布的统计分析，本文将介绍如何利用 Python 将手机号码解析出省、市信息。 这里一共介绍三种方式，相信能够应对所有的情况。 ","date":"2022-10-09","objectID":"/posts/20221009221221-it%E5%AE%A1%E8%AE%A1_%E5%9C%B0%E5%9F%9F%E5%88%86%E5%B8%83%E4%B9%8B%E6%89%8B%E6%9C%BA%E5%8F%B7%E7%A0%81%E5%BD%92%E5%B1%9E%E5%9C%B0%E8%A7%A3%E6%9E%90/:1:0","tags":["IT审计","python"],"title":"IT审计-地域分布之手机号码归属地解析","uri":"/posts/20221009221221-it%E5%AE%A1%E8%AE%A1_%E5%9C%B0%E5%9F%9F%E5%88%86%E5%B8%83%E4%B9%8B%E6%89%8B%E6%9C%BA%E5%8F%B7%E7%A0%81%E5%BD%92%E5%B1%9E%E5%9C%B0%E8%A7%A3%E6%9E%90/"},{"categories":["工作"],"content":"phone库 我们可以使用 python 的phone库。 github链接：https://github.com/ls0f/phone 安装 在终端中用pip安装： pip install phone 用法 用法非常简单，这里是官方文档示例： from phone import Phone p = Phone() data = p.find(18190478611) print(data) 执行结果： {'phone': '18190478611', 'province': '四川', 'city': '德阳', 'zip_code': '618000', 'area_code': '0838', 'phone_type': '电信'} 我们可以从电话号码解析出：省、市、邮政编码、行政区划、运营商。 这个库更新时间为 2018 年10月。 由于作者似乎没有再更新，所以有些号码可能存在不能解析的情况。 ","date":"2022-10-09","objectID":"/posts/20221009221221-it%E5%AE%A1%E8%AE%A1_%E5%9C%B0%E5%9F%9F%E5%88%86%E5%B8%83%E4%B9%8B%E6%89%8B%E6%9C%BA%E5%8F%B7%E7%A0%81%E5%BD%92%E5%B1%9E%E5%9C%B0%E8%A7%A3%E6%9E%90/:1:1","tags":["IT审计","python"],"title":"IT审计-地域分布之手机号码归属地解析","uri":"/posts/20221009221221-it%E5%AE%A1%E8%AE%A1_%E5%9C%B0%E5%9F%9F%E5%88%86%E5%B8%83%E4%B9%8B%E6%89%8B%E6%9C%BA%E5%8F%B7%E7%A0%81%E5%BD%92%E5%B1%9E%E5%9C%B0%E8%A7%A3%E6%9E%90/"},{"categories":["工作"],"content":"phonenumbers库 除了上面的phone库外，我们这里还有一个一直保持更新的 python 库： python-phonenumbers 安装 pip install phonenumbers 用法 from phonenumbers import geocoder from phonenumbers import carrier import phonenumbers cn_number = phonenumbers.parse(\"18190478611\", \"CN\") # \"CN\"地区代码表示中国 # 电话号码的省和城市 city = geocoder.description_for_number(cn_number, \"zh\") # \"zh\"描述语言表示中文简体 # 电话号码的运营商 carrier = carrier.name_for_number(cn_number, \"zh\") # \"zh\"描述语言表示中文简体 print(city,carrier) 执行结果： 四川省德阳市 中国电信 这个库的优点是一直在更新，但相对来说他把省和城市是合在一起的，需要我们自己去做一个拆分。 不过我们在以前也介绍过如何将地址拆分成省、市、区信息。 ","date":"2022-10-09","objectID":"/posts/20221009221221-it%E5%AE%A1%E8%AE%A1_%E5%9C%B0%E5%9F%9F%E5%88%86%E5%B8%83%E4%B9%8B%E6%89%8B%E6%9C%BA%E5%8F%B7%E7%A0%81%E5%BD%92%E5%B1%9E%E5%9C%B0%E8%A7%A3%E6%9E%90/:1:2","tags":["IT审计","python"],"title":"IT审计-地域分布之手机号码归属地解析","uri":"/posts/20221009221221-it%E5%AE%A1%E8%AE%A1_%E5%9C%B0%E5%9F%9F%E5%88%86%E5%B8%83%E4%B9%8B%E6%89%8B%E6%9C%BA%E5%8F%B7%E7%A0%81%E5%BD%92%E5%B1%9E%E5%9C%B0%E8%A7%A3%E6%9E%90/"},{"categories":["工作"],"content":"免费API接口 对于上面的库，如果还有查不到的情况，我们可以使用下面的免费接口代替： import requests import json def parse_phone(phone_number): url = 'https://cx.shouji.360.cn/phonearea.php?number=%s' % phone_number response = requests.get(url) json_str = json.loads(response.text) return json_str['data'] data = parse_phone('18080073070') print(data) {'province': '四川', 'city': '成都', 'sp': '电信'} 这个 360 的接口，同样可以解析出省、市、运营商的信息。 通过三种解析电话号码归属地的方式，我们可以获取到地理位置信息，从而可以进一步去分析终端消费者的地域分布。 这对于 IPO 的项目的 IT 审计来说，应该是实用的。 ","date":"2022-10-09","objectID":"/posts/20221009221221-it%E5%AE%A1%E8%AE%A1_%E5%9C%B0%E5%9F%9F%E5%88%86%E5%B8%83%E4%B9%8B%E6%89%8B%E6%9C%BA%E5%8F%B7%E7%A0%81%E5%BD%92%E5%B1%9E%E5%9C%B0%E8%A7%A3%E6%9E%90/:1:3","tags":["IT审计","python"],"title":"IT审计-地域分布之手机号码归属地解析","uri":"/posts/20221009221221-it%E5%AE%A1%E8%AE%A1_%E5%9C%B0%E5%9F%9F%E5%88%86%E5%B8%83%E4%B9%8B%E6%89%8B%E6%9C%BA%E5%8F%B7%E7%A0%81%E5%BD%92%E5%B1%9E%E5%9C%B0%E8%A7%A3%E6%9E%90/"},{"categories":["工作"],"content":"国庆放假前一天在现场熬到凌晨两点， 然后写了一篇文章《国庆不加班》，并信誓旦旦地给项目组同事说，“谁让我加班，我就跑路”。 果然，我加了三天班， 也确实跑了，只是跑到所里加的班。 今天开会，领导说：“大家不接受新的事物，再等 10 年，就会被淘汰。” 我脑海里已想像出领导心中构想出的未来审计的画面： 领导说，当年他们干审计的时候用的是铅笔，用算盘做合并， 想想确实从审计作业模式、审计工具的使用上来说，已经发生了天翻地覆的变化。 但再仔细想想大家每天干的事： 任重道远。 注：本文图片由百度AI ERNIE-ViLG模型生成 ","date":"2022-10-08","objectID":"/posts/20221008225536-%E6%9C%AA%E6%9D%A5%E7%9A%84%E5%AE%A1%E8%AE%A1/:0:0","tags":["审计"],"title":"未来的审计","uri":"/posts/20221008225536-%E6%9C%AA%E6%9D%A5%E7%9A%84%E5%AE%A1%E8%AE%A1/"},{"categories":["工作"],"content":"好几天没有更新文章了，最近有点忙。 我一个多月没有回家了，上周五刚回家，就被迫到所里加班两天。 还没来得及陪孩子出去走走。 在会计师事务所，很难有闲下来的时间。 虽然这样，正常情况下，我尽量让自己不一天从起床到睡觉都在工作。 说实话，我估计这样我也忍受不了。 其实人一天到晚没有一点自己的时间的话，效率会很低下，心情也会很低下，至少我是如此。 我喜欢晚上能有自己时间学习新东西，写写东西，或者躺着刷刷视频。 其实每天我也没有干什么实质性的东西， 感觉打几个电话，发几条信息，时间就过去了。 当然我是喜欢记录的人，也是喜欢优化工作流的人。 在使用 emacs 后，我把所有工作、学习的事全放在上面。 ","date":"2022-09-26","objectID":"/posts/20220926223437-%E5%BF%99/:0:0","tags":["emacs","效率"],"title":"忙","uri":"/posts/20220926223437-%E5%BF%99/"},{"categories":["工作"],"content":"GTD 工作中接收到什么任务或者想到做什么事，先记录在我的 GTD 清单中。 尽量不让这些事占据我的大脑，影响手头在做的事。 等空闲的时候查看生成的排期，保证先做重要紧急的事。 这样可以只专注于一件事情，不用脑子里想太多东西。 每天也可以回顾下，一天中花费的时间在哪里： 不过开始做一件事的时候，我也经常忘记记时，可能还没有养成这个习惯。 ","date":"2022-09-26","objectID":"/posts/20220926223437-%E5%BF%99/:1:0","tags":["emacs","效率"],"title":"忙","uri":"/posts/20220926223437-%E5%BF%99/"},{"categories":["工作"],"content":"笔记 emacs的org mode是强大的笔记系统。 不管是写公众号文章还是平时学习的笔记都会记录下来： 写完后，也可以一键转为其他格式的文件，如 markdown ，pdf， docx 等，方便和别人分享，并且不需要考虑排版问题。 除了学习外，我也把做过的项目上的记录放在里面： 使用了org roam插件，可以建立双链笔记，一个项目从开头到结束的内容全部记录在里面。 包括： 审计计划 沟通记录 会议纪要 审计内容 重大事项的备忘录 当然如果是项目上每天的工作安排还是记录在前面说的 GTD 上，使用了org agenda插件。 ","date":"2022-09-26","objectID":"/posts/20220926223437-%E5%BF%99/:2:0","tags":["emacs","效率"],"title":"忙","uri":"/posts/20220926223437-%E5%BF%99/"},{"categories":["工作"],"content":"代码 当然，平时还可以使用 emacs 来写 python 代码 甚至在org mode写笔记的时候，也可以执行代码，进行文学编程： 这对于学习编程、写笔记文章非常友好。 ","date":"2022-09-26","objectID":"/posts/20220926223437-%E5%BF%99/:3:0","tags":["emacs","效率"],"title":"忙","uri":"/posts/20220926223437-%E5%BF%99/"},{"categories":["工作"],"content":"结语 最后，我感觉打造属于自己的一套工具链是有好处的。 能让自己按部就班的完成每天的工作， 随着工作流程不断的优化和熟练， 能提高自己的学习、工作效率。 ","date":"2022-09-26","objectID":"/posts/20220926223437-%E5%BF%99/:4:0","tags":["emacs","效率"],"title":"忙","uri":"/posts/20220926223437-%E5%BF%99/"},{"categories":["工作"],"content":"在实践中， IT 审计团队通常是和财务审计团队配合完成审计工作的，区别是财务审计是对被审计单位的财务报表及其附注发表意见，而 IT 审计是对信息系统发表意见。 我们所做的工作是通过测试财务报表所依赖的信息系统(包括财务系统和业务系统）的有效性、数据的真实性，证明信息系统环境是否可以信赖。从某种意义上来说， IT 审计是服务于财务审计。 随着财务审计对 IT 审计工作的了解，他们会对 IT 审计提出更多 IT 审计工作范围外的期待。 尤其是在企业信息化浪潮下，受限于技术能力，财务审计团队在数据处理，方法创新方面对 IT 审计团队提出了更高的要求。因此 IT 审计如何更好地辅助财务审计是一个新的课题。 ","date":"2022-09-18","objectID":"/posts/20220918151947-it%E5%AE%A1%E8%AE%A1%E4%B9%8B%E8%BE%85%E5%8A%A9%E8%B4%A2%E5%8A%A1%E5%AE%A1%E8%AE%A1/:0:0","tags":["IT审计","python"],"title":"IT审计之辅助财务审计","uri":"/posts/20220918151947-it%E5%AE%A1%E8%AE%A1%E4%B9%8B%E8%BE%85%E5%8A%A9%E8%B4%A2%E5%8A%A1%E5%AE%A1%E8%AE%A1/"},{"categories":["工作"],"content":"利用Python代替繁重计算 在财务审计中存在大量数据处理、数据计算的基础性工作，对于这类有逻辑重复性工作， IT 审计团队可以借助 Python 批量完成。 ","date":"2022-09-18","objectID":"/posts/20220918151947-it%E5%AE%A1%E8%AE%A1%E4%B9%8B%E8%BE%85%E5%8A%A9%E8%B4%A2%E5%8A%A1%E5%AE%A1%E8%AE%A1/:1:0","tags":["IT审计","python"],"title":"IT审计之辅助财务审计","uri":"/posts/20220918151947-it%E5%AE%A1%E8%AE%A1%E4%B9%8B%E8%BE%85%E5%8A%A9%E8%B4%A2%E5%8A%A1%E5%AE%A1%E8%AE%A1/"},{"categories":["工作"],"content":"成本还原 对于生产制造业的 IPO 审计项目，成产品的料工费占比是财务审计特别关注的事项。而很多企业采用了逐步结转分步法来核算生产成本，由于每一道工序的半成品将是下一道工序的原材料，所以要计算产成品真实的料工费占比就需要进行成本还原。 如果企业使用的 ERP 系统没有还原后的成本结构报表，同时财务成本会计也未手工编制成本结构报表，那么这项核查工作对于财务审计来说将是巨大的工作量。 对于这类财审提出的需求，我们会了解企业的生产工艺，以及成本还原的计算方法，再利用 Python 编程语言，模拟成本还原的计算过程，将产成品拆分成真实的料工费，从而计算出料工费的占比。 通过 IT 审计团队的辅助，财审团队能完成人工短时间无法完成的工作。 ","date":"2022-09-18","objectID":"/posts/20220918151947-it%E5%AE%A1%E8%AE%A1%E4%B9%8B%E8%BE%85%E5%8A%A9%E8%B4%A2%E5%8A%A1%E5%AE%A1%E8%AE%A1/:1:1","tags":["IT审计","python"],"title":"IT审计之辅助财务审计","uri":"/posts/20220918151947-it%E5%AE%A1%E8%AE%A1%E4%B9%8B%E8%BE%85%E5%8A%A9%E8%B4%A2%E5%8A%A1%E5%AE%A1%E8%AE%A1/"},{"categories":["工作"],"content":"保费收入与收款流水核对 在一家保险公司 IT 审计项目中，财审团队需要我们对保费收入与收款流水进行数据核对。 当我们了解到业务中存在大量多个保单对应多个收款流水的情况，对于这种多对多关系，正常是无法批量核对的。 一般情况下，我们核对的数据关系要么是一对一、多对一或者一对多。这三种情况我们写 SQL 语句时都很好处理，只需要将多条数据按单号聚合汇总再进行核对就可以。 这种多对多的关系我们可以借助数学图论中的二分图解决。 比如，我们将这种关系画上线，可以看到其中可以形成一些独立的网络，这里我们将这种网络（用不同颜色标记）简称为组。 我们将独立的网络编上组号，然后将两个数据集的金额分别按组号汇总再进行核对。 示例 Python 代码： class Net(object): def __init__(self): self.setA = { 'A': ['a', 'b', 'c'], 'B': ['d'], 'C': ['b'], 'D': ['a', 'c'], 'E': ['e'] } self.setB = { 'a': ['A', 'D'], 'b': ['A', 'C'], 'c': ['A', 'D'], 'd': ['B'], 'e': ['E'], } self.keys = list(self.setA.keys()) + list(self.setB.keys()) self.groups = {} def split_net(self): num = 0 for key in self.keys: if key not in self.groups.keys(): num += 1 self.loop_net(key, num) def loop_net(self, node, id): if node: self.groups[node] = id if node in self.setA.keys(): sub_nodes = self.setA[node] else: sub_nodes = self.setB[node] for sub_node in sub_nodes: if sub_node: if sub_node not in self.groups.keys(): self.loop_net(sub_node, id) if __name__ == '__main__': net = Net() net.split_net() print(net.groups) 我们借助 Python 构建了类Net,通过 loop_net函数递归找出两个数据集形成的独立网络，从而给独立网络分组，最后我们可以将两个数据集分别按组号聚合后进行核对。 ","date":"2022-09-18","objectID":"/posts/20220918151947-it%E5%AE%A1%E8%AE%A1%E4%B9%8B%E8%BE%85%E5%8A%A9%E8%B4%A2%E5%8A%A1%E5%AE%A1%E8%AE%A1/:1:2","tags":["IT审计","python"],"title":"IT审计之辅助财务审计","uri":"/posts/20220918151947-it%E5%AE%A1%E8%AE%A1%E4%B9%8B%E8%BE%85%E5%8A%A9%E8%B4%A2%E5%8A%A1%E5%AE%A1%E8%AE%A1/"},{"categories":["工作"],"content":"利用Python获取外部信息 在财务审计过程中，外部信息的可靠性大于内部信息，因此审计师会查询大量的外部信息与获取的内部信息做交叉验证。 例如，审计一家汽车硬件销售的企业，财务审计团队计划查询销售订单中对应的汽车车架号的信息，核实有没有真实车辆以及车型信息，以及判断查询的外部信息与订单信息是否存在矛盾。 企业 1 年的销售订单有 30 万，依赖审计师人工查询将不太现实。那么，我们 IT 审计团队提出了两种方案： 购买接口，通过 python 调用接口批量获取数据。 编写爬虫，通过 python 编写爬虫获取公开网站数据。 出于节约成本考虑我们选择编写爬虫获取公开信息，用 python 的selenium包，自动查询网站数据，并将结果保存到本地文件。 视频 最后再由财务审计团队对外部信息与内部信息的一致性进行判断。 当然，对于很多公开网站都会有反爬措施，如验证码、访问频率限制、字体混淆等，对于我们 IT 审计团队提出了一定的技术要求。 除此外，财务审计对于外部信息的获取有很大的需求，如同行业财务指标、公司公告、发函快递信息、汇率、交易性金融资产价格等等。 这类需求，随着这几年的发展已有很多成熟的商业网站可以满足，但对于一些特殊的、行业属性较强的小众信息，如果不能批量查询，那么 IT 审计团队就可以辅助财务审计完成信息获取工作。 ","date":"2022-09-18","objectID":"/posts/20220918151947-it%E5%AE%A1%E8%AE%A1%E4%B9%8B%E8%BE%85%E5%8A%A9%E8%B4%A2%E5%8A%A1%E5%AE%A1%E8%AE%A1/:2:0","tags":["IT审计","python"],"title":"IT审计之辅助财务审计","uri":"/posts/20220918151947-it%E5%AE%A1%E8%AE%A1%E4%B9%8B%E8%BE%85%E5%8A%A9%E8%B4%A2%E5%8A%A1%E5%AE%A1%E8%AE%A1/"},{"categories":["工作"],"content":"利用IT技术进行方法创新 2020年 6 月24日，证监会依法对獐子岛公司信息披露违法违规案作出行政处罚及市场禁入决定。证监会将渔船的北斗定位信息，通过第三方机构还原出航行轨迹，从而计算出采捕区域面积，进而估算真实成本。 根据这则公开披露的信息，启发了我们利用信息技术的优势，对相关数据进行深入分析挖掘，使审计工作更加智慧、高效。我们 IT 审计团队相对有信息技术的优势，而财务审计团队在财务处理、项目风险识别等方面更有优势，两个团队的良好融合会发挥1+1\u003e2的效果。 对于这类精纬度空间信息，我们可以通过 Python 计算面积、周长、距离。 示例 Python 代码： from pyproj import Geod # 导入Geod类 from shapely.geometry import Point, LineString, Polygon # 导入点、线、多边形类 # 计算封闭区域面积、周长 geod = Geod(ellps=\"WGS84\") # 创建一个WGS84坐标系 polygon = Polygon([(116.169465, 39.932670), (116.160260, 39.924492), (116.150625, 39.710019), (116.183198, 39.709920), (116.226950, 39.777616), (116.442621, 39.799892), (116.463478, 39.790066), (116.588276, 39.809551), (116.536091, 39.808859), (116.573856, 39.839643), (116.706380, 39.916740), (116.600293, 39.937770), (116.514805, 39.982375), (116.499935, 40.013710), (116.546520, 40.030443), (116.687668, 40.129961), (116.539697, 40.080659), (116.503390, 40.058474), (116.468800, 40.052578)]) # 将多个精纬度坐标实例化为Polygon多边形对象 poly_area, poly_perimeter = geod.geometry_area_perimeter(polygon) # 计算多边形面积和周长 print(poly_area, poly_perimeter) # 打印面积和周长 面积:951546279.1726327 周长:183419.43445625657 ","date":"2022-09-18","objectID":"/posts/20220918151947-it%E5%AE%A1%E8%AE%A1%E4%B9%8B%E8%BE%85%E5%8A%A9%E8%B4%A2%E5%8A%A1%E5%AE%A1%E8%AE%A1/:3:0","tags":["IT审计","python"],"title":"IT审计之辅助财务审计","uri":"/posts/20220918151947-it%E5%AE%A1%E8%AE%A1%E4%B9%8B%E8%BE%85%E5%8A%A9%E8%B4%A2%E5%8A%A1%E5%AE%A1%E8%AE%A1/"},{"categories":["工作"],"content":"结语 随着新技术、新模式在企业发展过程中不断涌现，财务审计与 IT 审计的融合将会更加紧密。在这样的背景下， IT 审计的工作界限未来可能会更加模糊， IT 审计如何发挥我们的优势辅助财务审计高效、智慧地完成审计工作需要我们共同探索。 ","date":"2022-09-18","objectID":"/posts/20220918151947-it%E5%AE%A1%E8%AE%A1%E4%B9%8B%E8%BE%85%E5%8A%A9%E8%B4%A2%E5%8A%A1%E5%AE%A1%E8%AE%A1/:4:0","tags":["IT审计","python"],"title":"IT审计之辅助财务审计","uri":"/posts/20220918151947-it%E5%AE%A1%E8%AE%A1%E4%B9%8B%E8%BE%85%E5%8A%A9%E8%B4%A2%E5%8A%A1%E5%AE%A1%E8%AE%A1/"},{"categories":["工作"],"content":"在处理空间地理信息时，我们常常需要与精纬度打交道。例如，物流运输行业，我们需要计算行驶轨迹的距离，或者对位置信息的可视化，都需要用到精纬度信息。 但有时候，我们获取到的可能只是一个行政区划代码或者是地址信息。我们需要解析出精纬度，从而为下一步计算和可视化打下基础。 之前我们介绍过 python 的cpca库将地址解析成省、市、区信息，而它自身还带有全国行政区划的精纬度信息。 ","date":"2022-09-18","objectID":"/posts/20220918230007-python%E8%8E%B7%E5%8F%96%E8%A1%8C%E6%94%BF%E5%8C%BA%E5%88%92%E7%9A%84%E7%B2%BE%E7%BA%AC%E5%BA%A6/:0:0","tags":["python","IT审计"],"title":"python获取行政区划的精纬度","uri":"/posts/20220918230007-python%E8%8E%B7%E5%8F%96%E8%A1%8C%E6%94%BF%E5%8C%BA%E5%88%92%E7%9A%84%E7%B2%BE%E7%BA%AC%E5%BA%A6/"},{"categories":["工作"],"content":"地址拆分为行政区划 通过pip install cpca安装好 cpca 库后，我们通过简单几行代码就可以将地址拆分成省市区信息，以及对应的行政区划代码。 location_str = [\"徐汇区虹漕路461号58号楼5楼\", \"泉州市洛江区万安塘西工业区\", \"北京朝阳区北苑华贸城\"] import cpca df = cpca.transform(location_str) print(df) ","date":"2022-09-18","objectID":"/posts/20220918230007-python%E8%8E%B7%E5%8F%96%E8%A1%8C%E6%94%BF%E5%8C%BA%E5%88%92%E7%9A%84%E7%B2%BE%E7%BA%AC%E5%BA%A6/:1:0","tags":["python","IT审计"],"title":"python获取行政区划的精纬度","uri":"/posts/20220918230007-python%E8%8E%B7%E5%8F%96%E8%A1%8C%E6%94%BF%E5%8C%BA%E5%88%92%E7%9A%84%E7%B2%BE%E7%BA%AC%E5%BA%A6/"},{"categories":["工作"],"content":"解析行政区划精纬度 这个库本身并没有解析精纬度的函数，但是我在查看源代码的时候，发现他这个adcodes.csv文件中有行政区划的精纬度信息。 一下就来了精神。 首先我们查看下 cpca 库包装的路径在哪，才能找到这个文件: pip3 show cpca 我发现在我的电脑上文件是在/home/nigo/.local/lib/python3.10/site-packages路径下。 这下我们可以本地直接解析出行政区划的精纬度了，这个目前最小单位是到“区”一级。 import pandas as pd # 读取数据(需要修改成你本地自己的路径） df = pd.read_csv('/home/nigo/.local/lib/python3.10/site-packages/cpca/resources/adcodes.csv',converters={'adcode':str}) data = {} # 循环数据，建立行政区划与经纬度的关系字典 for index,row in df.iterrows(): area_code = row['adcode'] area_code = area_code[:6] data[area_code] = (row['longitude'],row['latitude']) def get_lon_lat(area_code): \"\"\"根据行政区划代码查询经纬度\"\"\" return data[area_code] if __name__ == \"__main__\": lon,lat = get_lon_lat('310104') print(lon,lat) ","date":"2022-09-18","objectID":"/posts/20220918230007-python%E8%8E%B7%E5%8F%96%E8%A1%8C%E6%94%BF%E5%8C%BA%E5%88%92%E7%9A%84%E7%B2%BE%E7%BA%AC%E5%BA%A6/:2:0","tags":["python","IT审计"],"title":"python获取行政区划的精纬度","uri":"/posts/20220918230007-python%E8%8E%B7%E5%8F%96%E8%A1%8C%E6%94%BF%E5%8C%BA%E5%88%92%E7%9A%84%E7%B2%BE%E7%BA%AC%E5%BA%A6/"},{"categories":["工作"],"content":"结语 在之前审计的物流运输企业中，物理轨迹的精纬度是单独存放的，而运输订单只有行政区划代码和城市名称，有了这个库就可以不借助第三方接口，方便地解析出起运点和运达点的精纬度。 从而可以计算运输距离，再进一步进行数据分析和数据可视化。 ","date":"2022-09-18","objectID":"/posts/20220918230007-python%E8%8E%B7%E5%8F%96%E8%A1%8C%E6%94%BF%E5%8C%BA%E5%88%92%E7%9A%84%E7%B2%BE%E7%BA%AC%E5%BA%A6/:3:0","tags":["python","IT审计"],"title":"python获取行政区划的精纬度","uri":"/posts/20220918230007-python%E8%8E%B7%E5%8F%96%E8%A1%8C%E6%94%BF%E5%8C%BA%E5%88%92%E7%9A%84%E7%B2%BE%E7%BA%AC%E5%BA%A6/"},{"categories":["工作"],"content":"平时我们想获取一些网页的信息，需要写爬虫，有些网站有各种验证码，增加了我们工作的一些困难。 在上个咨询项目中，我发现了一个识别验证码的库，非常好用，推荐给有需要的朋友。 它的名字就叫带带弟弟OCR ，看名字就是拯救我们这类小白的。 他不用安装什么深度学习框架，不需要搞一堆训练集训练，直接安装就可以使用。 ","date":"2022-09-17","objectID":"/posts/20220917225722-%E5%B8%A6%E5%B8%A6%E5%BC%9F%E5%BC%9Focr/:0:0","tags":["python"],"title":"带带弟弟ocr","uri":"/posts/20220917225722-%E5%B8%A6%E5%B8%A6%E5%BC%9F%E5%BC%9Focr/"},{"categories":["工作"],"content":"安装 pip install ddddocr ","date":"2022-09-17","objectID":"/posts/20220917225722-%E5%B8%A6%E5%B8%A6%E5%BC%9F%E5%BC%9Focr/:1:0","tags":["python"],"title":"带带弟弟ocr","uri":"/posts/20220917225722-%E5%B8%A6%E5%B8%A6%E5%BC%9F%E5%BC%9Focr/"},{"categories":["工作"],"content":"识别数字验证码 这里我们拿个最简单的数字验证码看看 我们只需要几行代码，就可以完成数字验证码的识别： import ddddocr ocr = ddddocr.DdddOcr(show_ad=False) with open(\"./images/2022-09-17_23-09-27_screenshot.png\", 'rb') as f: image = f.read() res = ocr.classification(image) print(res) 简单、易用，准确率极高。 在 github 上的介绍页面上，经过大家测试对于这些数字验证码都是可以准确识别的。 ","date":"2022-09-17","objectID":"/posts/20220917225722-%E5%B8%A6%E5%B8%A6%E5%BC%9F%E5%BC%9Focr/:2:0","tags":["python"],"title":"带带弟弟ocr","uri":"/posts/20220917225722-%E5%B8%A6%E5%B8%A6%E5%BC%9F%E5%BC%9Focr/"},{"categories":["工作"],"content":"点选验证码 在介绍页面，这种点选的验证码，也是可以识别的。 ","date":"2022-09-17","objectID":"/posts/20220917225722-%E5%B8%A6%E5%B8%A6%E5%BC%9F%E5%BC%9Focr/:3:0","tags":["python"],"title":"带带弟弟ocr","uri":"/posts/20220917225722-%E5%B8%A6%E5%B8%A6%E5%BC%9F%E5%BC%9Focr/"},{"categories":["工作"],"content":"滑块验证码 竟然还支持滑块验证码的识别，真香！ ","date":"2022-09-17","objectID":"/posts/20220917225722-%E5%B8%A6%E5%B8%A6%E5%BC%9F%E5%BC%9Focr/:4:0","tags":["python"],"title":"带带弟弟ocr","uri":"/posts/20220917225722-%E5%B8%A6%E5%B8%A6%E5%BC%9F%E5%BC%9Focr/"},{"categories":["工作"],"content":"官方文档 这个ddddocr的官方文档地址： https://github.com/sml2h3/ddddocr 对于很多需要破解验证码的网站来说，这个库真是神器。 ","date":"2022-09-17","objectID":"/posts/20220917225722-%E5%B8%A6%E5%B8%A6%E5%BC%9F%E5%BC%9Focr/:5:0","tags":["python"],"title":"带带弟弟ocr","uri":"/posts/20220917225722-%E5%B8%A6%E5%B8%A6%E5%BC%9F%E5%BC%9Focr/"},{"categories":["生活"],"content":"因为成都疫情回不了家，所以我买了张票到媳妇湖南老家去了。 到家后拍了一张照片，在朋友圈发了个状态“日落而归”。 这里夕阳很美。 院子里有两棵树, 这是 2011 年我大三的时候，第一次去她家我们俩种的。 如今，已经这么大了，我们从恋爱到现在也有十多年了。 当年来的时候，他爸爸还在砌这堵墙， 而我就扛着扁担给他爸爸担砖。 晚饭，陪她爸爸喝完酒，在通向山上的马路上散步， 凉风习习，鸟叫虫鸣。 向山下的村子望去， 一片安静详和。 ","date":"2022-09-09","objectID":"/posts/20220909213543-%E6%97%A5%E8%90%BD%E8%80%8C%E5%BD%92/:0:0","tags":["杂文"],"title":"日落而归","uri":"/posts/20220909213543-%E6%97%A5%E8%90%BD%E8%80%8C%E5%BD%92/"},{"categories":["工作"],"content":"之前我有个错觉，很多活只有我能干。 因为很多次问大家，都没人说能干，或者安排了也没干出来。 但，实际上大家都能学出来，之所以没学出来，是因为没有“机会”。 这有两方面原因： 个人原因。 环境原因。 很多人觉得学个东西，得学成了，有 10 分把握了才能干活。不敢去尝试，或者没有好奇心想去尝试。其实当你有 3 分把握的事，都应该去试试。 这是个人的因素，当只有 3 分的实力，愿意去尝试 10 分的事的时候，我感觉人是有创造力的，也是有精气神的。 当然也有环境的因素，以前是没人干，你稍微会一点点就被迫营业了，这有压力，更多的是机会。因为外界对你的期望不高，做不出来也没关系。做出来就会的强烈的正向反馈。 现在呢，可能如果不是自己积极主动，别人觉得你干不了这活，也不会交给你了。失去了这种外界给自己的压力，其实也就失去了非常宝贵的机会。 把几位同事拉进了一个学习群，周一安排了一个做个小工具的任务，黄小仙主动领命，今天就给把成品交给我了。 我感觉还是非常快速的。就算让我去做，我其实也是先网上学习相关文档，然后根据需求写，不一定比她写得快。 我知道，有 3 分本事不断尝试做 10 分的事，这是最快速的成长方法。 这 3 分本事，是自己平时主动学习的结果。 而这 10 分的事，有可能是别人逼你的，也可能是你自己争取的。 无论怎样，循环下去，将看到恐怖的成长。 我感觉以后我可以摸鱼了！ ","date":"2022-09-08","objectID":"/posts/20220908232514-%E6%88%91%E8%AF%A5%E6%91%B8%E9%B1%BC%E4%BA%86/:0:0","tags":["杂文"],"title":"我该摸鱼了","uri":"/posts/20220908232514-%E6%88%91%E8%AF%A5%E6%91%B8%E9%B1%BC%E4%BA%86/"},{"categories":["工作"],"content":"oslaw 前两天，看到有人在一个群里问“哪里可以查马来西亚工商信息。” 有人推荐了一个网址：http://www.oslaw.net/ 其中给了查询境外工商信息的方式。 我看了下这个 oslaw 网站，是一个中介机构常用查询网站的集合，还不错，推荐给大家。 ","date":"2022-09-04","objectID":"/posts/20220904220239-%E5%88%B8%E5%95%86_%E5%BE%8B%E5%B8%88_%E5%AE%A1%E8%AE%A1%E5%BF%85%E5%A4%87%E7%BD%91%E7%AB%99/:1:0","tags":["效率"],"title":"券商、律师、审计必备网站","uri":"/posts/20220904220239-%E5%88%B8%E5%95%86_%E5%BE%8B%E5%B8%88_%E5%AE%A1%E8%AE%A1%E5%BF%85%E5%A4%87%E7%BD%91%E7%AB%99/"},{"categories":["工作"],"content":"主体信息 可以查询境内企业，其他组织/实体，境外实体，海外基金，自然人的相关信息。 ","date":"2022-09-04","objectID":"/posts/20220904220239-%E5%88%B8%E5%95%86_%E5%BE%8B%E5%B8%88_%E5%AE%A1%E8%AE%A1%E5%BF%85%E5%A4%87%E7%BD%91%E7%AB%99/:1:1","tags":["效率"],"title":"券商、律师、审计必备网站","uri":"/posts/20220904220239-%E5%88%B8%E5%95%86_%E5%BE%8B%E5%B8%88_%E5%AE%A1%E8%AE%A1%E5%BF%85%E5%A4%87%E7%BD%91%E7%AB%99/"},{"categories":["工作"],"content":"知识产权 可以查商标、专利、著作权、域名、政府机构、港澳台及境外、知识产权诉讼等相关信息。 ","date":"2022-09-04","objectID":"/posts/20220904220239-%E5%88%B8%E5%95%86_%E5%BE%8B%E5%B8%88_%E5%AE%A1%E8%AE%A1%E5%BF%85%E5%A4%87%E7%BD%91%E7%AB%99/:1:2","tags":["效率"],"title":"券商、律师、审计必备网站","uri":"/posts/20220904220239-%E5%88%B8%E5%95%86_%E5%BE%8B%E5%B8%88_%E5%AE%A1%E8%AE%A1%E5%BF%85%E5%A4%87%E7%BD%91%E7%AB%99/"},{"categories":["工作"],"content":"动产/不动产 可以查询动产、土地、房产、矿产相关信息。 ","date":"2022-09-04","objectID":"/posts/20220904220239-%E5%88%B8%E5%95%86_%E5%BE%8B%E5%B8%88_%E5%AE%A1%E8%AE%A1%E5%BF%85%E5%A4%87%E7%BD%91%E7%AB%99/:1:3","tags":["效率"],"title":"券商、律师、审计必备网站","uri":"/posts/20220904220239-%E5%88%B8%E5%95%86_%E5%BE%8B%E5%B8%88_%E5%AE%A1%E8%AE%A1%E5%BF%85%E5%A4%87%E7%BD%91%E7%AB%99/"},{"categories":["工作"],"content":"行政处罚及征信 可以查询各部委处罚、信用中国、以及一些各平台的征信信息。 ","date":"2022-09-04","objectID":"/posts/20220904220239-%E5%88%B8%E5%95%86_%E5%BE%8B%E5%B8%88_%E5%AE%A1%E8%AE%A1%E5%BF%85%E5%A4%87%E7%BD%91%E7%AB%99/:1:4","tags":["效率"],"title":"券商、律师、审计必备网站","uri":"/posts/20220904220239-%E5%88%B8%E5%95%86_%E5%BE%8B%E5%B8%88_%E5%AE%A1%E8%AE%A1%E5%BF%85%E5%A4%87%E7%BD%91%E7%AB%99/"},{"categories":["工作"],"content":"诉讼仲裁 可以查询司法案例、审判流程、执行、仲裁、涉外、法院及检察院相关信息。 ","date":"2022-09-04","objectID":"/posts/20220904220239-%E5%88%B8%E5%95%86_%E5%BE%8B%E5%B8%88_%E5%AE%A1%E8%AE%A1%E5%BF%85%E5%A4%87%E7%BD%91%E7%AB%99/:1:5","tags":["效率"],"title":"券商、律师、审计必备网站","uri":"/posts/20220904220239-%E5%88%B8%E5%95%86_%E5%BE%8B%E5%B8%88_%E5%AE%A1%E8%AE%A1%E5%BF%85%E5%A4%87%E7%BD%91%E7%AB%99/"},{"categories":["工作"],"content":"法律法规 可以查询法规数据库、政府网站对应的法律法规。 ","date":"2022-09-04","objectID":"/posts/20220904220239-%E5%88%B8%E5%95%86_%E5%BE%8B%E5%B8%88_%E5%AE%A1%E8%AE%A1%E5%BF%85%E5%A4%87%E7%BD%91%E7%AB%99/:1:6","tags":["效率"],"title":"券商、律师、审计必备网站","uri":"/posts/20220904220239-%E5%88%B8%E5%95%86_%E5%BE%8B%E5%B8%88_%E5%AE%A1%E8%AE%A1%E5%BF%85%E5%A4%87%E7%BD%91%E7%AB%99/"},{"categories":["工作"],"content":"资质证照 可以查询常规、电信、文化传媒相关的资质证照信息。 ","date":"2022-09-04","objectID":"/posts/20220904220239-%E5%88%B8%E5%95%86_%E5%BE%8B%E5%B8%88_%E5%AE%A1%E8%AE%A1%E5%BF%85%E5%A4%87%E7%BD%91%E7%AB%99/:1:7","tags":["效率"],"title":"券商、律师、审计必备网站","uri":"/posts/20220904220239-%E5%88%B8%E5%95%86_%E5%BE%8B%E5%B8%88_%E5%AE%A1%E8%AE%A1%E5%BF%85%E5%A4%87%E7%BD%91%E7%AB%99/"},{"categories":["工作"],"content":"资本市场 资本市场相关的信息查询网站 ","date":"2022-09-04","objectID":"/posts/20220904220239-%E5%88%B8%E5%95%86_%E5%BE%8B%E5%B8%88_%E5%AE%A1%E8%AE%A1%E5%BF%85%E5%A4%87%E7%BD%91%E7%AB%99/:1:8","tags":["效率"],"title":"券商、律师、审计必备网站","uri":"/posts/20220904220239-%E5%88%B8%E5%95%86_%E5%BE%8B%E5%B8%88_%E5%AE%A1%E8%AE%A1%E5%BF%85%E5%A4%87%E7%BD%91%E7%AB%99/"},{"categories":["工作"],"content":"医疗卫生 可以查询医疗卫生相关的信息。 ","date":"2022-09-04","objectID":"/posts/20220904220239-%E5%88%B8%E5%95%86_%E5%BE%8B%E5%B8%88_%E5%AE%A1%E8%AE%A1%E5%BF%85%E5%A4%87%E7%BD%91%E7%AB%99/:1:9","tags":["效率"],"title":"券商、律师、审计必备网站","uri":"/posts/20220904220239-%E5%88%B8%E5%95%86_%E5%BE%8B%E5%B8%88_%E5%AE%A1%E8%AE%A1%E5%BF%85%E5%A4%87%E7%BD%91%E7%AB%99/"},{"categories":["工作"],"content":"效率工具 一些办公上用得到的软件也罗列了下： 当然，如果你有自己常用的网站也可以在上面“我的导航”中添加自己喜欢的。 ","date":"2022-09-04","objectID":"/posts/20220904220239-%E5%88%B8%E5%95%86_%E5%BE%8B%E5%B8%88_%E5%AE%A1%E8%AE%A1%E5%BF%85%E5%A4%87%E7%BD%91%E7%AB%99/:1:10","tags":["效率"],"title":"券商、律师、审计必备网站","uri":"/posts/20220904220239-%E5%88%B8%E5%95%86_%E5%BE%8B%E5%B8%88_%E5%AE%A1%E8%AE%A1%E5%BF%85%E5%A4%87%E7%BD%91%E7%AB%99/"},{"categories":["工作"],"content":"结语 我也把这个网站以及一些国外的工商信息网站收录到审计军火库中。 如果还有其他什么好的资源，可以分享到审计军火库： https://gitee.com/nigo81/audit-guid 可以方便大家查询收藏。 ","date":"2022-09-04","objectID":"/posts/20220904220239-%E5%88%B8%E5%95%86_%E5%BE%8B%E5%B8%88_%E5%AE%A1%E8%AE%A1%E5%BF%85%E5%A4%87%E7%BD%91%E7%AB%99/:1:11","tags":["效率"],"title":"券商、律师、审计必备网站","uri":"/posts/20220904220239-%E5%88%B8%E5%95%86_%E5%BE%8B%E5%B8%88_%E5%AE%A1%E8%AE%A1%E5%BF%85%E5%A4%87%E7%BD%91%E7%AB%99/"},{"categories":["生活"],"content":"晚上吃了碗面，一个人在酒店楼下抽着烟。 准备一柱香的时间就上楼去。 当我刷着手机，突然一个中年妇女走到我面前。 “给我买份饭吧，我和我妹妹几顿没吃了。”她说着，然后指了下几米远的另一个中年妇女。 她说话很小声，我还没怎么反应过来。 大概两秒后，我仔细看了下她们，衣着整洁，背着包，怎么也不像吃不起饭的样子。 正常情况下，只要是遇到好手好脚的，问我要钱我都不会给，肯定是骗子。 不过呢，酒店底楼旁就是一个小餐馆，卖一些盖饭、面之类的。给她们买份饭，好像我也不会被骗什么。 于是，我说：“好，走嘛。” 带他们进了小餐馆，她们点了盖饭，一共 36 元，扫完码，我就闪了，也没有多余的话。 以前，我遇到的都是什么要车费啊，要吃饭的钱之类的，总之都是要钱。 这种要人买份饭还是第一次。 回来我还在网上专门查了查，发现还挺多这种情况的。 有人反映这种骗人的套路就是你给买了饭后，吃了装痛苦，让人赔医药费。 还好，我付完钱就走了。 小时候，我爸就教我要心善，多做好事。 只要出去遇到断手断脚的，他都会给几块、十块钱。 回乡下老家的时候，看到村子里的傻子坐在我们家门口，也会去盛些肉和饭给他吃。 也许他们都是信因果报应的，认为做善事就会积福。 我爸是修车的，从十几岁从农村出来， 最开始修自行车、后来修摩托车、再后来修货车，一辈子挣的都是血汗钱。 2017年，他从 5 、6米高的地方摔下来，脑内大出血，做了开颅手术，活了下来。 当时我还在年报现场，第二天赶回去的时候，我感觉他可能要走了。因为在 07 年我大伯也是做了开颅手术，没两天就走了。 幸运的是，他挺过去了。 后面他一直给我们念叨他没死的原因是， 他年轻的时候修自行车，看到几个计生办的把一个大肚子妇女往三轮车上拉,要把别人带去引产。 他拿着手上的工具，就把那几个人拦着说：“别人这么大的肚子，你们欺负孤儿寡母的，这是造孽啊，要遭报应的。今天你们就别想把她带走。” 那几个工作人员可能看着我爸一身脏兮兮的衣服，又一副二杆子的样子，就撒手走了。 这也算是救了一个生命。 我爸出院后就反复念叨说他没死，就是当年救了这个人。 我也不知道是否有因果报应，但很多事总是很玄学，命运之中自有安排。 但行好事，莫问前程。 ","date":"2022-09-01","objectID":"/posts/20220901222137-%E9%99%8C%E7%94%9F%E4%BA%BA%E8%AE%A9%E6%88%91%E4%B9%B0%E9%A5%AD/:0:0","tags":["杂文"],"title":"陌生人让我买饭","uri":"/posts/20220901222137-%E9%99%8C%E7%94%9F%E4%BA%BA%E8%AE%A9%E6%88%91%E4%B9%B0%E9%A5%AD/"},{"categories":["工作"],"content":"平时我用的 arcolinux 系统,但有时候也有不得不开 windows 系统的时候. 比如,填工时的时候需要vpn. 所以,之前我是用 virtualbox 装了个 win10 的虚拟机,用的微软官方的开发者版本. 不过不知道什么原因,过几十分钟就会自动关机. 因为平时只是填下工时,所以影响不大,就没有管它. 但是,最近要帮别人写个 VBA 的工具,这就只有在 windows 里面进行了,所以还得重新找个干净的镜像装下. 我之前一直以为微软官方的系统,需要激活什么的,今天直接在官方网站下载了 win10 家庭版的镜像, 用我平时的微软账号登录就完整了,居然不用激活. 原来,这么简单,微软也是允许我白嫖的.也不用担心网上找的镜像安装一堆乱七遭八的东西. 官网下载地址: https://www.microsoft.com/zh-cn/software-download/windows10ISO 终于解决了我虚拟机中 win10 系统自动关机的问题! ","date":"2022-08-31","objectID":"/posts/20220831232615-%E5%B9%B2%E5%87%80%E7%9A%84windows10%E9%95%9C%E5%83%8F/:0:0","tags":["效率"],"title":"干净的windows10镜像","uri":"/posts/20220831232615-%E5%B9%B2%E5%87%80%E7%9A%84windows10%E9%95%9C%E5%83%8F/"},{"categories":["生活"],"content":"逐梦 壹 梦，是模糊的、虚幻的 你看不清它的样子 只能跟着它的影子 一路狂奔 ","date":"2022-08-27","objectID":"/posts/20220827231902-%E9%80%90%E6%A2%A6_%E5%A3%B9/:1:0","tags":["逆行的狗"],"title":"逐梦 壹","uri":"/posts/20220827231902-%E9%80%90%E6%A2%A6_%E5%A3%B9/"},{"categories":["生活"],"content":"楔子 傍晚，答完最后的考题，提前在电脑上点击了确认提交的按钮。 我兴奋地走出注册会计师的考场， 长舒一口气，终于结束了两天 CPA 的6门考试。 门口熙熙攘攘的人群，我像小学生一样蹦蹦跳跳地跑向在门口等我的大学同学龙哥。 他和他媳妇凤姐等着为我庆祝重要的考试。 成都，满是自由的空气，我感觉到前所未有的轻松。 “考得怎么样？”龙哥问。 “应该还可以。” 简单几句话后，龙哥开着车带着我去撸串了。 就着酒，向龙哥讲述着我这几年的辛苦生活， 感受着这自由的一切，满怀对未来的憧憬。 ","date":"2022-08-27","objectID":"/posts/20220827231902-%E9%80%90%E6%A2%A6_%E5%A3%B9/:1:1","tags":["逆行的狗"],"title":"逐梦 壹","uri":"/posts/20220827231902-%E9%80%90%E6%A2%A6_%E5%A3%B9/"},{"categories":["生活"],"content":"缘起 对于我来讲，梦的起点，即是CPA 也是整篇故事的开头。 它成了我对未来所有希望的载体， 虽然，考它的原因只是因为这是我唯二能报名的考试， 但，它就是波涛汹涌的大海中的一片绿叶， 托着我脑海中整个海市蜃楼。 回忆过去的一年， 随着军号， 6 点半起床， 每天看书到晚上 12 点。 偶尔也去菜地，锄锄地， 偶尔也去跑个五公里，出出汗。 CPA就是我的全部， 是我改变命运的机会， 是向反对我的父母的证明， 我相信在哪里我都可以混得很好， 我可以吃苦，我也拥有长期训练出来的“智力”， 而我需要的只是一个机会， 以及给我证明的时间。 和龙哥干完最后一杯酒， 我仿佛看到几年前我们一起训练、一起学习的情景， 入肚的酒气和回忆， 化为内心无尽的信心和勇气。 我来了， 属于我的自由， 属于我的未来！ ","date":"2022-08-27","objectID":"/posts/20220827231902-%E9%80%90%E6%A2%A6_%E5%A3%B9/:1:2","tags":["逆行的狗"],"title":"逐梦 壹","uri":"/posts/20220827231902-%E9%80%90%E6%A2%A6_%E5%A3%B9/"},{"categories":["生活"],"content":"逐梦 贰 走，干审计！ 一次高中同学聚会，一位女同学在信永中和会计师事务所成都分所工作，我给她说我也去考了 CPA ，已经过了三门了，打算以后去事务所工作，你们平时工作怎么样？ 她大概给我讲了些，说平时工作比较辛苦，出差比较多。 我想这辛苦能有多辛苦，总比白加黑，5+2好吧。 “事务所待遇怎么样？”我问。 “她说，你想挣多少？”，她说。 “干个两三年，有 5000 块不？”我小心翼翼地问。 她笑了笑，“那肯定是有的。” “好，那我就去事务所试试。”,心里暗自下了决定。 ","date":"2022-08-27","objectID":"/posts/20220827231902-%E9%80%90%E6%A2%A6_%E5%A3%B9/:2:0","tags":["逆行的狗"],"title":"逐梦 壹","uri":"/posts/20220827231902-%E9%80%90%E6%A2%A6_%E5%A3%B9/"},{"categories":["生活"],"content":"碰壁 2016年 4 月，我就回到了家。 向同学咨询了下，他们要年底才招人。 我想了想，反正还有剩下三门考试要考，就等到下半年去应聘，正好也可以准备下考试。 虽然媳妇没有上班，涵涵才 1 岁，肚子里也有了悦悦， 但这段时间单位还是继续发工资，所以也没有什么压力，自己每天就陪陪家人，复习考试。 大概到了 9 月份，一边准备着考试，一边开始投简历了。 为了保险起见，我百度了下会计师事务所的排名，分别到他们的官网都或者邮箱都投递了简历。 但都石沉大海。 当时我投递的简历就长这样： 我也实在找不到与工作职位相符的经历， 我总不可能写熟练操作山地步兵武器： 95 式自动步枪， 120 火箭筒， 82 毫米无后坐力炮， 100 毫米迫击炮，高射机枪…….吧。 别人肯定会想，“哥，你是来干审计的，还是来砸场子的？” 连写的“单位相关财务工作”也只是和我们司务长经常聊天，硬扯的。 虽然写的熟练运用 office 办公软件，其实连 Excel 都还没有用过。 等了几天，实在等不下去了，怎么办？ 只能发扬“没有条件也要创造条件”的优良传统了。 总体策略就是线下+线上的模式。 线下 我拉出四川排名前 10 的事务所办公地址，跑到成都待了两天，直接到公司前台去投简历。 什么立信、大华、华信全跑了，一般前台收了简历就告诉我后面有招聘的时候会通知我，然后就没有然后了。 只有一个前台老师，年纪比较大了，忘记哪个所了，让我等一下，很负责任地跑去他们领导那里问了下，然后告诉我最近他们不招人。 一次、两次，信心还是有所动摇了，不知道自己找不找得到工作。 线上 由于我认识的人也只有一个前面说的高中同学在事务所，也没有谁能帮忙介绍下。 我就跑到信永的贴吧去，看有没有了解的人指条路： 当时翻贴吧，看到最多的就是这位“不倒的斯嘉莉”，给大家回复招聘的邮箱，我一直在猜想应该是位 HR ，也不知道我猜得对不对。 当然，这也没有什么用，但好在看到同样一批求职的人在问，心里稍微感觉好点。 然后我又加了很多 QQ 群，看看有没有朋友能帮忙介绍的。 当时有个深圳的以前天职的大哥,很热心，帮我介绍给了成都这边他认识的领导。 屁颠屁颠地还跑去参加了天职在某个高校的校招的宣讲会，让我到年底的时候等他们通知。 当时很感谢这位大哥，他后面回成都了，约了几次吃饭，都没约成功，没有当面感谢他。 总之，这段时间都没有任何结果，只能老老实实看书了。 ","date":"2022-08-27","objectID":"/posts/20220827231902-%E9%80%90%E6%A2%A6_%E5%A3%B9/:2:1","tags":["逆行的狗"],"title":"逐梦 壹","uri":"/posts/20220827231902-%E9%80%90%E6%A2%A6_%E5%A3%B9/"},{"categories":["生活"],"content":"柳暗花明 大概是考完注会后，终于收到信永的笔试通知了。 当时高兴坏了，总算看到了一丝希望。 接下来，很顺利地通过笔试。 后面是面试， 还记得是人力蒋总、汪经理、夏经理面试我， 开始让我自我介绍，简短介绍了下后， 就是问专业问题， 汪经理问：“审计货币资金要执行哪些审计程序。” 当时我飞速思考了三秒，最多就是三秒。 我发现我都忘记完了，因为会计这门是去年考过的。 我赶紧回答，“不知道。” 这时，汪经理笑了笑说：“哦，你应该是忘记了，后面真正工作了和实务结合起来就印象深刻了。” 结果，居然就没有再问我专业问题了，反而对我之前的工作比较感兴趣。 然后，就开始聊之前的生活，说着说着三位领导都不停在笑。 整个面试就在轻松的氛围下结束了。 出来，我还问了一起面试的朋友，他们被不停地问各种专业问题，我感觉自己运气太好了。 接着就是合伙人面试，当时是大罗总面试的我。 走进他办公室，他摘下眼镜，看着我的简历，非常儒雅的气质。 “我们这刚开始工资比较低，你的期望工资是多少？”罗总问。 “ 2000 ”，我说。 他突然忍不住地笑了笑说：“ 2000 倒不至于。” 不过，当时我就是想学东西，只要能管吃住，不给钱都愿意干。 罗总说：“给你两年的时间，一年 20 万不成问题。” 虽然后面自己干得并不好，但当时他的话让我对未来还是充满了期望。 走出他办公室，感觉稳了，心里憧憬着能成为一名注册会计师，能有一技之长，能混口饭吃。 大概 1 个月后，我收到了录取通知，凭着自己努力终于找到自己想要的工作了。 走，干审计！ ","date":"2022-08-27","objectID":"/posts/20220827231902-%E9%80%90%E6%A2%A6_%E5%A3%B9/:2:2","tags":["逆行的狗"],"title":"逐梦 壹","uri":"/posts/20220827231902-%E9%80%90%E6%A2%A6_%E5%A3%B9/"},{"categories":["生活"],"content":"下完班，一行四人坐地铁回酒店。 其实酒店并不远，坐一站地铁就可以到，但地铁里走的时间远远超过了坐地铁的时间。 今天的广州下着小雨，出站后我们在人行道等着红绿灯。 突然，我看着小林带着一个外国小哥走到梅总的旁边， 小哥让梅总帮忙接听下电话，给滴滴司机说下他在哪里。 开始我还以为小哥说的粤语，听不懂。 梅总帮他把订单取消了，然后给他指了路。 全程，我就听到梅总最后说了个Of course 中间我问小林，为什么你自己不给小哥说，要让梅总去？ 小林说：“我英语不好。” 我说：“你这个英语是可以的，指个路没问题。” 她说：“我是有家室的人。” 我看了看小哥， 180 几，高高瘦瘦，一幅清秀的样子。 “你怕是想得有点多哦，别人只是问个路，你还来个I hava family” 翻了一个大大的白眼给她。 ","date":"2022-08-25","objectID":"/posts/20220825232249-%E7%BB%99%E8%80%81%E5%A4%96%E6%8C%87%E8%B7%AF/:0:0","tags":["杂文"],"title":"给老外指路","uri":"/posts/20220825232249-%E7%BB%99%E8%80%81%E5%A4%96%E6%8C%87%E8%B7%AF/"},{"categories":["生活"],"content":"时间一天一天过去， 它的离去甚至都不曾通知你， 挤在早高峰的地铁， 拘谨的空间中也无人认识你， 每天做着一件又一件重复的事情， 迎着朝霞，送走夕阳， 走过无数个城市， 当夜晚来临， 蜗居在廉价酒店， 吃着一份外卖， 这又是未曾通知且不曾期待的一天。 ","date":"2022-08-22","objectID":"/posts/20220822234714-%E6%97%A0%E9%A2%98_2022_08_22/:0:0","tags":["杂文"],"title":"无题 2022-08-22","uri":"/posts/20220822234714-%E6%97%A0%E9%A2%98_2022_08_22/"},{"categories":["工作"],"content":"“数据是 21 世纪的石油，而分析则是内燃机。” 如果说数据是石油，其本身是无价值的，只有对数据深度挖掘，才能为企业业务增长提供新的引擎，形成真正的数据资产。 近年来，随着信息技术飞速的发展，企业信息化建设已由类似于 ERP 等行业属性相对较强的信息系统建设转向信息系统之上的数据管理与业务应用建设，如建设适应企业业务发展的数据中台、业务中台等新型 IT 架构。通过建设敏捷高效可复用的支撑平台，为业务数字化创新提供高效数据和服务支撑。 IT审计执行的信息系统一般控制、应用控制测试是对企业信息科技领域管控的评价，仍然是对信息系统基础设施及建立其上的业务流程的控制测试。面对企业业务开展所产生的海量数据，其勾勒出了企业经营活动真实画像，数据核查工作在应对舞弊、异常检测方面显得越来越重要。 ","date":"2022-08-14","objectID":"/posts/20220814214453-it%E5%AE%A1%E8%AE%A1%E4%B9%8B%E7%8B%AC%E7%AB%8B%E6%95%B0%E6%8D%AE%E6%A0%B8%E6%9F%A5/:0:0","tags":["IT审计"],"title":"IT审计之独立数据核查","uri":"/posts/20220814214453-it%E5%AE%A1%E8%AE%A1%E4%B9%8B%E7%8B%AC%E7%AB%8B%E6%95%B0%E6%8D%AE%E6%A0%B8%E6%9F%A5/"},{"categories":["工作"],"content":"数据核查的特点 ","date":"2022-08-14","objectID":"/posts/20220814214453-it%E5%AE%A1%E8%AE%A1%E4%B9%8B%E7%8B%AC%E7%AB%8B%E6%95%B0%E6%8D%AE%E6%A0%B8%E6%9F%A5/:1:0","tags":["IT审计"],"title":"IT审计之独立数据核查","uri":"/posts/20220814214453-it%E5%AE%A1%E8%AE%A1%E4%B9%8B%E7%8B%AC%E7%AB%8B%E6%95%B0%E6%8D%AE%E6%A0%B8%E6%9F%A5/"},{"categories":["工作"],"content":"由抽样审计转变为全量审计 IT审计的数据核查大多时候是为财务审计服务的。受限于技术手段，财务审计在进行数据核查时，往往是抽样审计。但面对类似电商、游戏等这样的互联网企业所产生的海量销售订单，抽样检查多少个合适呢？ 100 个、 1000 个还是 10000 个才合适呢？ 借助于 SQL 、ClickHouse等大数据分析技术，我们可以对上亿行的数据量进行全量核查，全量分析。 例如，对于大型集团企业，审计在执行银行流水与财务序时账核对时一般仅对大额流水进行检查，并且会耗用大量人力和时间。如果企业开通了银企直联，银行流水与序时账一般会有关联字段，我们可以利用 SQL 进行全量双向核对；如果企业未开通银企直联，或没有关联字段，我们仍然可以利用 Python 按照人工核对的逻辑编写代码，实现网银流水与序时账的全量核对，不再区分金额大小。 再如，对于生产工艺复杂的制造型企业，其工序可能多达十几步或者几十步，审计难以对生产成本进行重新计算以验证存货计量的准确性。但对于计算机来说，这些工序的成本分摊逻辑是一致的，借助于 Python ，我们也是可以实现对所有工单的生产成本的归集和分摊进行全量重新计算。对于这些收入、成本计算逻辑复杂的企业，利用 Python 这样的编程语言，复现系统的计算逻辑，能取得很好的数据核查效果。 ","date":"2022-08-14","objectID":"/posts/20220814214453-it%E5%AE%A1%E8%AE%A1%E4%B9%8B%E7%8B%AC%E7%AB%8B%E6%95%B0%E6%8D%AE%E6%A0%B8%E6%9F%A5/:1:1","tags":["IT审计"],"title":"IT审计之独立数据核查","uri":"/posts/20220814214453-it%E5%AE%A1%E8%AE%A1%E4%B9%8B%E7%8B%AC%E7%AB%8B%E6%95%B0%E6%8D%AE%E6%A0%B8%E6%9F%A5/"},{"categories":["工作"],"content":"数据分析的颗粒度更小 财务审计在执行分析性程序时，往往使用的数据颗粒度很大，如按年或月的汇总金额去进行波动分析。数据的颗粒度就像一张照片的像素，当颗粒度很大时，照片所呈现的信息将会失真，很多细节信息将难以发现。而 IT 审计进行数据核查时一般按照最小颗粒度的数据进行多维度分析，如订单、小时、分钟、渠道等，这是异常检测的基础。 如上图所示，当我们将订单按照一天 24 小时划分为 24 个区间，分别统计每个小时区间的订单金额时，能发现 2019 年0点和 2020 年8点的订单金额显示异常。这就是将分析的颗粒度变小的好处，能还原更多细节信息。 如上图所示，我们甚至可以按分钟去统计次数，去检测是否存在利用机器人等技术短时间大量刷单的情况。 如上图所示，我们可以以订单的颗粒度去分析单价的稳定性，对于发散的或者偏离正态分布的数据检测出来，进一步去核查异常数据产生的原因。 ","date":"2022-08-14","objectID":"/posts/20220814214453-it%E5%AE%A1%E8%AE%A1%E4%B9%8B%E7%8B%AC%E7%AB%8B%E6%95%B0%E6%8D%AE%E6%A0%B8%E6%9F%A5/:1:2","tags":["IT审计"],"title":"IT审计之独立数据核查","uri":"/posts/20220814214453-it%E5%AE%A1%E8%AE%A1%E4%B9%8B%E7%8B%AC%E7%AB%8B%E6%95%B0%E6%8D%AE%E6%A0%B8%E6%9F%A5/"},{"categories":["工作"],"content":"数据核查对象多样化 在大数据时代，几乎所有的人、事、物都能够数据化，进而被分析。 我们将数据核查的对象可以划分为结构化数据和非结构化数据，结构化数据即为能够用数据或者统一结构加以表示的信息，如信息系统中的各种报表。而非结构化数据，就是一些无法用数字或统一的结构表示，如合同、发票、邮件、网页等。 IT审计数据核查的对象不再局限于财务账、业务报表等结构化数据，借助于新的 IT 技术，我们可以将数据核查的范围延伸到非结构化的数据。 如上图所示，审计一家航运企业，以前我们只能通过手工抽样查询船舶定位位置与业务系统中的班期表核对，验证航行的真实性。现在我们可以利用 Python 爬虫技术，批量解析网页中船舶经纬度信息和出发地、目的地，全量核对。 如上图所示，借助于 OCR 技术，我们可以将非结构化的发票图片文件识别成结构化数据，从而实现发票的全量核查。 当然，我们还可以将数据划分为财务数据、业务数据、日志数据三种类型，财务审计在做数据核查时更多核查的是财务数据。而 IT 审计核查的对象会延伸到业务数据和日志数据。 从企业舞弊造假成本来说，=财务数据\u003c业务数据\u003c日志数据=，我们更倾向于通过日志数据、业务数据的核查来验证财务数据的真实性、准确性、完整性。 如上图所示，审计一家制造型企业，我们获取了公司 ERP 系统的操作日志，按天对作业频率进行分析，检查作业频率异常偏高的情况，以排查是否存在舞弊迹象。由于操作日志真实反映了人员的所有系统操作，其数据的可信度相比财务数据更高，能更好地应对舞弊欺诈行为。 总之， IT 审计的数据核查的来源具有多样化的特点。 ","date":"2022-08-14","objectID":"/posts/20220814214453-it%E5%AE%A1%E8%AE%A1%E4%B9%8B%E7%8B%AC%E7%AB%8B%E6%95%B0%E6%8D%AE%E6%A0%B8%E6%9F%A5/:1:3","tags":["IT审计"],"title":"IT审计之独立数据核查","uri":"/posts/20220814214453-it%E5%AE%A1%E8%AE%A1%E4%B9%8B%E7%8B%AC%E7%AB%8B%E6%95%B0%E6%8D%AE%E6%A0%B8%E6%9F%A5/"},{"categories":["工作"],"content":"数据核查的方法 IT审计数据核查需要将 IT 技术与审计方法相结合。在信息技术飞速发展的浪潮下，我们需要拥抱新技术、新思想、新变革，同时对我们的审计思路、审计模式进行创新。 审计一家游戏企业，玩家通过充值获得游戏币，游戏币可以在商城中购买游戏道具，购买的道具可以自己使用也可以赠送他人。在审计过程中，我们发现一些账号的充值金额异常大，我们利用 Neo4j 图数据库将所有道具的赠送关系进行网络分析： 我们发现消费金额前 25 名的异常账号，其中就有 19 个账号相互之间有赠送行为，形成了网络。通过进一步审计程序，我们发现其中一些账号是淘宝店家，他们通过从价格更低的渠道充值后，以\"赠送\"的方式卖给游戏玩家，因此其充值金额较大，且存在大量赠送行为。 利用 Neo4j 、Gephi、 NetworkX 等工具，我们可以轻松地进行复杂网络关系分析，挖掘出数据背后的关联关系，这是新技术为我们数据核查带来了新的手段、新的方法。 但 IT 技术仅仅是一种工具，我们在做数据核查时，更多的需要和我们的审计方法论结合、和生活常识结合、和行业经验结合、和统计学知识结合。 例如， IPO 的电商企业的数据核查要求我们 IT 审计对是否存在刷单行为进行分析，从数据分析的工具上讲，我们使用 SQL 就能进行分析，但我们从什么维度去分析能发现是否存在刷单行为呢？ 其实我觉得更好的方法是从生活常识入手，从行业经验入手，我们可以去找参与过刷单朋友，询问他们是如何刷单的，了解其特点，然后再设计数据分析的维度。 例如，我向朋友了解到有的刷单方法是找普通的人去购买，发货的时候只发一个空盒子或者价值较小的重量较轻的东西，完成订单后，再通过微信红包的方式返钱给他。 针对这种刷单方式，我们就可以利用“发货重量轻“的特征去筛选出这些异常订单。我们可以根据商品 SKU 的重量信息，计算出系统里一个订单的重量，再去和物流公司发货时称重重量核对，从而检测出重量偏离较大的异常订单。 当然，这只是一个举例，通过这个例子，我想说明在 IT 审计数据核查过程中分析的思路很多时候比技术手段更加重要。 我们正处在信息爆炸、技术变革的时代，我们应该学习新的 IT 技术，积极探索新的审计方法、审计思路，通过深入挖掘数据背后的价值，提高我们的审计质量、审计效率。 ","date":"2022-08-14","objectID":"/posts/20220814214453-it%E5%AE%A1%E8%AE%A1%E4%B9%8B%E7%8B%AC%E7%AB%8B%E6%95%B0%E6%8D%AE%E6%A0%B8%E6%9F%A5/:2:0","tags":["IT审计"],"title":"IT审计之独立数据核查","uri":"/posts/20220814214453-it%E5%AE%A1%E8%AE%A1%E4%B9%8B%E7%8B%AC%E7%AB%8B%E6%95%B0%E6%8D%AE%E6%A0%B8%E6%9F%A5/"},{"categories":["工作"],"content":"下午被安排给新员工培训 SQL ，带着大家从安装数据库到一些简单的 SQL 语句，讲了 3 个小时。 其实如果大家平时项目上遇不到这种大数据量的情景的话，基本上没有太大的用。但整个分所还是有不少的这样的项目。 唯一的作用感觉就是让他们有一个亲身处理 400 多万行数据的感觉，将来如果遇到了知道学习什么。 其实做一项系统工程，需要处理好三个维度：时间维、逻辑维、知识维。 其中知识维就是要么你知道用什么知识，要么你能用拥有这些知识的人。无论打工者还是老板概莫能外。 对于学习知识的我们来说，其实知识本身并不重要，而习得知识的能力很重要。 你如果留心周围的人会发现，一般厉害的人不只是一方面厉害，更多情况下多方面厉害。一个掌握学习能力的人你随便丢他到陌生的领域，大概率他也会很厉害。 大部分人都停留在表面，觉得做一份工作，学一门知识，自己就是专家了，忽视了背后的基础技能的重要性。其实呢，无论什么工作都有可能被淘汰，任何一门知识都都会变得无用。你平时所做的努力，都在积累背后的某一种能力。 而最能让你有碗饭吃就是这些基础能力。 就像我的领导，我觉得她有一种能力就是说服人的能力，同样一句话，从她嘴里说出来，就能让人信服。有这样的能力，去哪个公司不能当个中层领导？ 就像几年前我加入过\"千熊会员\"，一个四大出来做知识付费的审计师，我发现他有个能力，就是能把一个方法、流程包装成非常吸引人的\"产品\"，靠着这个\"包装\"和总结的能力确实能把知识卖出去。 而我评估自己的能力就是数理逻辑能力，只要是有一定门槛，依赖数理逻辑的专业，我有信心能快速上手。 人的延展性是非常强的，不只一种可能。如果有一天这个行业都没了，总得吃饭吧，我可能为了生计就得去跑外卖或者开滴滴。 如果我是去跑外卖，在熟悉情况后，我也一定会去计算和统计哪种路径、时间、方式去跑能时效比最高。 如果我是去跑滴滴，在熟悉情况后，我也一定会去计算哪个时间段、哪个区域去跑最挣钱。 而我还是得用我最擅长的技能。我还会利用以前在部队宣传股学到的技能，去做自媒体，讲我们外卖小哥的故事。 上高中时，非常喜欢看的美剧《 Heros 》(超能英雄)，我最喜欢的一个角色就是 Peter ，他的超能力就是可以学习其他有超能力的人的超能力，简直太 Bug 了。 还有一个反派角色是 Sylar ，他的超能力是洞悉事物的本质，但是需要挖开别人的脑子，过于残忍，不太喜欢。 最后，想说什么呢？ 多学点别人带不走的东西，时刻保持在哪里都可以吃饭的能力。 ","date":"2022-08-14","objectID":"/posts/20220814214721-%E8%B6%85%E8%83%BD%E8%8B%B1%E9%9B%84/:0:0","tags":["感悟"],"title":"超能英雄","uri":"/posts/20220814214721-%E8%B6%85%E8%83%BD%E8%8B%B1%E9%9B%84/"},{"categories":["工作"],"content":"前几天一个网友发了一个传销组织的数据，他想求每个层级的人数。 Figure 1: 图1 这两天正好学了networkx，我们来看如果用网络分析解决这个问题。 Figure 2: 图2 这是整个推荐关系的可视化网络图。其中正红色的点为根节点。 下面我们一步一步来解决。 ","date":"2022-08-14","objectID":"/posts/20220814001303-%E4%BC%A0%E9%94%80%E7%BB%84%E7%BB%87%E5%B1%82%E7%BA%A7%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/:0:0","tags":["网络分析","python","IT审计"],"title":"传销组织层级结构分析","uri":"/posts/20220814001303-%E4%BC%A0%E9%94%80%E7%BB%84%E7%BB%87%E5%B1%82%E7%BA%A7%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"读取数据并创建网络 我们使用pandas读取 excel 数据，并用nx.from_pandas_edgelist(df,source,target,edge_attr,create_using)函数来创建一个图=G=。 这个函数是根据边数据来创建图，其中： source:df中表示边起始的列名（推荐人）。 target:df中表示边目标的列名（被推荐人）。 edge\\_attr:df中表示边属性的列名（如权重，颜色，大小等）。 create\\_using:表示创建什么类型的图，无向图，有向图等。这里我们使用有向图=DiGraph=,因为推荐关系是有方向的。 import networkx as nx import pandas as pd # 读取数据创建图 df = pd.read_excel('~/传销原始数据.xlsx') df = df.loc[:, ['推荐人ID', '被推荐人ID']] df.columns = ['source', 'target'] G = nx.from_pandas_edgelist(df, 'source', 'target', create_using=nx.DiGraph()) 当然这样创建的图=G=只是一个类的实例化，并不一张真正可视化的图。如果你想可视化它，可以使用=pyvis=包进行，它可以生成一个可交互的网络图。 from pyvis.network import Network nt = Network('650px', '1250px', directed=True) nt.from_nx(G) nt.show('test.html') 这将会生成如图 2 所示的网络图。 ","date":"2022-08-14","objectID":"/posts/20220814001303-%E4%BC%A0%E9%94%80%E7%BB%84%E7%BB%87%E5%B1%82%E7%BA%A7%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/:1:0","tags":["网络分析","python","IT审计"],"title":"传销组织层级结构分析","uri":"/posts/20220814001303-%E4%BC%A0%E9%94%80%E7%BB%84%E7%BB%87%E5%B1%82%E7%BA%A7%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"找到根节点 考虑到这个网络是一个传销组织，那么正常情况下应该是有个唯一的根节点，整个组织类似树状结构。 我们先得找到这个根节点，怎么找呢？ 这就需要先引一个图论中的概念度，度的意思就是一个节点的相邻节点的数量。 Figure 3: 图3 如图 3 所示，如果不考虑边的方向，那点节点 1 有4个相邻节点（有边相连），那么节点 1 的度就是 4 。 即degree=4。 但是这是一个有向图，就会分成in_degree和 out_degree 两种度。 那么我们要找到根结点，只需要去找in_degree==0的节点就是根节点，同理out_degree==0的节点为末级节点。 因此，我们写代码： top_nodes = [n for n, d in G.in_degree() if d == 0] print('root node:', top_nodes) 可以计算出根结点为： [0] Figure 4: 图4 如图 4 所示，我们可以找到图中的根节点，它就是这个网络的头目。 ","date":"2022-08-14","objectID":"/posts/20220814001303-%E4%BC%A0%E9%94%80%E7%BB%84%E7%BB%87%E5%B1%82%E7%BA%A7%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/:2:0","tags":["网络分析","python","IT审计"],"title":"传销组织层级结构分析","uri":"/posts/20220814001303-%E4%BC%A0%E9%94%80%E7%BB%84%E7%BB%87%E5%B1%82%E7%BA%A7%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"计算网络层级关系 为了计算网络层级关系，这里我们需要引入一个概念*距离*，也就是两个节点之间的最短路径长度。 Figure 5: 图5 对于节点 1 到节点 4 的距离为 3 ，因为两条路径可以从节点 1 到达节点 3 ： [1, 2, 3, 4] [1, 2, 5, 4] 这两条路径最短的距离就是 3 。 在networkx库中有个函数nx.shortest_path_length(G,source,target)可以求出节点source和 target 之间的距离。 如果省略target参数，就可以求出source下所有节点与source之间的距离。 因此，我们只需要用=nx.shortest_path_length(G, 0)=就可以求出=根节点0=下的所有节点的距离，也就是*网络层级*。 level = nx.shortest_path_length(G, 0) nx.set_node_attributes(G, level, 'level') level 的值是下面这样的=节点:距离=的字典，可以看到一共 32 个层级。 {0:0,2576:1,..., 5659: 32} 我们求出了所有子节点到根节点的距离level列表，用set_node_attributes()函数给每个节点添加一个层级属性。 下面，我们只需要将level列表，统计出 1-32 层级中分别有哪些节点即可。 # 显示层级 data = {} for n, l in level.items(): if l in data.keys(): nodes = data[l] nodes.append(n) data[l] = nodes else: data[l] = [n] # 打印前10层节点 for l, n in data.items(): if l \u003c 10: print(l, n) 这里我们展示前 10 层级对应的哪些节点： 当然，我们将上面print(l,n)替换成print(l,len(n))，就可以看到每一层级对应的节点数量。 Figure 6: 图6 ","date":"2022-08-14","objectID":"/posts/20220814001303-%E4%BC%A0%E9%94%80%E7%BB%84%E7%BB%87%E5%B1%82%E7%BA%A7%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/:3:0","tags":["网络分析","python","IT审计"],"title":"传销组织层级结构分析","uri":"/posts/20220814001303-%E4%BC%A0%E9%94%80%E7%BB%84%E7%BB%87%E5%B1%82%E7%BA%A7%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"下线前10的节点 我们知道=度=表示了相邻节点数量，那么度值最大的 10 个，也就是下线数最大的 10 个。 degrees = G.out_degree() top_degree_nodes = sorted(degrees, key=lambda x: x[1], reverse=True)[:10] print(top_degree_nodes) 计算结果： [(2828, 264), (0, 115), (2700, 86), (2833, 65), (2999, 55), (2560, 53), (2574, 42), (3021, 37), (2651, 36), (2834, 31)] 可以看到下线最多的节点是节点2828有 264 个下线，第二是根节点0有 115 个下线。 Figure 7: 图7 这些节点表现在图中就是像水母一样的中心节点。 ","date":"2022-08-14","objectID":"/posts/20220814001303-%E4%BC%A0%E9%94%80%E7%BB%84%E7%BB%87%E5%B1%82%E7%BA%A7%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/:4:0","tags":["网络分析","python","IT审计"],"title":"传销组织层级结构分析","uri":"/posts/20220814001303-%E4%BC%A0%E9%94%80%E7%BB%84%E7%BB%87%E5%B1%82%E7%BA%A7%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"最大介绍top10 除了通过=度=来衡量一个节点是否为关键节点外，我们还可以通过介数来衡量。 如图 8 所示，根节点 0 传递到节点1,节点2,节点3…. 其中节点2,节点 5 的度非常小，分别为 2 和1,但是如果少了他们的话，后面整个网络就断了。 介数就是表示网络中群体与群体之间的中间人角色，现实生活中如果度数大的是黄牛，那么这个介数的中间人就是给黄牛提供渠道的关键人物。 Figure 8: 图8 我们在图中将前 10 大中介点标记成了绿色，方便查看。 ","date":"2022-08-14","objectID":"/posts/20220814001303-%E4%BC%A0%E9%94%80%E7%BB%84%E7%BB%87%E5%B1%82%E7%BA%A7%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/:5:0","tags":["网络分析","python","IT审计"],"title":"传销组织层级结构分析","uri":"/posts/20220814001303-%E4%BC%A0%E9%94%80%E7%BB%84%E7%BB%87%E5%B1%82%E7%BA%A7%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"完整代码 以上分析的完整代码： import networkx as nx from pyvis.network import Network import pandas as pd # 读取数据创建图 df = pd.read_excel('~/传销原始数据.xlsx') df = df.loc[:, ['推荐人ID', '被推荐人ID']] df.columns = ['source', 'target'] G = nx.from_pandas_edgelist(df, 'source', 'target', create_using=nx.DiGraph()) # 求根节点 top_nodes = [n for n, d in G.in_degree() if d == 0] print('root node:', top_nodes) # 节点层级 level = nx.shortest_path_length(G, 0) nx.set_node_attributes(G, level, 'level') # 显示层级 data = {} for n, l in level.items(): if l in data.keys(): nodes = data[l] nodes.append(n) data[l] = nodes else: data[l] = [n] # 打印前10层节点 for l, n in data.items(): if l \u003c 10: print(l, len(n)) # 打印前10大度节点 degrees = G.out_degree() top_degree_nodes = sorted(degrees, key=lambda x: x[1], reverse=True)[:10] print(top_degree_nodes) # 给节点添加属性 for node in G.nodes: G.nodes[node]['title'] = str(node) level = G.nodes[node]['level'] # 给节点添加大小属于 G.nodes[node]['value'] = 32 - level # 第一、二、三层节点添加颜色 if level == 0: G.nodes[node]['color'] = 'red' elif level == 1: G.nodes[node]['color'] = 'fuchsia' elif level == 2: G.nodes[node]['color'] = 'purple' # 中介点 center = nx.betweenness_centrality(G) center_tops = sorted(center.items(), key=lambda x: x[1], reverse=True)[:10] # 给前10大中介点添加颜色 for node in center_tops: G.nodes[node[0]]['color'] = 'teal' nx.write_gexf(G, 'test.gexf') nt = Network('650px', '1250px', directed=True) nt.from_nx(G) nt.show('test.html') ","date":"2022-08-14","objectID":"/posts/20220814001303-%E4%BC%A0%E9%94%80%E7%BB%84%E7%BB%87%E5%B1%82%E7%BA%A7%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/:6:0","tags":["网络分析","python","IT审计"],"title":"传销组织层级结构分析","uri":"/posts/20220814001303-%E4%BC%A0%E9%94%80%E7%BB%84%E7%BB%87%E5%B1%82%E7%BA%A7%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"结语 networkx是复杂网络分析的利器，搭配上可视化库 pyvis ，可以简单几行代码完成分析和可视化。 ","date":"2022-08-14","objectID":"/posts/20220814001303-%E4%BC%A0%E9%94%80%E7%BB%84%E7%BB%87%E5%B1%82%E7%BA%A7%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/:7:0","tags":["网络分析","python","IT审计"],"title":"传销组织层级结构分析","uri":"/posts/20220814001303-%E4%BC%A0%E9%94%80%E7%BB%84%E7%BB%87%E5%B1%82%E7%BA%A7%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/"},{"categories":["工作"],"content":"给一个公众号投了关于 IT 审计的文稿，需要一张作者照片。 但我发现之前没有拍稍微正式点的形象照，所以就一个人跑去照相馆拍了。 说实话，平时我都不拍照，我媳妇用手机给我拍也是抗拒的，每次都是一种不自然的状态。 就听到给我照相的小哥不停的说： “哎～，来微笑” “对，稍微笑一点” “哎～，来～，笑一下” “对，对～，很好，自然一点” “表情僵了，来，自然一点” 我都替小哥着急，想着赶紧拍完了事。 为了后面不再拍照，就一次性选了 9 张照片，花了 900 大洋，有点心疼。 如果有 IT 审计相关的业务咨询可以邮件联系: tujiabing81@163.com ","date":"2022-08-14","objectID":"/posts/20220814214405-%E7%8B%97%E5%93%A5%E5%8E%BB%E7%85%A7%E7%9B%B8%E9%A6%86/:0:0","tags":["杂文"],"title":"狗哥去照相馆","uri":"/posts/20220814214405-%E7%8B%97%E5%93%A5%E5%8E%BB%E7%85%A7%E7%9B%B8%E9%A6%86/"},{"categories":["效率"],"content":"有网友问，怎么批量修改文件最后的修改日期。 比如， excel 文件、 word 文件等。 当然我们先将电脑日期设置成以前的某个日期，然后一个一个打开文件后，修改下，再保存。这样可以完成日期的更换。 今天我们用 python 来实现文件修改日期的批量替换。 比如在=/home/nigo/tmp/test=文件夹下有一些文件，最后修改日期是=2022-07-19=。 我们只需要做两步： 循环获取该文件夹所有文件路径。 修改文件日期 我们先看修改文件日期： import os def change_file_date(path, atime, mtime): \"\"\"改变文件修改日期和访问日期\"\"\" info = os.stat(path) os.utime(path, (atime, mtime)) 我们只需要用os.utime函数就可以将文件的访问日期和修改日期分别改变为atime和 mtime （时间戳数字）。 完整代码如下： import os import datetime def change_file_date(path, atime, mtime): \"\"\"改变文件修改日期和访问日期\"\"\" info = os.stat(path) os.utime(path, (atime, mtime)) def get_file_list(dir, file_list): \"\"\"递归获取文件夹下所有的文件路径\"\"\" newdir = dir if os.path.isfile(dir): file_list.append(dir) elif os.path.isdir(dir): for s in os.listdir(dir): #如果需要忽略某些文件夹，使用以下代码 # if s == \"xxx\": # continue newdir=os.path.join(dir,s) get_file_list(newdir, file_list) return file_list if __name__ == \"__main__\": # 需要修改的文件所在的文件夹 modify_directory = '/home/nigo/tmp/test' # 需要设置成的修改时间：年,月,日,时,分,秒 modify_time = datetime.datetime(2022, 4, 5, 18, 20, 31) # 将时期转化为时间戳 mtime = datetime.datetime.timestamp(modify_time) # 获取指定文件夹下的所有文件路径 paths = get_file_list(modify_directory, []) # 循环所有文件 for path in paths: # 修改文件的访问时间和修改时间 change_file_date(path, mtime, mtime) 我们执行代码将/home/nigo/tmp/test文件夹下的所有文件修改日期改变为2022-04-05 18:20:31。 可以看到所有文件的修改日期已全部批量修改。 当然你会 VBA 的话，也可以使用 VBA 实现，只是用 Python 更快速一点。 ","date":"2022-08-14","objectID":"/posts/20220814214636-%E6%89%B9%E9%87%8F%E6%94%B9%E5%8F%98%E6%96%87%E4%BB%B6%E6%9C%80%E5%90%8E%E4%BF%AE%E6%94%B9%E6%97%B6%E9%97%B4/:0:0","tags":["python"],"title":"批量改变文件最后修改时间","uri":"/posts/20220814214636-%E6%89%B9%E9%87%8F%E6%94%B9%E5%8F%98%E6%96%87%E4%BB%B6%E6%9C%80%E5%90%8E%E4%BF%AE%E6%94%B9%E6%97%B6%E9%97%B4/"},{"categories":["效率"],"content":" 陈版主答疑文章使用的爬虫失效了，暂时没有更新，这周我抽时间更新下，再为大家每天推送。 昨天文章有朋友留言让分享下上交所警示函下载的工具， 虽然写这个代码不难，但还是可以和大家分享下思路。 ","date":"2022-08-14","objectID":"/posts/20220814220542-%E4%B8%8A%E4%BA%A4%E6%89%80%E8%AD%A6%E7%A4%BA%E5%87%BD%E6%89%B9%E9%87%8F%E4%B8%8B%E8%BD%BD/:0:0","tags":["python"],"title":"上交所警示函批量下载","uri":"/posts/20220814220542-%E4%B8%8A%E4%BA%A4%E6%89%80%E8%AD%A6%E7%A4%BA%E5%87%BD%E6%89%B9%E9%87%8F%E4%B8%8B%E8%BD%BD/"},{"categories":["效率"],"content":"任务拆解 当我们想做一个工具的时候，首先需要梳理出逻辑。 也就是先手工操作一遍，把一个大任务拆分成可执行的小任务。 ","date":"2022-08-14","objectID":"/posts/20220814220542-%E4%B8%8A%E4%BA%A4%E6%89%80%E8%AD%A6%E7%A4%BA%E5%87%BD%E6%89%B9%E9%87%8F%E4%B8%8B%E8%BD%BD/:1:0","tags":["python"],"title":"上交所警示函批量下载","uri":"/posts/20220814220542-%E4%B8%8A%E4%BA%A4%E6%89%80%E8%AD%A6%E7%A4%BA%E5%87%BD%E6%89%B9%E9%87%8F%E4%B8%8B%E8%BD%BD/"},{"categories":["效率"],"content":"大目标 比如，我们的目标是登录上交所网站，输入“警示函”关键字，点击查询， 点击一个列表页，将显示的 PDF 下载下来，然后复制其中的文字到我们保存的文件中。 这个流程有好几步，很多人刚开始学习的时候不太意识到这是一个大目标， 你直接对别人说：“哎，把最近几年上交所警示函内容帮我整理出来。” 别人是茫然的，不知道怎么做。 同样的，你自己也不知道，你可能只能在浏览器上搜索：“批量下载上交所警示函” 如果运气好，别人做过，可能会有现成的轮子，否则，你就又卡住了。 要知道，对于一个大目标我们是很难实际落地执行的。 ","date":"2022-08-14","objectID":"/posts/20220814220542-%E4%B8%8A%E4%BA%A4%E6%89%80%E8%AD%A6%E7%A4%BA%E5%87%BD%E6%89%B9%E9%87%8F%E4%B8%8B%E8%BD%BD/:1:1","tags":["python"],"title":"上交所警示函批量下载","uri":"/posts/20220814220542-%E4%B8%8A%E4%BA%A4%E6%89%80%E8%AD%A6%E7%A4%BA%E5%87%BD%E6%89%B9%E9%87%8F%E4%B8%8B%E8%BD%BD/"},{"categories":["效率"],"content":"小任务 那么,要想实现我们的大目标，最好的方法就是任务拆解。 获取网页信息（包括 PDF 下载链接) 下载 PDF 文件 解析 PDF 文件 保存数据 当我们能把任务进行拆解后，难度就自然极度下降了， 我们现在只需要针对这 4 个问题写函数完成。 我们以最简单的解析 PDF 文件为例， 啊？为什么这个是最简单的？因为之前在一篇文章中学过，用 pdfplumber 库解析 PDF 。 import pdfplumber def extract_pdf(path): \"\"\"提取pdf文字内容\"\"\" with pdfplumber.open(path) as pdf: pages = pdf.pages text = ''.join(page.extract_text() for page in pages) return text 你看 4 个问题，我们就解决了一个。简单吧？ ","date":"2022-08-14","objectID":"/posts/20220814220542-%E4%B8%8A%E4%BA%A4%E6%89%80%E8%AD%A6%E7%A4%BA%E5%87%BD%E6%89%B9%E9%87%8F%E4%B8%8B%E8%BD%BD/:1:2","tags":["python"],"title":"上交所警示函批量下载","uri":"/posts/20220814220542-%E4%B8%8A%E4%BA%A4%E6%89%80%E8%AD%A6%E7%A4%BA%E5%87%BD%E6%89%B9%E9%87%8F%E4%B8%8B%E8%BD%BD/"},{"categories":["效率"],"content":"周而复始 需要注意的是，上交所给的 PDF 绝大部分是文本的，一小部分的是扫描图片的。 这个代码只能解析文本的 PDF ，如果你想完全解决，那么我们又可以任务拆解的方法， 将3.解析PDF文件分解为： 3.1 解析文字类PDF 3.2 解析扫描类PDF 啊？扫描类的 PDF 文件我怎么解析呢？要么你在浏览器上搜索下有没有这个解决办法。 要么我们再进一步拆解，我们可以把扫描的 PDF 保存为一张张图片,再用 OCR 去识别图片： 3.2.1 PDF拆分成图片 3.2.2 OCR识别图片为文字 每一个如果不会，就去搜索解决，搜索没有直接答案的，就看能不能拆成更小的任务， 循环往复，直到找到解决问题的方法。 ","date":"2022-08-14","objectID":"/posts/20220814220542-%E4%B8%8A%E4%BA%A4%E6%89%80%E8%AD%A6%E7%A4%BA%E5%87%BD%E6%89%B9%E9%87%8F%E4%B8%8B%E8%BD%BD/:1:3","tags":["python"],"title":"上交所警示函批量下载","uri":"/posts/20220814220542-%E4%B8%8A%E4%BA%A4%E6%89%80%E8%AD%A6%E7%A4%BA%E5%87%BD%E6%89%B9%E9%87%8F%E4%B8%8B%E8%BD%BD/"},{"categories":["效率"],"content":"搜索问题及笔记记录 通过上面的步骤，我们能把一个复杂任务转换为简单任务。 这也是数学中的化归思想。 这些简单任务，有些我们可能已经会了，有些可能不会。 对于不会的，我们就需要去检索了，也就是问 度娘。 这个真就是熟能生巧了，查得多了，就有技巧了，基本小的问题你都能解决。 当你查到后，一定要把有价值的问题，记录到你的笔记中， 你看上次我们在“ python 提取关键审计事项”的文章中用到的pdfplumber， 今天又用上了。 查一次你可能会忘记，当你记录下来，下次遇到你就节约了检索的时间， 多遇到几次，你就彻底掌握了，这个就是知识习得的过程。 ","date":"2022-08-14","objectID":"/posts/20220814220542-%E4%B8%8A%E4%BA%A4%E6%89%80%E8%AD%A6%E7%A4%BA%E5%87%BD%E6%89%B9%E9%87%8F%E4%B8%8B%E8%BD%BD/:2:0","tags":["python"],"title":"上交所警示函批量下载","uri":"/posts/20220814220542-%E4%B8%8A%E4%BA%A4%E6%89%80%E8%AD%A6%E7%A4%BA%E5%87%BD%E6%89%B9%E9%87%8F%E4%B8%8B%E8%BD%BD/"},{"categories":["效率"],"content":"完整代码 其实代码并不重要，有需要的可以自己拿来练习、练习。 import pdfplumber import pandas as pd import requests from urllib.parse import urljoin,urlencode,quote import os import pymysql import time as ttime def extract_pdf(path): \"\"\"提取pdf文字内容\"\"\" with pdfplumber.open(path) as pdf: pages = pdf.pages text = ''.join(page.extract_text() for page in pages) return text def download_pdf(url,path,pdf_name): \"\"\"下载PDF文件\"\"\" file_path = os.path.join(path,pdf_name) if os.path.exists(file_path)==False: if os.path.exists(path)==False: os.makedirs(path) r=requests.get(url) with open(file_path,'wb') as f: f.write(r.content) def get_download_urls(keyword): \"\"\"获取列表信息及PDF下载链接\"\"\" page = 1 url = 'http://query.sse.com.cn/search/getSearchResult.do?search=qwjs\u0026jsonCallBack=\u0026searchword=T_L+CTITLE+T_E+T_L' + quote(keyword) +'+T_R+and+cchannelcode+T_E+T_L0T_D8311T_D8321T_D8348T_D8349T_D8365T_D8703T_D8828T_D8834T_D9856T_D9860T_D9862T_D9888T_D9889T_D9892T_D10004T_D10011T_D10743T_D12002T_D88888888T_RT_R\u0026orderby=-CRELEASETIME\u0026page=%s\u0026perpage=10\u0026_=1660204739688' % page header = { 'User-Agent':'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.5060.134 Safari/537.36 Edg/103.0.1264.71', 'Host':'query.sse.com.cn', 'Referer':'http://www.sse.com.cn/', } response = requests.get(url,headers=header) json_str = response.json() total_page = int(json_str['countPage']) infos = [] for page in range(total_page+1): ttime.sleep(4) # 暂停的秒数，避免频繁调用 print('获取第%s页信息，共%s页' % (page,total_page)) url = 'http://query.sse.com.cn/search/getSearchResult.do?search=qwjs\u0026jsonCallBack=\u0026searchword=T_L+CTITLE+T_E+T_L' + quote(keyword) +'+T_R+and+cchannelcode+T_E+T_L0T_D8311T_D8321T_D8348T_D8349T_D8365T_D8703T_D8828T_D8834T_D9856T_D9860T_D9862T_D9888T_D9889T_D9892T_D10004T_D10011T_D10743T_D12002T_D88888888T_RT_R\u0026orderby=-CRELEASETIME\u0026page=%s\u0026perpage=10\u0026_=1660204739688' % page response = requests.get(url,headers=header) json_str = response.json() for row in json_str['data']: title = row['CTITLE_TXT'] print(title) link = row['CURL'] url = urljoin(\"http://www.sse.com.cn/\",link) date = row['CRELEASETIME'] time = row['CRELEASETIME2'] file_type = row['MIMETYPE'] id = row['DOCID'] data = { 'title':title, 'url':url, 'date':date, 'time':time, 'file_type':file_type, 'id':id } infos.append(data) return infos def upload_mysql(connect, cursor, item, table_name): \"\"\"上传字典数据到mysql数据库\"\"\" keys = ','.join(item.keys()) values = ','.join(['%s']*len(item)) sql = 'insert into %s(%s) values(%s) on duplicate key update ' % ( table_name, keys, values) update = ','.join([key + '=%s' for key in item]) sql += update try: cursor.execute(sql, tuple(item.values())*2) connect.commit() except: connect.rollback() if __name__ == '__main__': # 使用数据库，如果不将解析的数据传到数据库，可以注释掉,注意修改数据库账号、密码信息 # connect = pymysql.connect( # host = '127.0.0.1', db = 'book', user = 'root', # passwd = 'xxxx', charset = 'utf8') # cursor = connect.cursor() # table_name = 'chufa' # 使用数据库，如果不将解析的数据传到数据库，可以注释掉 directory = './pdf' # 下载的pdf文件保存文件夹路径 infos = get_download_urls('警示函') df = pd.DataFrame(infos) df.to_excel('下载链接.xlsx',index=False) # 将获取到的列表信息保存到本地 output = [] for row in infos: url = row['url'] pdf_name = row['title'] + '.' + row['file_type'] try: download_pdf(url,directory,pdf_name) # 下载PDF print('下载文件：%s' % pdf_name) path = os.path.join(directory,pdf_name) content = extract_pdf(path) except: print('下载文件失败') content = '' row['content'] = content # 传数据库,如果不用数据库可以注释掉 # upload_mysql(connect,cursor,row,table_name) 由于解析的 PDF 文字很多，直接输出成 Excel 会串行，所以我是在第 4 步保存数据的时候， 把数据保存在数据库中，然后把数据库的表导出成 Excel 。 为了让读者能执行代码，我把上传数据库的代码注释了，但是解析的content你就看不到。 如果你会 mysql 数据库，可以把取消注释代码。 如果你想查询其它的关键词，下载 PDF ，可以修改这行代码的关键词： infos = get_download_urls('警示函') ","date":"2022-08-14","objectID":"/posts/20220814220542-%E4%B8%8A%E4%BA%A4%E6%89%80%E8%AD%A6%E7%A4%BA%E5%87%BD%E6%89%B9%E9%87%8F%E4%B8%8B%E8%BD%BD/:3:0","tags":["python"],"title":"上交所警示函批量下载","uri":"/posts/20220814220542-%E4%B8%8A%E4%BA%A4%E6%89%80%E8%AD%A6%E7%A4%BA%E5%87%BD%E6%89%B9%E9%87%8F%E4%B8%8B%E8%BD%BD/"},{"categories":["效率"],"content":"文件信息及PDF下载 我把下载好的信息和 PDF 也打包分享大家，有需要的可以直接下载： https://pan.baidu.com/s/1tTErvLvPgo0R30WTP9nUvA?pwd=k3sr ","date":"2022-08-14","objectID":"/posts/20220814220542-%E4%B8%8A%E4%BA%A4%E6%89%80%E8%AD%A6%E7%A4%BA%E5%87%BD%E6%89%B9%E9%87%8F%E4%B8%8B%E8%BD%BD/:4:0","tags":["python"],"title":"上交所警示函批量下载","uri":"/posts/20220814220542-%E4%B8%8A%E4%BA%A4%E6%89%80%E8%AD%A6%E7%A4%BA%E5%87%BD%E6%89%B9%E9%87%8F%E4%B8%8B%E8%BD%BD/"},{"categories":["工作"],"content":"最近在投一个资金分析的标，需要对几百个账户资金数据进行分析。 一般我们审计一家企业的时候，是很难对资金数据进行穿透的，为什么？ 因为我们只有被审计企业的资金账户数据，他的上游、下游的数据我们都不可能获取到。 所以，我们无法对整个资金链进行穿透。 也就是说，最困难的点是我们没有*数据*。 而这个项目最有意思是公安机关能获取到所有数据，我们需要做的就是分析。 那么在有数据的情况下怎么去分析呢？ 用 Excel 肯定不行吧，几百个账户，上亿的流水，眼睛去看或者用公式去看都很难。你很难直观知道这个钱分批转出去后，最终到了哪些账户里。 这就需要复杂网络分析的技术，去找网络中资金走的什么链路，最终归集到哪里，哪些节点是关键节点等等？ 所以这几天我正在学习复杂网络分析的相关知识，以及 python 的=networkx=库。 我非常期待能做这个项目，并把学到的知识运用到实战中。 ","date":"2022-08-14","objectID":"/posts/20220814214247-%E5%AD%A6%E4%B9%A0/:0:0","tags":["IT审计"],"title":"学习","uri":"/posts/20220814214247-%E5%AD%A6%E4%B9%A0/"},{"categories":["工作"],"content":"需求为向导 我一般不太喜欢去为了学习一个新的知识而学习新的知识，或者是为了考证而考证。 我喜欢在工作中看什么东西对我有用，我再去针对性地去学习，也就是以需求为向导地学习。 这样会有非常大的动力，并且学习过程中，能立马解决现实中的问题，带来强烈的正向反馈，进而促使我投入更多精力去掌握这些新的知识。 随着用这些知识解决问题数量的增多，就会慢慢从入门到精通。 而这个过程是非常有趣的，娱乐的，我感觉很多时候比玩游戏、刷剧有趣多了。 我基本休息的时间，都在干类似的事情，乐于其中。 祝读者周末愉快！ ","date":"2022-08-14","objectID":"/posts/20220814214247-%E5%AD%A6%E4%B9%A0/:1:0","tags":["IT审计"],"title":"学习","uri":"/posts/20220814214247-%E5%AD%A6%E4%B9%A0/"},{"categories":["效率"],"content":"前面在所里的时候，一位经理问我一些效率工具使用的问题。 我把以前做的东西告诉了她大概怎么使用的，然后给她了一个以前整理过的链接，让她自己去看。 聊到最后，我就说搞这些就是浪费自己时间，方便别人，而且还不能升职。 她也点点头，认同这个事实。 当时初、中级的时候就学了很多这些，也做了很多工具，当然完全是为了方便我自己不去做重复的工作，这是一个理念的问题。 以前那种 VBA 工具，我现在一个都没有去做了。不是因为我理念变了，或者说正常工作多了，而是我完全没有这些需求，我做它干嘛？ 我折腾的都是自己工作上用得上的东西，能帮助我不做重复工作的事。 只是每个时间段，学的东西不一样。 我仍然还是每天浪费了很多时间在学东西上面。 最近我从 vim 编辑器转到了 emacs 编辑器上面， 一个是编辑器之神，一个是神之编辑器。很多时候就是纯粹浪费时间。 但这种浪费时间，对于我来说是娱乐的，类似于喜欢打游戏的人的一样，一种消遣方式。 比如，上周有同事，让我把上交所的警示函给她找出来。 网站上是 pdf 文件。 由于我以前浪费过时间折腾过 python ，所以也就帮忙写了个爬虫批量把 PDF 下载下来，然后读取 PDF 的内容，整理成 Excel 。 最后发给她所有信息，以及打包的 PDF 文件。 不过我好像自己又浪费了几个小时时间。 ","date":"2022-08-13","objectID":"/posts/20220813233123-%E6%88%91%E6%B5%AA%E8%B4%B9%E4%BA%86%E5%BE%88%E5%A4%9A%E6%97%B6%E9%97%B4/:0:0","tags":["杂文"],"title":"我浪费了很多时间","uri":"/posts/20220813233123-%E6%88%91%E6%B5%AA%E8%B4%B9%E4%BA%86%E5%BE%88%E5%A4%9A%E6%97%B6%E9%97%B4/"}]